{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lesson 1A: Logistic Regression Theory\n",
                "\n",
                "\n",
                "## Introduction\n",
                "\n",
                "Logistic regression can be most easily thought of as learning to pick ripe fruit when you were a child.\n",
                "\n",
                "Whether it was apples, oranges, mangoes or rambutan - you'd follow a few simple rules: \"if it has the right color, feels slightly soft when squeezed, and has a sweet aroma, it's ready to eat\".\n",
                "\n",
                "Essentially, you were converting multiple continuous measurements into a single yes/no decision. After a few weeks of practice, you were able to pick ripe fruit with 90% accuracy. \n",
                "\n",
                "That's logistic regression in its purest form - taking several measurements (like the percentage of red colour, firmness level, and aroma strength) and combining them to make binary decisions (ripe or not ripe).\n",
                "\n",
                "In this lesson, we'll use logistic regression to build our first binary classification model, establishing key machine learning concepts that will serve as building blocks for more advanced models. We'll:\n",
                "1. Learn the theory behind logistic regression\n",
                "2. Build a logistic regression model from scratch to deeply understand each component\n",
                "3. Apply it to the Wisconsin Breast Cancer dataset\n",
                "\n",
                "Then in the next lesson (1b), we'll:\n",
                "1. Use industry-standard PyTorch to implement the same model more efficiently\n",
                "2. Learn best practices for production machine learning\n",
                "3. Compare our implementation with PyTorch's optimized version"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Table of Contents\n",
                "\n",
                "1. [Introduction](#introduction)\n",
                "2. [Required Libraries](#required-libraries)\n",
                "3. [What is Logistic Regression?](#what-is-logistic-regression)\n",
                "4. [How Logistic Regression Works](#how-logistic-regression-works)\n",
                "   - [Step 1: Linear Combination](#step-1-linear-combination)\n",
                "   - [Step 2: Sigmoid Function](#step-2-sigmoid-function)\n",
                "   - [Step 3: Making a Prediction](#step-3-making-a-prediction)\n",
                "   - [Interactive Logistic Regression Visualization](#interactive-logistic-regression-visualization)\n",
                "     - [2D Decision Boundary - 2 features](#2d-decision-boundary---2-features)\n",
                "     - [3D Decision Boundary - 3 features](#3d-decision-boundary---3-features)\n",
                "   - [Hyperplane in Higher Dimensions - n features](#hyperplane-in-higher-dimensions---n-features)\n",
                "5. [The Training Process: Learning to Spot Cancer](#the-training-process-learning-to-spot-cancer)\n",
                "   - [Understanding Feature Importance](#1.-understanding-feature-importance)\n",
                "   - [Combining Features](#2.-combining-features)\n",
                "   - [Converting to Mathematics](#3.-converting-to-mathematics)\n",
                "   - [Visualizing the Learning Process](#4.-visualizing-the-learning-process)\n",
                "   - [Understanding Our Results](#5.-understanding-our-results)\n",
                "   - [The Problem: Different Scales](#the-problem:-different-scales)\n",
                "   - [Nature's Solution: Normal Distributions](#nature's-solution:-normal-distributions)\n",
                "   - [Making Measurements Comparable](#making-measurements-comparable)\n",
                "6. [Learning the Right Weights](#learning-the-right-weights)\n",
                "   - [The Training Approach](#the-training-approach)\n",
                "   - [Starting Fresh](#starting-fresh)\n",
                "   - [Making Our First Prediction](#making-our-first-prediction)\n",
                "   - [Converting Score to Probability](#converting-score-to-probability)\n",
                "   - [Reality Check](#reality-check)\n",
                "   - [Converting Error to Loss](#converting-error-to-loss)\n",
                "   - [Binary Cross-Entropy Loss](#binary-cross-entropy-loss)\n",
                "   - [Asymmetric Loss: When Mistakes Aren't Equal](#asymmetric-loss-when-mistakes-arent-equal)\n",
                "7. [Gradient Descent: Learning from our Errors](#gradient-descent-learning-from-our-errors)\n",
                "   - [Step 1: Starting position and \"the forward pass\"](#step-1-starting-position-and-the-forward-pass)\n",
                "   - [Step 2: Sigmoid Activation - Making a Prediction](#step-2-sigmoid-activation---making-a-prediction)\n",
                "   - [Step 3: Measuring the Error](#step-3-measuring-the-error)\n",
                "   - [Step 4: Calculating the Gradient of loss for each parameter - the backwards pass](#step-4-calculating-the-gradient-of-loss-for-each-parameter)\n",
                "   - [Step 4: How gradient of loss with respect to each parameter is derived using the Chain Rule](#step-4---the-calculus-how-gradient-of-loss-with-respect-to-each-parameter-is-derived-using-the-chain-rule)\n",
                "   - [Step 5: Calculating the amount to update each parameter by](#step-5-calculating-the-amount-to-update-each-parameter-by)\n",
                "   - [Step 6: Updating the Parameters](#step-6-updating-the-parameters)\n",
                "   - [Second Pass - Step 1 again](#second-pass---step-1-again)\n",
                "   - [The Learning Process](#the-learning-process)\n",
                "8. [Implementing Logistic Regression: From Theory to Code](#implementing-logistic-regression:-from-theory-to-code)\n",
                "9. [Understanding Our Training Results Through Evaluation](#understanding-our-training-results-through-evaluation)\n",
                "   - [Key Outcomes](#key-outcomes)\n",
                "   - [Medical Interpretation](#medical-interpretation)\n",
                "10. [Basic Evaluation Concepts](#basic-evaluation-concepts)\n",
                "      - [The Four Possible Outcomes](#the-four-possible-outcomes)\n",
                "      - [Basic Accuracy Formula](#basic-accuracy-formula)\n",
                "      - [The Problem with Simple Accuracy](#the-problem-with-simple-accuracy)\n",
                "      - [The Confusion Matrix](#the-confusion-matrix)\n",
                "11. [Understanding Our Model's Performance](#understanding-our-models-performance)\n",
                "      - [The Good News](#the-good-news)\n",
                "      - [The Challenges](#the-challenges)\n",
                "      - [Clinical Implications](#clinical-implications)\n",
                "      - [Next Steps](#next-steps)\n",
                "12. [Understanding Learning Rate Effects](#understanding-learning-rate-effects)\n",
                "      - [Reading the Loss Curves](#reading-the-loss-curves)\n",
                "      - [The Performance Trade-offs](#the-performance-trade-offs)\n",
                "      - [What This Tells Us About Machine Learning](#what-this-tells-us-about-machine-learning)\n",
                "13. [From Theory to Practice: Our Journey Through Logistic Regression](#from-theory-to-practice-our-journey-through-logistic-regression)\n",
                "      - [Building From Ground Up](#building-from-ground-up)\n",
                "      - [Deep Mathematical Understanding](#deep-mathematical-understanding)\n",
                "      - [Understanding Our Implementation's Limitations](#understanding-our-implementations-limitations)\n",
                "      - [Looking Ahead to Lesson 1B](#looking-ahead-to-lesson-1b)\n",
                "      - [Further Reading](#further-reading)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Required Libraries\n",
                "\n",
                "Before we get started, let's load the necessary libraries that will be used throughout this lesson in our theory examples.\n",
                "\n",
                "In this lesson we will use the following libraries:\n",
                "<table style=\"margin-left:0\">\n",
                "<tr>\n",
                "<th align=\"left\">Library</th>\n",
                "<th align=\"left\">Purpose</th>\n",
                "</tr>\n",
                "<tr>\n",
                "<td>Pandas</td>\n",
                "<td>Data tables and data manipulation</td>\n",
                "</tr>\n",
                "<tr>\n",
                "<td>Numpy</td>\n",
                "<td>Numerical computing functions</td>\n",
                "</tr>\n",
                "<tr>\n",
                "<td>Matplotlib</td>\n",
                "<td>Plotting functions</td>\n",
                "</tr>\n",
                "<tr>\n",
                "<td>Seaborn</td>\n",
                "<td>Statistical visualisation</td>\n",
                "</tr>\n",
                "<tr>\n",
                "<td>Scikit-learn</td>\n",
                "<td>Machine learning utilities including logistic regression, preprocessing, metrics, and dataset loading functions</td>\n",
                "</tr>\n",
                "<tr>\n",
                "<td>Typing</td>\n",
                "<td>Type hints</td>\n",
                "</tr>\n",
                "</table>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Standard library imports\n",
                "from typing import List, Optional, Union, Tuple\n",
                "\n",
                "# Third party imports\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from numpy.typing import NDArray\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.datasets import load_breast_cancer\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score,\n",
                "    precision_score, \n",
                "    recall_score,\n",
                "    f1_score,\n",
                "    confusion_matrix\n",
                ")\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# Jupyter specific\n",
                "%matplotlib inline\n",
                "\n",
                "# Configure settings\n",
                "np.random.seed(42)\n",
                "pd.set_option('display.max_columns', None)\n",
                "plt.style.use('seaborn-v0_8')\n",
                "\n",
                "print(\"Libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## What is Logistic Regression?\n",
                "\n",
                "Formally, logistic regression is a statistical model that estimates the probability of a binary outcome based on one or more input variables.\n",
                "\n",
                "Despite its name, logistic regression is a classification algorithm, not a regression algorithm. It estimates the probability of a binary outcome (yes/no, true/false, 1/0) based on one or more input variables.\n",
                "\n",
                "At its most basic level, the logistic regression algorithm follows 4 key steps:\n",
                "1. Takes in numeric measurements (like temperature, age, or price)\n",
                "2. Combines them in a clever way to calculate a score\n",
                "3. Converts this score into a probability between 0 and 1\n",
                "4. Makes a yes/no decision based on whether that probability exceeds 0.5\n",
                "\n",
                "The \"regression\" in its name comes from how it finds relationships between input features and the probability of the outcome. It uses a special function called the sigmoid (or logistic function) to transform linear predictions into probabilities.\n",
                "\n",
                "Before diving into the implementation, let's understand the core mathematical concepts that make this possible."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## How Logistic Regression Works\n",
                "Logistic regression works by finding a mathematical relationship between the input data and the probability of the outcome being a binary outcome - a \"yes\" or \"no\", 1 or 0, true or false.\n",
                "\n",
                "Logistic regression does this by following three key steps:\n",
                "\n",
                "1. **Linear Combination**: First we combine input features by multiplying each one by a learned weight and adding a bias term to obtain a score.\n",
                "\n",
                "2. **Sigmoid Function**: Then we convert the score to a probability using the sigmoid function.\n",
                "\n",
                "3. **Decision Rule**: Finally we convert the probability into a yes/no prediction by setting a threshold (typically 0.5).\n",
                "\n",
                "\\\n",
                "Let's work through a medical diagnosis example to see logistic regression in action. We'll use three key features:\n",
                "\n",
                "```\n",
                "Patient Data:\n",
                "- Age: 45\n",
                "- Blood Pressure: 128/82\n",
                "- Cholesterol: 240\n",
                "```\n",
                "\n",
                "### Step 1: Linear Combination\n",
                "\n",
                "First, logistic regression combines all input features by multiplying each one by a learned weight and intially these weights are random values:\n",
                "\n",
                "\n",
                "### $z = w_1x_1 + w_2x_2 + ... + w_nx_n + b$\n",
                "\n",
                "\n",
                "Here:\n",
                "- `x1`, `x2`, ..., `xn` are the input features values - in this example: age (years), systolic blood pressure (mmHg), total cholesterol (mg/dL).\n",
                "- `w1`, `w2`, ..., `wn` are the weights - values that indicates how important each feature is.\n",
                "- `b` is the bias term - a value that indicates the base prediction level, like a doctor's starting suspicion. In this example, we'll set it to 0.\n",
                "\n",
                "#### For our medical example:\n",
                "\n",
                "**Initial weights and bias:**\n",
                "\n",
                "### $w_1 = 0.03, w_2 = 0.02, w_3 = 0.01, b = 0$\n",
                "\n",
                "**Linear combination:**\n",
                "\n",
                "### $z = 0.03 \\times \\text{age} + 0.02 \\times blood\\_pressure + 0.01 \\times \\text{cholesterol} + 0$\n",
                "### $z = 0.03 \\times 45 + 0.02 \\times 128 + 0.01 \\times 240 + 0$\n",
                "### $z = 1.35 + 2.56 + 2.40 + 0$\n",
                "### $z = 6.31$\n",
                "\n",
                "\n",
                "This gives us a number that could be any value from negative infinity to positive infinity. \n",
                "\n",
                "To turn this into a probability, we need the sigmoid function."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 2: Sigmoid Function\n",
                "\n",
                "The result of the linear combination (`z`) could be any number from negative infinity to positive infinity, but we want a probability between 0 and 1. To achieve this, we pass `z` through a special mathematical function called the sigmoid function:\n",
                "\n",
                "\n",
                "### $p = \\frac{1}{1 + e^{-z}}$\n",
                "\n",
                "Here, `e` is Euler's number (approximately 2.71828), also known as the base of natural logarithms.\n",
                "\n",
                "The sigmoid function squashes `z` into a value between 0 and 1, which we can interpret as the probability of the outcome being \"yes\". For our example:\n",
                "\n",
                "### $p = \\frac{1}{1 + e^{-6.31}}$\n",
                "### $p = \\frac{1}{1 + 0.00182}$\n",
                "### $p = 0.998$\n",
                "\n",
                "In this example, our calculation determines that the probability of the patient being at high risk of disease is 99.8%.\n",
                "\n",
                "The sigmoid function has several important properties:\n",
                "\n",
                "1. Always outputs values between 0 and 1\n",
                "2. Centered at 0.5 (when input is 0)\n",
                "3. S-shaped curve captures natural probability thresholds\n",
                "\n",
                "![Sigmoid Curve](../static/images/sigmoid-curve.png)\n",
                "\n",
                "Let's visualize the sigmoid function in python:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def sigmoid(x):\n",
                "    \"\"\"Convert input to probability between 0 and 1\"\"\"\n",
                "    return 1 / (1 + np.exp(-x))\n",
                "\n",
                "# Create range of input values\n",
                "x = np.linspace(-10, 10, 200)\n",
                "y = sigmoid(x)\n",
                "\n",
                "# Plot sigmoid function\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(x, y, 'b-', label='Sigmoid Function')\n",
                "plt.axhline(y=0.5, color='r', linestyle='--', label='Decision Boundary')\n",
                "plt.grid(True)\n",
                "plt.title('Sigmoid Function: Converting Linear Input to Probability')\n",
                "plt.xlabel('Linear Combination (z)')\n",
                "plt.ylabel('Probability')\n",
                "plt.legend()\n",
                "\n",
                "# Add annotations\n",
                "plt.annotate('Negative Class', xy=(-5, 0.1), xytext=(-5, 0.3),\n",
                "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
                "plt.annotate('Positive Class', xy=(5, 0.9), xytext=(5, 0.7),\n",
                "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 3: Making a Prediction\n",
                "\n",
                "Finally, we convert the probability to a yes/no prediction using a threshold (usually 0.5):\n",
                "\n",
                "```python\n",
                "if probability > 0.5:\n",
                "    prediction = \"Yes\" (Class 1)\n",
                "else:\n",
                "    prediction = \"No\" (Class 0)\n",
                "```\n",
                "\n",
                "For our medical example:\n",
                "```\n",
                "probability = 0.998 > 0.5\n",
                "prediction = \"Yes (Class 1) High risk of disease\"\n",
                "```\n",
                "\n",
                "## Interactive Logistic Regression Visualization \n",
                "\n",
                " Let's visualize this decision process with a simple 2D example in python showing the decision boundary for two features.\n",
                "\n",
                "### 2D Decision Boundary - 2 features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Create synthetic patient data\n",
                "np.random.seed(42)  # For reproducible results\n",
                "num_patients = 200\n",
                "num_features = 2\n",
                "\n",
                "# Generate random patient measurements\n",
                "patient_features = np.random.randn(num_patients, num_features)  \n",
                "\n",
                "# Step 2: Create risk labels\n",
                "patient_risk = (patient_features[:, 0] + patient_features[:, 1] > 0).astype(int)\n",
                "\n",
                "# Step 3: Train the logistic regression model\n",
                "risk_predictor = LogisticRegression()\n",
                "risk_predictor.fit(patient_features, patient_risk)\n",
                "\n",
                "# Step 4: Prepare the visualization grid\n",
                "padding = 2\n",
                "feature1_min = patient_features[:, 0].min() - padding\n",
                "feature1_max = patient_features[:, 0].max() + padding\n",
                "feature2_min = patient_features[:, 1].min() - padding \n",
                "feature2_max = patient_features[:, 1].max() + padding\n",
                "\n",
                "# Step 5: Create the visualization\n",
                "plt.figure(figsize=(12, 10))\n",
                "\n",
                "# Plot the actual patient data points\n",
                "plt.scatter(patient_features[patient_risk==0][:, 0], \n",
                "           patient_features[patient_risk==0][:, 1], \n",
                "           color='blue', \n",
                "           label='Low Risk',\n",
                "           s=70,\n",
                "           alpha=0.6)\n",
                "plt.scatter(patient_features[patient_risk==1][:, 0], \n",
                "           patient_features[patient_risk==1][:, 1], \n",
                "           color='red', \n",
                "           label='High Risk',\n",
                "           s=70,\n",
                "           alpha=0.6)\n",
                "\n",
                "# Plot the decision boundary line\n",
                "model_weights = risk_predictor.coef_[0]\n",
                "model_bias = risk_predictor.intercept_[0]\n",
                "boundary_x = np.array([feature1_min, feature1_max])\n",
                "boundary_y = -(model_weights[0]*boundary_x + model_bias)/model_weights[1]\n",
                "plt.plot(boundary_x, boundary_y, 'k--', linewidth=2, label='Decision Boundary')\n",
                "\n",
                "# Add labels and formatting\n",
                "plt.title('Logistic Regression Decision Boundary', fontsize=14, pad=20)\n",
                "plt.xlabel('Feature 1 - Age', fontsize=12)\n",
                "plt.ylabel('Feature 2 - Blood Pressure', fontsize=12)\n",
                "plt.legend(fontsize=10)\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "# Ensure plot shows full range\n",
                "plt.xlim(feature1_min, feature1_max)\n",
                "plt.ylim(feature2_min, feature2_max)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This visualization shows how logistic regression creates a linear decision boundary in the feature space. \n",
                "\n",
                "Points below the line are classified as Class 0 - False (blue), and points above the line are Class 1 - True (red).\n",
                "\n",
                "Patients were classified as high risk (1) because their features measurements sum to greater than zero. Patients were classified as low risk (0) because their features measurements sum to less than zero.\n",
                "\n",
                "The dotted black line shows where the model's predicted probability equals 0.5, which is where the feature measurements sum to 0.\n",
                "\n",
                "Key insights:\n",
                "1. The decision boundary is always linear\n",
                "2. Distance from boundary indicates prediction confidence\n",
                "3. Points far from boundary have probabilities close to 0 or 1\n",
                "4. Points near boundary have probabilities close to 0.5\n",
                "\n",
                "\n",
                "#### 3D Decision Boundary - 3 features\n",
                "\n",
                "In 3D space, the decision boundary becomes a plane.\n",
                "The plane divides the 3D space into two regions, each corresponding to a class.\n",
                "\n",
                "Let's visualize this decision process with a simple 3D example in python showing the decision boundary for three features.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3D visualization\n",
                "def visualize_logistic_regression_3d():\n",
                "    # Set random seed for reproducibility\n",
                "    np.random.seed(0)\n",
                "    \n",
                "    # Generate random 3D data points\n",
                "    feature_data = np.random.randn(200, 3)\n",
                "    # Create binary labels based on sum of features\n",
                "    labels = (feature_data[:, 0] + feature_data[:, 1] + feature_data[:, 2] > 0).astype(int)\n",
                "\n",
                "    # Train logistic regression model\n",
                "    logistic_model = LogisticRegression()\n",
                "    logistic_model.fit(feature_data, labels)\n",
                "\n",
                "    # Create 3D plot\n",
                "    figure = plt.figure(figsize=(12, 8))\n",
                "    axes_3d = figure.add_subplot(111, projection='3d')\n",
                "\n",
                "    # Add grid lines for better visualization\n",
                "    axes_3d.grid(True, color='gray', linestyle='-', alpha=0.3)\n",
                "    axes_3d.xaxis._axinfo[\"grid\"]['color'] = 'gray'\n",
                "    axes_3d.yaxis._axinfo[\"grid\"]['color'] = 'gray'\n",
                "    axes_3d.zaxis._axinfo[\"grid\"]['color'] = 'gray'\n",
                "\n",
                "    # Calculate decision boundary plane coordinates\n",
                "    feature1_min, feature1_max = feature_data[:, 0].min() - 1, feature_data[:, 0].max() + 1\n",
                "    feature2_min, feature2_max = feature_data[:, 1].min() - 1, feature_data[:, 1].max() + 1\n",
                "    feature1_grid, feature2_grid = np.meshgrid(np.arange(feature1_min, feature1_max, 0.02),\n",
                "                                              np.arange(feature2_min, feature2_max, 0.02))\n",
                "    \n",
                "    # Calculate feature3 values for decision boundary plane\n",
                "    feature3_boundary = (-logistic_model.intercept_[0] - \n",
                "                        logistic_model.coef_[0][0] * feature1_grid - \n",
                "                        logistic_model.coef_[0][1] * feature2_grid) / logistic_model.coef_[0][2]\n",
                "\n",
                "    # Plot decision boundary plane\n",
                "    axes_3d.plot_surface(feature1_grid, feature2_grid, feature3_boundary, alpha=0.2, color='gray')\n",
                "\n",
                "    # Plot data points colored by class\n",
                "    axes_3d.scatter(feature_data[labels==0][:, 0], \n",
                "                   feature_data[labels==0][:, 1], \n",
                "                   feature_data[labels==0][:, 2], \n",
                "                   color='blue', label='Low Risk', alpha=0.8)\n",
                "    axes_3d.scatter(feature_data[labels==1][:, 0], \n",
                "                   feature_data[labels==1][:, 1], \n",
                "                   feature_data[labels==1][:, 2], \n",
                "                   color='red', label='High Risk', alpha=0.8)\n",
                "\n",
                "    # Add labels and title\n",
                "    axes_3d.set_xlabel('Feature 1 - Age')\n",
                "    axes_3d.set_ylabel('Feature 2 - Blood Pressure')\n",
                "    axes_3d.set_zlabel('Feature 3 - LDL Cholesterol')\n",
                "    axes_3d.set_title('3D Logistic Regression Decision Boundary')\n",
                "    axes_3d.legend(bbox_to_anchor=(1.15, 1))\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Generate visualization\n",
                "visualize_logistic_regression_3d()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Hyperplane in Higher Dimensions - n features\n",
                "\n",
                "For datasets with more than 3 features, we can't visualize the decision boundary directly. \n",
                "\n",
                "The concept extends to a hyperplane in higher-dimensional space.\n",
                "\n",
                "A hyperplane in n-dimensional space is the subspace of dimension n-1 that divides the space into two parts.\n",
                "\n",
                "![Mind Blowing](../static/images/mind-blowing.gif)\n",
                "\n",
                "### The Equation of the Hyperplane\n",
                "   - For n features, the hyperplane is defined by the equation: $w_1 x_1 + w_2 x_2 + ... + w_n x_n + b = 0$\n",
                "   - w1, w2, ..., wn are the weights learned by the model, and b is the bias term.\n",
                "\n",
                "   **Look familiar? This is the same linear combination equation we saw at the start of the lesson!**\n",
                "\n",
                "While we can't visualize beyond 3D, the same principle applies in higher dimensions - the model finds a hyperplane that best separates the classes in the feature space.\n",
                "\n",
                "Now that we understand how logistic regression makes predictions, let's see how it chooses and learns the right weights and bias during training."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The Training Process: Learning to Spot Cancer\n",
                "\n",
                "### 1. Understanding Feature Importance\n",
                "\n",
                "Let's see how doctors learn to diagnose cancer by looking at two key features:\n",
                "\n",
                "**Cell Size**\n",
                "```\n",
                "Normal Cell:  12mm across\n",
                "Cancer Cell:  18mm across  (50% bigger - suspicious!)\n",
                "```\n",
                "\n",
                "**Cell Shape**\n",
                "```\n",
                "Normal Cell:  Smooth, round edges\n",
                "Cancer Cell:  Rough, irregular edges (very suspicious!)\n",
                "```\n",
                "\n",
                "### 2. Combining Features\n",
                "\n",
                "After examining hundreds of cells, doctors learn that some patterns matter more than others:\n",
                "```\n",
                "Pattern                     Likely Diagnosis\n",
                "-------------------         ----------------\n",
                "Big + Smooth                Probably benign\n",
                "Normal + Very irregular     Likely cancer\n",
                "\n",
                "Key Learning: Shape irregularity is a stronger indicator than size!\n",
                "```\n",
                "\n",
                "### 3. Converting to Mathematics\n",
                "\n",
                "We can translate the doctor's knowledge into weights:\n",
                "```\n",
                "Doctor's Rule               Mathematical Version\n",
                "-------------               -------------------\n",
                "Size matters some    →      Size × 0.3\n",
                "Shape matters more   →      Shape × 0.7\n",
                "\n",
                "Decision Rule: If (Size × 0.3 + Shape × 0.7) > 4.41: Suspicious!\n",
                "```\n",
                "\n",
                "### 4. Visualizing the Learning Process\n",
                "\n",
                "Let's create a dataset of 200 cells (100 normal, 100 cancerous) and analyze how these features help us distinguish between them:\n",
                "\n",
                "1. **Size Distribution**    - First, we'll look at how cell sizes differ between normal and cancerous cells\n",
                "2. **Shape Distribution**   - Then, we'll examine the shape irregularity patterns\n",
                "3. **Combined View**        - We'll plot size against shape to see how they work together\n",
                "4. **Final Score**          - Finally, we'll see how combining these features (0.3×Size + 0.7×Shape) helps separate the two groups"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# This code creates a dataset of normal and cancerous cells with different size and shape irregularity scores \n",
                "# Then presents the distribution of \n",
                "\n",
                "# Create sample data for demonstration\n",
                "np.random.seed(42)\n",
                "\n",
                "# Generate two groups of cells\n",
                "normal_size = np.random.normal(12, 1, 100)  # Normal cells: mean 12mm\n",
                "cancer_size = np.random.normal(17, 2, 100)  # Cancer cells: mean 17mm\n",
                "\n",
                "# Create corresponding shape irregularity scores\n",
                "normal_shape = np.random.normal(0.3, 0.1, 100)  # More regular\n",
                "cancer_shape = np.random.normal(0.7, 0.15, 100) # More irregular\n",
                "\n",
                "# Create figure with 4 subplots in 2x2 layout\n",
                "plt.figure(figsize=(15, 15))\n",
                "\n",
                "# Plot 1: Size Distribution bar chart of normal and cancerous cells\n",
                "plt.subplot(221)\n",
                "plt.hist(normal_size, alpha=0.5, color='green', label='Normal Cells')\n",
                "plt.hist(cancer_size, alpha=0.5, color='red', label='Cancer Cells')\n",
                "plt.title('Step 1: Size Distribution')\n",
                "plt.xlabel('Cell Size (mm)')\n",
                "plt.ylabel('Number of Cells')\n",
                "plt.legend()\n",
                "\n",
                "# Plot 2: Shape Distribution bar chart of normal and cancerous cells\n",
                "plt.subplot(222)\n",
                "plt.hist(normal_shape, alpha=0.5, color='green', label='Normal Cells')\n",
                "plt.hist(cancer_shape, alpha=0.5, color='red', label='Cancer Cells')\n",
                "plt.title('Step 2: Shape Distribution')\n",
                "plt.xlabel('Shape Irregularity')\n",
                "plt.ylabel('Number of Cells')\n",
                "plt.legend()\n",
                "\n",
                "# Plot 3: Size vs Shape Scatter with normal and cancerous cells labelled\n",
                "plt.subplot(223)\n",
                "plt.scatter(normal_size, normal_shape, alpha=0.5, color='green', label='Normal')\n",
                "plt.scatter(cancer_size, cancer_shape, alpha=0.5, color='red', label='Cancer')\n",
                "plt.title('Step 3: Size vs Shape')\n",
                "plt.xlabel('Cell Size (mm)')\n",
                "plt.ylabel('Shape Irregularity')\n",
                "plt.legend()\n",
                "\n",
                "# Plot 4: Combined Score bar chart of normal and cancerous cells\n",
                "plt.subplot(224)\n",
                "normal_score = 0.3 * normal_size + 0.7 * normal_shape\n",
                "cancer_score = 0.3 * cancer_size + 0.7 * cancer_shape\n",
                "plt.hist(normal_score, alpha=0.5, color='green', label='Normal Cells')\n",
                "plt.hist(cancer_score, alpha=0.5, color='red', label='Cancer Cells')\n",
                "plt.title('Step 4: Combined Score')\n",
                "plt.xlabel('Score (0.3×Size + 0.7×Shape)')\n",
                "plt.ylabel('Number of Cells')\n",
                "plt.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Understanding Our Results\n",
                "\n",
                "Looking at our four plots reveals the challenge of combining features:\n",
                "\n",
                "1. **Size Distribution** (top left):\n",
                "   - Normal cells cluster around 12mm (green)\n",
                "   - Cancer cells cluster around 17mm (red)\n",
                "   - Significant overlap between 13-14mm\n",
                "     \n",
                "  \n",
                "  \n",
                "2. **Shape Distribution** (top right):\n",
                "   - Normal cells have regularity around 0.3 (green)\n",
                "   - Cancer cells have irregularity around 0.7 (red)\n",
                "   - Clear separation but still some overlap\n",
                "       \n",
                "  \n",
                "\n",
                "3. **Size vs Shape** (bottom left):\n",
                "   - Clear clustering pattern emerges\n",
                "   - Normal cells: small + regular (bottom left, green)\n",
                "   - Cancer cells: large + irregular (top right, red)\n",
                "   - We see a clear separation between the two classes\n",
                "     \n",
                "\n",
                "4. **Combined Score** (bottom right):\n",
                "   - Formula: 0.3×Size + 0.7×Shape\n",
                "   - Normal scores cluster around 4.0\n",
                "   - Cancer scores cluster around 6.0\n",
                "   - We can imagine a decision boundary at 4.41 \n",
                "     \n",
                "  \n",
                "  \n",
                "  \n",
                "### The Problem: Different Scales\n",
                "\n",
                "Our measurements live in different orders of magnitude:\n",
                "- Size: Typically 10-20 millimeters\n",
                "- Shape: Always between 0-1\n",
                "\n",
                "Size dominates our equation just because it uses bigger numbers!\n",
                "\n",
                "### Nature's Solution: Normal Distributions\n",
                "\n",
                "<img alt=\"Normal Distribution\" src=\"../static/images/normal-distribution.jpg\" width=\"875\"/>\n",
                "\n",
                "Here's something remarkable about biology: most measurements follow a 'normal distribution'.\n",
                "\n",
                "<img alt=\"Height Normal Distribution\" src=\"../static/images/height-normal-distribution.png\" width=\"875\"/>\n",
                "\n",
                "For cell size:\n",
                "- Most cells cluster around an average (μ)\n",
                "- Variation is predictable (measured by σ)\n",
                "- Very few cells are more than 3σ from average\n",
                "\n",
                "This pattern appears in both size AND shape measurements!\n",
                "\n",
                "### Making Measurements Comparable\n",
                "\n",
                "We can use this natural pattern to standardize our measurements\n",
                "### Standard Deviation (σ) = $\\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\mu)^2}{n}}$\n",
                "```pre\n",
                "Where:\n",
                "- σ is the standard deviation\n",
                "- x_i is each value in the dataset \n",
                "- μ is the mean of the dataset\n",
                "- n is the number of values\n",
                "```\n",
                "\n",
                "### Standardized Value = $ \\frac{value - average}{standard\\_deviation}$\n",
                "### Standardized Value = $\\frac{x - \\mu}{\\sigma}$\n",
                "\n",
                "This tells us: \"How many standard deviations away from normal?\"\n",
                "\n",
                "Now our measurements speak the same language:\n",
                "```pre\n",
                "Original → Standardized (σ units)\n",
                "\n",
                "Cancer Cell:\n",
                "18mm   → +2.1  (2.1σ above normal size)\n",
                "0.8    → +1.9  (1.9σ above normal shape)\n",
                "\n",
                "Normal Cell:\n",
                "16mm   → +0.8  (0.8σ above normal size)\n",
                "0.3    → -0.7  (0.7σ below normal shape)\n",
                "```\n",
                "\n",
                "\n",
                "### Now We Can Learn Properly!\n",
                "\n",
                "With standardized values:\n",
                "1. Size and shape are comparable\n",
                "2. We can find true importance (weights)\n",
                "3. Numbers have biological meaning\n",
                "\n",
                "### Let's compare our raw measurements dataset and a standardised measurements data set\n",
                "- Intial weights of both features will be 0.5 and no bias so the output of the linear combination will be: Combined score $(z) = 0.5 \\times feature_1 + 0.5 \\times feature_2 + 0$\n",
                "- We'll see how the output of combined score $(z) = w_1x_1 + w_2x_2 + b$, changes for both our datasets\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate sample data\n",
                "np.random.seed(42)\n",
                "n_samples = 1000\n",
                "\n",
                "# Generate realistic cell measurements\n",
                "normal_size = np.random.normal(12, 1, n_samples)    \n",
                "cancer_size = np.random.normal(16, 2, n_samples)    \n",
                "normal_shape = np.random.normal(0.3, 0.1, n_samples)  \n",
                "cancer_shape = np.random.normal(0.7, 0.15, n_samples) \n",
                "\n",
                "# Colors\n",
                "size_color = '#FF69B4'  # Pink\n",
                "shape_color = '#4FB0FF'  # Light blue\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
                "\n",
                "# Plot 1: Raw Measurements Scatter - FIXED SCALE to show true relationship\n",
                "axes[0,0].scatter(normal_size, normal_shape, alpha=0.5, c='green', label='Normal Cells')\n",
                "axes[0,0].scatter(cancer_size, cancer_shape, alpha=0.5, c='red', label='Cancer Cells')\n",
                "axes[0,0].set_title('Raw Measurements\\nNotice how Shape only uses tiny portion of y-axis!')\n",
                "axes[0,0].set_xlabel('Cell Size (mm)')\n",
                "axes[0,0].set_ylabel('Shape Irregularity (0-1)')\n",
                "axes[0,0].set_ylim(-2, 20)  # Force same scale as x-axis to show true scale difference\n",
                "axes[0,0].legend()\n",
                "axes[0,0].grid(True)\n",
                "\n",
                "# Plot 2: Raw feature contributions\n",
                "size_contribution = np.abs(0.5 * normal_size).mean()\n",
                "shape_contribution = np.abs(0.5 * normal_shape).mean()\n",
                "\n",
                "# Simple bar plot showing relative scales with fixed y-axis\n",
                "axes[0,1].bar(['Raw Feature 1: Size\\n(0.5 × feature 1)', 'Raw Feature 2: Shape\\n(0.5 × feature 2)'], \n",
                "              [size_contribution, shape_contribution],\n",
                "              color=[size_color, shape_color])\n",
                "axes[0,1].set_ylabel('Absolute Contribution to Combined Score')\n",
                "axes[0,1].set_ylim(0, 12)  # Fixed scale to show full context\n",
                "axes[0,1].grid(True, alpha=0.3)\n",
                "\n",
                "# Standardize ALL data together\n",
                "all_sizes = np.concatenate([normal_size, cancer_size])\n",
                "all_shapes = np.concatenate([normal_shape, cancer_shape])\n",
                "\n",
                "def standardize(x):\n",
                "    return (x - np.mean(x)) / np.std(x)\n",
                "\n",
                "std_sizes = standardize(all_sizes)\n",
                "std_shapes = standardize(all_shapes)\n",
                "\n",
                "# Split back into normal/cancer\n",
                "std_sizes_normal = std_sizes[:n_samples]\n",
                "std_sizes_cancer = std_sizes[n_samples:]\n",
                "std_shapes_normal = std_shapes[:n_samples]\n",
                "std_shapes_cancer = std_shapes[n_samples:]\n",
                "\n",
                "# Plot 3: Standardized Measurements Scatter\n",
                "axes[1,0].scatter(std_sizes_normal, std_shapes_normal, alpha=0.5, c='green', label='Normal Cells')\n",
                "axes[1,0].scatter(std_sizes_cancer, std_shapes_cancer, alpha=0.5, c='red', label='Cancer Cells')\n",
                "axes[1,0].set_title('Standardized Measurements\\nBoth features now use same scale (-3σ to +3σ)')\n",
                "axes[1,0].set_xlabel('Standardized Size (σ units)')\n",
                "axes[1,0].set_ylabel('Standardized Shape (σ units)')\n",
                "axes[1,0].set_xlim(-3, 3)  # Set to standard normal range\n",
                "axes[1,0].set_ylim(-3, 3)  # Set to standard normal range\n",
                "axes[1,0].legend()\n",
                "axes[1,0].grid(True)\n",
                "\n",
                "# Plot 4: Standardized feature contributions\n",
                "std_size_contribution = np.abs(0.5 * std_sizes_normal).mean()\n",
                "std_shape_contribution = np.abs(0.5 * std_shapes_normal).mean()\n",
                "\n",
                "axes[1,1].bar(['Standardized\\nFeature 1: Size', 'Standardized\\nFeature 1: Shape'],\n",
                "              [std_size_contribution, std_shape_contribution],\n",
                "              color=[size_color, shape_color])\n",
                "axes[1,1].set_title('Standardized Feature Contributions\\nBoth features now contribute similarly')\n",
                "axes[1,1].set_ylabel('Absolute Contribution to Score')\n",
                "axes[1,1].set_ylim(0, 1)  # Fixed scale for standardized values\n",
                "axes[1,1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Print example values\n",
                "print(\"\\nAverage Absolute Raw Contributions to Combined Score (z)\")\n",
                "print(\"-\" * 50)\n",
                "print(f\"Size term (0.5 × size): {size_contribution:.2f}\")\n",
                "print(f\"Shape term (0.5 × shape): {shape_contribution:.2f}\")\n",
                "print(f\"Size term is {size_contribution/shape_contribution:.1f}x larger than shape term!\")\n",
                "\n",
                "print(\"\\nAverage Absolute Standardized Contributions to Combined Score (z)\")\n",
                "print(\"-\" * 50)\n",
                "print(f\"Standardized size term: {std_size_contribution:.2f}\")\n",
                "print(f\"Standardized shape term: {std_shape_contribution:.2f}\")\n",
                "print(f\"Ratio between terms: {std_size_contribution/std_shape_contribution:.2f}x\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Look at what standardisation does for us:\n",
                "\n",
                "1. **Original Measurements** (top row)\n",
                "   - Size and shape use completely different scales\n",
                "   - Natural clusters difficult to distinguish because they are on different scales causing them to appear to overlap\n",
                "\n",
                "2. **After Standardisation** (bottom row)\n",
                "   - Both measurements in standard deviation (σ) units\n",
                "   - Zero means \"average\"\n",
                "   - ±1 means \"one standard deviation difference\"\n",
                "   - Now we can fairly compare size and shape, and distinguish between each group!\n",
                "\n",
                "This prepares us to learn proper weights because:\n",
                "1. Size and shape now use same scale\n",
                "2. Values show biological significance\n",
                "3. Weights will reflect true importance\n",
                "\n",
                "Now we're ready to learn! \n",
                "\n",
                "Next, we'll see how to find the perfect weights using these standardised measurements and algebra."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Learning the Right Weights\n",
                "\n",
                "Now that our measurements are standardised, let's understand how our model learns to make diagnoses. \n",
                "\n",
                "Just like a doctor learning to spot cancer, our model needs to learn which clues matter most.\n",
                "\n",
                "### The Training Approach\n",
                "\n",
                "First, we split our data (569 samples) into the training data and the test data. \n",
                "- The Training Data (80%):\n",
                "  - Data used to train the model\n",
                "    - 455 cells with known diagnoses\n",
                "\n",
                "- The Testing Data (20%):\n",
                "  - Data used to check how good our model is at making predictions\n",
                "    - 114 cells with known diagnoses\n",
                "    - Like the final exam\n",
                "    - The model is not allowed to learn from these\n",
                "\n",
                "\n",
                "\n",
                "### Starting Fresh\n",
                "\n",
                "Just like a new medical student, our model starts with random weights, essentially random guesses about how important each feature is:\n",
                "\n",
                "For our guesses we'll pick small random numbers between -0.5 and 0.5 for each weight and we'll keep bias at 0.\n",
                "\n",
                "```pre\n",
                "weight_size  = 0.3     # Weight for cell size\n",
                "weight_shape = -0.4    # Weight for cell shape\n",
                "bias         = 0       # Base suspicion level (bias)\n",
                "\n",
                "```\n",
                "Why small random numbers?\n",
                "- Not too confident in any feature yet\n",
                "- Room to learn in either direction\n",
                "- Prevents extreme initial predictions\n",
                "\n",
                "**Note: In real production systems, we use the Xavier initialisation to choose our weights.** \n",
                "\n",
                "The Xavier initialisation reduces the size of the weight ranges as the number of features increases.\n",
                "\n",
                "When used with normalised inputs (mean=0, variance=1), this ensures the combined score z always has a variance of 1 around a mean of 0. \n",
                "\n",
                "With this variance:\n",
                "- 68% of z values fall between -1 and +1\n",
                "- 95% of z values fall between -2 and +2\n",
                "- 99.7% of z values fall between -3 and +3\n",
                "\n",
                "This is particularly important for logistic regression because:\n",
                "1. The sigmoid function is most sensitive between -3 and +3\n",
                "2. The steepest gradient on the sigmoid function (which is best for learning) is around 0\n",
                "3. Extreme z values (>|3|) cause vanishing gradients, slowing down training\n",
                "\n",
                "```python\n",
                "# Xavier initialization\n",
                "weight_range = sqrt(2.0 / n_features)\n",
                "weights = random_uniform(-weight_range, weight_range)\n",
                "\n",
                "# Example ranges for different numbers of features:\n",
                "2 features:   random_uniform(-1.000, 1.000)    # sqrt(2/2)   -> Var(z) ≈ 1.000\n",
                "6 features:   random_uniform(-0.577, 0.577)    # sqrt(2/6)   -> Var(z) ≈ 1.001\n",
                "8 features:   random_uniform(-0.500, 0.500)    # sqrt(2/8)   -> Var(z) ≈ 0.999\n",
                "10 features:  random_uniform(-0.447, 0.447)    # sqrt(2/10)  -> Var(z) ≈ 1.002\n",
                "14 features:  random_uniform(-0.378, 0.378)    # sqrt(2/14)  -> Var(z) ≈ 0.998\n",
                "18 features:  random_uniform(-0.333, 0.333)    # sqrt(2/18)  -> Var(z) ≈ 1.001\n",
                "```\n",
                "\n",
                "Going forward our example will stick with simple random numbers between -0.5 and 0.5 to make learning clearer!\n",
                "\n",
                "### Making Our First Prediction\n",
                "\n",
                "Let's look at how we predict for a single cell:\n",
                "```pre\n",
                "Example Cell #127:\n",
                "Size  = +2.1σ                                     # Much bigger than normal\n",
                "Shape = +1.9σ                                     # Very irregular shape\n",
                "\n",
                "\n",
                "1. Gather Evidence:\n",
                "   - Size is 2.1 standard deviations high\n",
                "   - Shape is 1.9 standard deviations irregular\n",
                "\n",
                "2. Multiple each feature by intial weight:\n",
                "   weight_size  = 0.3                             # Random intial weight for cell size\n",
                "   weight_shape = -0.4                            # Random intial Weight for cell shape\n",
                "\n",
                "   size_score  = 0.3 × 2.1  = 0.63\n",
                "   shape_score = -0.4 × 1.9 = -0.76\n",
                "\n",
                "3. Combine Evidence:\n",
                "   Bias = 0\n",
                "   \n",
                "   total_score (z) = size_score + shape_score + bias\n",
                "                   = 0.63 + (-0.76) + 0\n",
                "                   = -0.13\n",
                "```\n",
                "\n",
                "### Converting Score to Probability\n",
                "\n",
                "Now we have a score (z) = -0.13, but what does that mean? We need to convert it to a probability between 0 and 1.\n",
                "\n",
                "Nature gives us the perfect function for this - the sigmoid:\n",
                "## $ p = \\frac{1}{1 + e^{-z}} $\n",
                "```pre\n",
                "Where:\n",
                "- e is Euler's number (≈ 2.71828)\n",
                "- z is our score (-0.13)\n",
                "```\n",
                "\n",
                "For our example:\n",
                "## $ p = \\frac{1}{1 + e^{0.13}} $\n",
                "## $ = \\frac{1}{1 + 1.139} $\n",
                "## $ = \\frac{1}{2.139} $\n",
                "## $ = 0.47 $\n",
                "```pre\n",
                "Translation: \n",
                "- \"47% chance of cancer\"\n",
                "-  Our decision boundary is 0.5 = 50%\n",
                "-  So we predict benign / not cancer.\n",
                "```\n",
                "\n",
                "### Reality Check\n",
                "\n",
                "Now we compare to the truth:\n",
                "```pre\n",
                "Predicted: 47% chance of cancer\n",
                "Actual: Was cancer (100%)\n",
                "```\n",
                "\n",
                "**We were wrong!**\n",
                "\n",
                "But... how wrong exactly?\n",
                "\n",
                "This brings us to the most important question: How do we measure wrongness?\n",
                "\n",
                "### Converting Error to Loss\n",
                "\n",
                "Let's start with the simplest measure of being wrong - absolute distance, the bigger the number the worse the error:\n",
                "\n",
                "```pre\n",
                "Simple Distance Error = |Actual outcome - Predicted outcome|\n",
                "```\n",
                "\\\n",
                "**When the sample is cancer (y=1):**\n",
                "\n",
                "If the doctor says: \"1% chance cancer\" (p = 0.01)\n",
                "```pre\n",
                "Error = |1 - 0.01| = 0.99\n",
                "```\n",
                "\n",
                "If the doctor says: \"50% chance cancer\" (p = 0.50)\n",
                "```pre  \n",
                "Error = |1 - 0.50| = 0.50\n",
                "```\n",
                "\n",
                "If the doctor says: \"99% chance cancer\" (p = 0.99)\n",
                "```pre\n",
                "Error = |1 - 0.99| = 0.01\n",
                "```\n",
                "\\\n",
                "\\\n",
                "**When the sample is healthy (y=0):**\n",
                "\n",
                "If the doctor says: \"1% chance cancer\" (p = 0.01)\n",
                "```pre\n",
                "Error = |0 - 0.01| = 0.01\n",
                "``` \n",
                "\n",
                "If the doctor says: \"50% chance cancer\" (p = 0.50) \n",
                "```pre\n",
                "Error = |0 - 0.50| = 0.50\n",
                "```\n",
                "\n",
                "If the doctor says: \"99% chance cancer\" (p = 0.99)\n",
                "```pre\n",
                "Error = |0 - 0.99| = 0.99\n",
                "```\n",
                "\n",
                "#### Simple distance error vs model confidence visualisation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate predictions from 0 to 1\n",
                "probability_of_cancer_array = np.linspace(0.001, 0.999, 1000)\n",
                "\n",
                "# Calculate mistakes for cancer case (y=1)\n",
                "error_where_is_cancer_array = np.abs(1 - probability_of_cancer_array)\n",
                "\n",
                "# Calculate mistakes for healthy case (y=0)\n",
                "error_where_is_healthy_array = np.abs(0 - probability_of_cancer_array)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(probability_of_cancer_array, error_where_is_cancer_array, 'r-', label='Actually Cancer (y=1)')\n",
                "plt.plot(probability_of_cancer_array, error_where_is_healthy_array, 'g-', label='Actually Healthy (y=0)')\n",
                "\n",
                "plt.title('Prediction Error vs Model Confidence\\nError increases when model is confidently wrong')\n",
                "plt.xlabel('Predicted Probability of Cancer (p)')\n",
                "plt.ylabel('Prediction error: \\n Error = |Actual - Predicted|')\n",
                "\n",
                "# Add annotations\n",
                "plt.annotate('Doctor says 1% cancer\\nwhen actually cancer\\n Error = 0.99', \n",
                "             xy=(0.01, 0.99), xytext=(0.2, 0.8),\n",
                "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
                "\n",
                "# Make grid more visible with custom properties\n",
                "plt.grid(True, color='gray', linestyle='-', alpha=0.3)\n",
                "\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Simple distance error has three fundamental problems:\n",
                "\n",
                "1. **Same Gradient Everywhere**\n",
                "   - With absolute distance, moving from 0.1 to 0.0 (small error)\n",
                "     gives the same guidance as moving from 0.9 to 0.8 (large error)\n",
                "   - Both tell the model \"change your weights by the same amount\"\n",
                "   - Like a coach who always just shouts \"FASTER!\" whether you're running 1% below \n",
                "     target pace or 50% below target pace\n",
                "\n",
                "2. **Unstable Training**\n",
                "   - Because the gradient of our prediction vs prediction error line is linear, the model takes fixed-size steps\n",
                "   - Like seasoning soup with only a teaspoon: \n",
                "     - too big a step when nearly perfect and we miss the target\n",
                "     - too small when completely unsalted (takes forever)\n",
                "\n",
                "3. **Weak Penalties for Bad Predictions**\n",
                "   - Being 90% confident and wrong should be punished more than being 51% confident and wrong\n",
                "   - Example: If the doctor says \"i'm 100% sure it's not cancer\" when it is cancer this outcome should be penalized more heavily than \"i'm 51% sure it's not cancer\"\n",
                "   - Simple distance treats these the same\n",
                "\n",
                "#### Let's try squaring the error to solve these problems:\n",
                "```pre\n",
                "Squared Error = (Actual outcome - Predicted outcome)²\n",
                "```\n",
                "\n",
                "**Examples when Actually Cancer (y=1)**\n",
                "\n",
                "Doctor says: \"1% chance cancer\" (p = 0.01)\n",
                "```pre  \n",
                "Error = (1 - 0.01)² = 0.98\n",
                "```\n",
                "\n",
                "Doctor says: \"50% chance cancer\" (p = 0.50)\n",
                "```pre\n",
                "Error = (1 - 0.50)² = 0.25\n",
                "```\n",
                "\n",
                "Doctor says: \"99% chance cancer\" (p = 0.99)\n",
                "```pre\n",
                "Error = (1 - 0.99)² = 0.0001\n",
                "```\n",
                "\n",
                "#### Squared distance error vs model confidence visualisation\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate squared mistakes\n",
                "squared_errors_cancer = (1 - probability_of_cancer_array)**2\n",
                "squared_errors_healthy = (0 - probability_of_cancer_array)**2\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(probability_of_cancer_array, squared_errors_cancer, 'r-', label='Actually Cancer (y=1)')\n",
                "plt.plot(probability_of_cancer_array, squared_errors_healthy, 'g-', label='Actually Healthy (y=0)')\n",
                "\n",
                "plt.title('Squared Error vs Predicted Probability')\n",
                "plt.xlabel('Predicted Probability of Cancer (p)')\n",
                "plt.ylabel('How big is the error?\\n (Error = (Actual - Predicted)²)')\n",
                "\n",
                "plt.annotate('Doctor says 1% cancer\\nwhen actually cancer\\nError = 0.98', \n",
                "             xy=(0.01, 0.98), xytext=(0.2, 0.8),\n",
                "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
                "\n",
                "# Make grid more visible with custom properties\n",
                "plt.grid(True, color='gray', linestyle='-', alpha=0.3)\n",
                "plt.grid(True)\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Squaring errors `(actual - predicted)²` helps penalize mistakes:\n",
                "- It increases the penalty for confident wrong predictions\n",
                "- It reduces the penalty for confident correct predictions\n",
                "\n",
                "However, the quadratic scaling isn't ideal for classification tasks. When a doctor is very confident but wrong, we need a much stronger penalty than squared error provides.\n",
                "\n",
                "### Logarithmic Loss\n",
                "\n",
                "Log loss provides exponential penalties for confident mistakes, making it ideal for classification tasks like medical diagnosis:\n",
                "\n",
                "```python\n",
                "Log Loss = -log(p)         # when actually cancer\n",
                "Log Loss = -log(1-p)       # when actually healthy\n",
                "```\n",
                "Examples when Actually Cancer (y=1):\n",
                "\n",
                "Doctor says: \"1% chance cancer\" (p = 0.01)\n",
                "```python\n",
                "Loss = -log(0.01) = 4.61   # HUGE penalty!\n",
                "```\n",
                " \n",
                "Doctor says: \"50% chance cancer\" (p = 0.50)\n",
                "```python\n",
                "Loss = -log(0.50) = 0.69   # Medium penalty\n",
                "``` \n",
                " \n",
                "Doctor says: \"99% chance cancer\" (p = 0.99)\n",
                "```python\n",
                "Loss = -log(0.99) = 0.01   # Tiny penalty\n",
                "```\n",
                "\n",
                "#### Error/Loss types vs model confidence visualisation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate log loss\n",
                "log_loss_cancer = -np.log(probability_of_cancer_array)\n",
                "log_loss_healthy = -np.log(1-probability_of_cancer_array)\n",
                "\n",
                "# Create figure with 2 subplots\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
                "\n",
                "# Plot 1: Compare all three measures for cancer case\n",
                "ax1.plot(probability_of_cancer_array, error_where_is_cancer_array, 'g-', label='Simple Distance', alpha=0.5)\n",
                "ax1.plot(probability_of_cancer_array, squared_errors_cancer, 'b-', label='Squared Error', alpha=0.5)\n",
                "ax1.plot(probability_of_cancer_array, log_loss_cancer, 'r-', label='Log Loss', alpha=0.5)\n",
                "\n",
                "ax1.set_title('Comparison of Different Measures\\nWhen Actually Cancer (y=1)')\n",
                "ax1.set_xlabel('Predicted Probability of Cancer (p)')\n",
                "ax1.set_ylabel('Penalty')\n",
                "ax1.set_ylim(0, 5)\n",
                "ax1.grid(True)\n",
                "ax1.legend()\n",
                "\n",
                "# Plot 2: Log Loss for both cases\n",
                "ax2.plot(probability_of_cancer_array, log_loss_cancer, 'r-', label='Actually Cancer (y=1)')\n",
                "ax2.plot(probability_of_cancer_array, log_loss_healthy, 'g-', label='Actually Healthy (y=0)')\n",
                "\n",
                "ax2.set_title('Binary Cross-Entropy Loss')\n",
                "ax2.set_xlabel('Predicted Probability of Cancer (p)')\n",
                "ax2.set_ylabel('Loss = -log(p) or -log(1-p)')\n",
                "ax2.set_ylim(0, 5)\n",
                "\n",
                "ax2.annotate('Doctor says 1% cancer\\nwhen actually cancer\\nLoss = 4.61!', \n",
                "             xy=(0.01, 4.61), xytext=(0.2, 3.5),\n",
                "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
                "\n",
                "ax2.grid(True)\n",
                "ax2.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Binary Cross-Entropy Loss\n",
                "\n",
                "Binary Cross-Entropy Loss is the most common loss function for binary classification problems.\n",
                "\n",
                "It combines two logarithmic loss terms to measure the difference between predicted probabilities and true labels, accounting for both positive (y=1) and negative (y=0) outcomes. \n",
                "\n",
                "When y=1, it measures how close the prediction is to 1 using -log(p), and when y=0, it measures how close the prediction is to 0 using -log(1-p). These terms are combined into a single loss function:\n",
                "\n",
                "#### Binary Cross-Entropy Loss Formula\n",
                "#### $Loss(y,p) = -(y \\log(p) + (1-y)\\log(1-p))$\n",
                "\n",
                "where:\n",
                "- $y$ is the true label (0 or 1)\n",
                "- $p$ is the predicted probability\n",
                "- $Loss$ is the resulting loss\n",
                "\n",
                "\n",
                "Looking at the graphs, we can see key properties:\n",
                "\n",
                "1. Infinite Punishment for Confident Mistakes\n",
                "   When Actually Cancer (y=1):\n",
                "   ```pre\n",
                "   p → 0:  Loss → ∞\n",
                "   ```\n",
                "   When Actually Healthy (y=0):\n",
                "   ```pre\n",
                "   p → 1:  Loss → ∞\n",
                "   ```\n",
                "\n",
                "2. Reward for Appropriate Confidence\n",
                "   When Actually Cancer (y=1):\n",
                "   ```pre\n",
                "   p = 0.99:  Loss = 0.01  (Excellent!)\n",
                "   p = 0.50:  Loss = 0.69  (Meh)\n",
                "   p = 0.01:  Loss = 4.61  (Terrible!)\n",
                "   ```\n",
                "\n",
                "3. Smooth Gradients for Learning\n",
                "   ```python\n",
                "   - No sudden jumps or cliffs\n",
                "   - Clear direction for improvement\n",
                "   - Always differentiable (good for calculus)\n",
                "   ```\n",
                "\n",
                "Note: In practice, we must clip our probability values to prevent numerical instability:\n",
                "```python\n",
                "# Clip probability values to prevent numerical instability in the loss function\n",
                "# Lower bound: epsilon (tiny positive number) prevents log(0) which is -∞\n",
                "# Upper bound: (1-epsilon) prevents log(1-1) which is also log(0)\n",
                "epsilon = 1e-15\n",
                "p = np.clip(p, epsilon, 1 - epsilon)\n",
                "\n",
                "# Now our loss will stay within computable bounds\n",
                "loss = -(y * np.log(p) + (1-y) * np.log(1-p))\n",
                "```\n",
                "\n",
                "### Asymmetric Loss: When Mistakes Aren't Equal\n",
                "\n",
                "In medical diagnosis, missing cancer is worse than a false alarm. We can modify our loss function:\n",
                "\n",
                "```python\n",
                "# First clip probabilities for numerical stability\n",
                "epsilon = 1e-15\n",
                "p = np.clip(p, epsilon, 1 - epsilon)\n",
                "\n",
                "# Then apply asymmetric weights\n",
                "alpha = 10.0  # Cost of missing cancer\n",
                "beta = 1.0    # Cost of false alarm\n",
                "\n",
                "# Calculate asymmetric loss\n",
                "asymmetric_loss = -(alpha * y * np.log(p) + beta * (1-y) * np.log(1-p))\n",
                "```\n",
                "\n",
                "### Visualising Asymmetric Loss vs Regular Binary Cross-Entropy Loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def asymmetric_cross_entropy(p, y, alpha=10.0, beta=1.0):\n",
                "    \"\"\"Calculate asymmetric binary cross-entropy loss\"\"\"\n",
                "    return -(alpha * y * np.log(p) + beta * (1-y) * np.log(1-p))\n",
                "\n",
                "# Generate predictions from 0.001 to 0.999 (avoid log(0))\n",
                "p = np.linspace(0.001, 0.999, 1000)\n",
                "\n",
                "# Calculate regular and asymmetric loss\n",
                "loss_cancer = -(1 * np.log(p))  # Regular BCE for y=1\n",
                "loss_healthy = -(1 * np.log(1-p))  # Regular BCE for y=0\n",
                "loss_cancer_asym = asymmetric_cross_entropy(p, y=1, alpha=10.0, beta=1.0)\n",
                "loss_healthy_asym = asymmetric_cross_entropy(p, y=0, alpha=10.0, beta=1.0)\n",
                "\n",
                "# Create comparison plot\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
                "\n",
                "# Regular BCE\n",
                "ax1.plot(p, loss_cancer, 'r-', label='Actually Cancer', linewidth=2)\n",
                "ax1.plot(p, loss_healthy, 'b-', label='Actually Healthy', linewidth=2)\n",
                "ax1.set_title('Step 1: Regular Binary Cross-Entropy\\nEqual penalties for both types of mistakes')\n",
                "ax1.set_xlabel('Predicted Probability of Cancer (p)')\n",
                "ax1.set_ylabel('Loss')\n",
                "ax1.grid(True, alpha=0.3)\n",
                "ax1.legend()\n",
                "\n",
                "# Add key points annotations for regular BCE\n",
                "ax1.annotate('High cost for\\nconfident mistakes', \n",
                "            xy=(0.05, 3), xytext=(0.2, 3.5),\n",
                "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
                "ax1.annotate('Symmetric penalties\\nfor both classes', \n",
                "            xy=(0.5, 0.7), xytext=(0.6, 1.5),\n",
                "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
                "\n",
                "# Asymmetric BCE (α=10, β=1)\n",
                "ax2.plot(p, loss_cancer_asym, 'r-', label='Actually Cancer (10x weight)', linewidth=2)\n",
                "ax2.plot(p, loss_healthy_asym, 'b-', label='Actually Healthy', linewidth=2)\n",
                "ax2.set_title('Step 2: Asymmetric Binary Cross-Entropy\\nMissing Cancer 10x More Costly')\n",
                "ax2.set_xlabel('Predicted Probability of Cancer (p)')\n",
                "ax2.set_ylabel('Loss')\n",
                "ax2.grid(True, alpha=0.3)\n",
                "ax2.legend()\n",
                "\n",
                "# Add key points annotations for asymmetric BCE\n",
                "ax2.annotate('10x higher penalty for\\nmissing cancer', \n",
                "            xy=(0.1, 20), xytext=(0.3, 30),\n",
                "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
                "ax2.annotate('Regular penalty for\\nfalse alarms', \n",
                "            xy=(0.9, 2), xytext=(0.5, 9),\n",
                "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Looking at the asymmetric plot:\n",
                "1. Missing Cancer (right plot, red line)\n",
                "   - Confident mistakes punished 10x more severely\n",
                "   - This forces the model to be extra careful about cancer cases\n",
                "\n",
                "2. False Alarms (right plot, blue line)\n",
                "   - Predicting Cancer when it is not cancer is still punished, but less severely\n",
                "   - This may be an acceptable trade-off if it helps catch more cancer cases\n",
                "\n",
                "In practice:\n",
                "- Regular BCE works well for balanced problems\n",
                "- Asymmetric BCE when mistakes have different costs\n",
                "- Medical diagnosis often uses asymmetric loss\n",
                "\n",
                "Now that we understand how to measure our model's mistakes using loss functions, let's explore how the model actually learns from these errors."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Gradient Descent: Learning from our Errors\n",
                "\n",
                "Back to our initial example, of our doctor learning to diagnose cancer. \n",
                "\n",
                "We know two things:\n",
                "1. We can measure how wrong we are using the loss function\n",
                "2. We want to adjust each weight of our model to be less wrong than the value it was set to previously\n",
                "\n",
                "### Step 1: Starting position and \"the forward pass\"\n",
                "\n",
                "Our model combines features using weights and adds a bias term:\n",
                "\n",
                "### $z = weight_1 \\times feature_1 + weight_2 \\times feature_2 + ... + weight_n \\times feature_n + bias$\n",
                "\n",
                "Initial random weights:\n",
                "```pre\n",
                "weight_size  = 0.3             # Weight for cell size\n",
                "weight_shape = -0.4            # Weight for cell shape\n",
                "bias      = 0.0                # Bias term\n",
                "```\n",
                "\n",
                "Input features (Standardised):\n",
                "```pre\n",
                "size  = +2.1σ                  # Much bigger than normal (2.1 standard deviations from mean)\n",
                "shape = +1.9σ                  # Very irregular (1.9 standard deviations from mean)\n",
                "truth = 1                      # Actually cancer\n",
                "\n",
                "Note: σ (sigma) represents standard deviation, which measures spread of data\n",
                "```\n",
                "\n",
                "### $z = weight_1 \\times feature_1 + weight_2 \\times feature_2 + ... + weight_n \\times feature_n + bias$\n",
                "```pre\n",
                "z = (0.3 × 2.1) + (-0.4 × 1.9) + 0\n",
                "  = 0.63 - 0.76\n",
                "  = -0.13                      # This is our score\n",
                "```\n",
                "The bias term is like a \"baseline suspicion level\" - it determines how likely we are to predict cancer even before looking at any measurements. Just as we'll learn the right weights for each feature, we'll also learn the right bias to help minimise our model's loss.\n",
                "\n",
                "### Step 2: Sigmoid Activation - Making a Prediction\n",
                "\n",
                "### $p = \\frac{1}{1 + e^{-z}}$\n",
                "\n",
                "\n",
                "```pre\n",
                "p = 1/(1 + e^(-(-0.13)))      # Convert score to probability using z = -0.13\n",
                "  = 1/(1 + e^(0.13))          # Simplify negative of negative\n",
                "  = 0.47                      # 47% chance of cancer (class 1)\n",
                "                              # Or 53% chance of benign (class 0)\n",
                "                              # Since p < 0.5, predict benign\n",
                "\n",
                "```\n",
                "Note: Model is unsure (close to 0.5)\n",
                "We'll use symmetric loss (equal penalty for false positives and negatives)\n",
                "\n",
                "### Step 3: Measuring the Error\n",
                "\n",
                "Binary cross-entropy loss formula:\n",
                "### $Loss = -(y \\log(p) + (1-y) \\log(1-p))$\n",
                "\n",
                "Where:\n",
                "```pre\n",
                "y = 1        # True label (cancer)\n",
                "p = 0.47     # Predicted probability of cancer\n",
                "```\n",
                "\n",
                "```pre\n",
                "loss = -(y * log(p) + (1-y) * log(1-p))\n",
                "     = -(1 * log(0.47) + (1-1) * log(1-0.47))\n",
                "     = -(1 * log(0.47) + 0 * log(1-0.47))\n",
                "     = -(log(0.47) + 0)\n",
                "     = 0.755\n",
                "```\n",
                "\n",
                "If it had been benign (y=0):\n",
                "```pre\n",
                "loss = -(0 * log(0.47) + 1 * log(1-0.47))\n",
                "     = -(0 + log(0.53))\n",
                "     = 0.635  # Smaller loss because prediction\n",
                "              # was slightly correct (53% benign)\n",
                "              # But still uncertain (close to 50%)\n",
                "```\n",
                "\n",
                "### Step 4: Calculating the Gradient of loss for each parameter\n",
                "\n",
                "To know how to adjust our weights and bias, we need to calculate the gradient (slope) of the loss with respect to each parameter.\n",
                "\n",
                "Note: ∂ (partial derivative) shows how one variable changes when we adjust another while holding other variables constant\n",
                "\n",
                "The gradient tells us:\n",
                "1. In which direction to move each parameter (positive/negative) to reduce our prediction error.\n",
                "2. How big of a step to take (magnitude) to reduce our prediction error.\n",
                "\n",
                "For weights, the gradient equation is:\n",
                "## $ \\frac{\\partial Loss}{\\partial weight_i} = (predicted\\_outcome - actual\\_outcome) * feature\\_input\\_value $\n",
                "\n",
                "For bias, the gradient equation is simpler:\n",
                "## $ \\frac{\\partial Loss}{\\partial bias} = (predicted\\_outcome - actual\\_outcome) $\n",
                "\n",
                "Let's calculate for our example:\n",
                "\n",
                "```pre\n",
                "predicted_outcome = 0.47    # Our prediction\n",
                "actual_outcome = 1          # Actually cancer\n",
                "```\n",
                "\n",
                "Gradient of Loss with respect to the Weight of size:\n",
                "```pre\n",
                "feature_input_value = 2.1\n",
                "∂Loss/∂w_size       = (0.47 - 1) * 2.1\n",
                "                    = -0.53 * 2.1\n",
                "                    = -1.113\n",
                "```\n",
                "\n",
                "Gradient of Loss with respect to the Weight of shape:\n",
                "```pre\n",
                "feature_input_value = 1.9\n",
                "∂Loss/∂w_shape      = (0.47 - 1) * 1.9\n",
                "                    = -0.53 * 1.9\n",
                "                    = -1.007\n",
                "```\n",
                "\n",
                "Gradient of Loss with respect to bias:\n",
                "```pre\n",
                "∂Loss/∂b            = (0.47 - 1)\n",
                "                    = -0.53\n",
                "```\n",
                "\n",
                "These formulae are derived using the chain rule. For both weights and bias:\n",
                "\n",
                "1. Loss is a function of probability: $Loss(y,p) = -(y \\log(p) + (1-y)\\log(1-p))$\n",
                "2. Probability is a function of score: $probability = \\frac{1}{1 + e^{-score}}$\n",
                "3. Score is a function of weights and bias: $score = w_1 \\cdot input_1 + w_2 \\cdot input_2 + bias$\n",
                "\n",
                "This creates a chain of dependencies:\n",
                "weights/bias → score → probability → loss\n",
                "\n",
                "To find how changes in weights affect loss, we multiply these relationships together using the chain rule.\n",
                "\n",
                "**Gradient of Loss with respect to the Weight:**\n",
                "## $ \\frac{\\partial Loss}{\\partial weight} = \\frac{\\partial Loss}{\\partial probability} * \\frac{\\partial probability}{\\partial score} * \\frac{\\partial score}{\\partial weight} $\n",
                "## $ \\frac{\\partial Loss}{\\partial weight} = \\frac{\\partial Loss}{\\cancel{\\partial prob}} * \\frac{\\cancel{\\partial prob}}{\\cancel{\\partial score}} * \\frac{\\cancel{\\partial score}}{\\partial weight} $\n",
                "\n",
                "**Gradient of Loss with respect to bias:**\n",
                "## $ \\frac{\\partial Loss}{\\partial bias} = \\frac{\\partial Loss}{\\partial probability} * \\frac{\\partial probability}{\\partial score} * \\frac{\\partial score}{\\partial bias} $\n",
                "## $ \\frac{\\partial Loss}{\\partial bias} = \\frac{\\partial Loss}{\\cancel{\\partial prob}} * \\frac{\\cancel{\\partial prob}}{\\cancel{\\partial score}} * \\frac{\\cancel{\\partial score}}{\\partial bias} $\n",
                "\n",
                "The next section dives into how we derived these formulas by finding the derivatives of each of our functions and simplifying using the chain rule.\n",
                "\n",
                "Feel free to skip to the next section if you're not interested in the derivation math.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4 - the calculus: How gradient of loss with respect to each parameter is derived using the Chain Rule\n",
                "\n",
                "\n",
                " | Differentiation Rules | Formulae |\n",
                " |-----------|---------|\n",
                " | Sum Rule | $ \\frac{d}{dx}[f(x) + g(x)] = \\frac{d}{dx}f(x) + \\frac{d}{dx}g(x) $  |\n",
                " | Constant Multiple Rule |  $ \\frac{d}{dx}[c \\cdot f(x)] = c \\cdot \\frac{d}{dx}f(x) $  |\n",
                " | Product Rule | $  \\frac{d}{dx}[f(x)g(x)] = f'(x)g(x) + f(x)g'(x) $ |\n",
                " | Chain Rule |  $ \\frac{d}{dx}f(g(x)) = f'(g(x)) \\cdot g'(x) $  |\n",
                " | Log Rule |  $ \\frac{d}{dx}\\log(x) = \\frac{1}{x} $  |\n",
                " | Exponential Rule |  $ \\frac{d}{dx}e^x = e^x $  |\n",
                " | Quotient Rule |  $ \\frac{d}{dx}[\\frac{f(x)}{g(x)}] = \\frac{f'(x)g(x) - f(x)g'(x)}{[g(x)]^2} $  |\n",
                "\n",
                "\n",
                "#### 1. Loss with respect to Probability: ($\\frac{\\partial Loss}{\\partial probability}$)\n",
                "\n",
                "$ Loss = -(y \\cdot \\log(probability) + (1-y)\\log(1-probability)) $\n",
                "\n",
                "##### **Differentiate term 1 - using Constant Multiple Rule and Log Rule:** \n",
                "##### $ -y \\cdot \\log(probability) $\n",
                "\n",
                "##### $ \\frac{\\partial}{\\partial probability}(-y \\cdot \\log(probability)) = -y \\cdot \\frac{1}{probability} $                                          \n",
                "##### $ \\frac{\\partial}{\\partial probability}(-y \\cdot \\log(probability)) = \\frac{-y}{probability} $                                                  \n",
                "\n",
                "##### **Differentiate Term 2 - using Constant Multiple Rule and Chain Rule:**\n",
                "#####  $-(1-y)\\log(1-probability)$\n",
                "\n",
                "##### $\\frac{\\partial}{\\partial probability}[-(1-y)\\log(1-probability)] = -(1-y) \\cdot \\frac{\\partial}{\\partial probability}[\\log(1-probability)]$   \n",
                "\n",
                "##### $\\frac{\\partial}{\\partial probability}[-(1-y)\\log(1-probability)] = -(1-y) \\cdot [\\frac{1}{1-probability} \\cdot \\frac{\\partial}{\\partial probability}(1-probability)]$                                           \n",
                "\n",
                "##### $\\frac{\\partial}{\\partial probability}[-(1-y)\\log(1-probability)] = -(1-y) \\cdot [\\frac{1}{1-probability} \\cdot (-1)]$                                                                                           \n",
                "\n",
                "##### $\\frac{\\partial}{\\partial probability}[-(1-y)\\log(1-probability)] = \\frac{1-y}{1-probability}$                                                                                                                   \n",
                "\n",
                "##### **Combining terms using Sum Rule:**\n",
                "\n",
                "##### $ \\frac{\\partial Loss}{\\partial probability} = \\frac{-y}{probability} + \\frac{1-y}{1-probability}$                                             \n",
                "\n",
                "---\n",
                "\n",
                "#### 2. Probability with respect to Score: ($\\frac{\\partial probability}{\\partial score}$)\n",
                "\n",
                "##### $ probability = \\frac{1}{1 + e^{-score}}$\n",
                "\n",
                "##### **Using Quotient Rule: $\\frac{d}{dx}[\\frac{f(x)}{g(x)}] = \\frac{f'(x)g(x) - f(x)g'(x)}{[g(x)]^2}$**\n",
                "\n",
                "##### $ \\frac{\\partial probability}{\\partial score} = \\frac{(0)(1 + e^{-score}) - (1)(-e^{-score})}{(1 + e^{-score})^2}$\n",
                "\n",
                "##### $ \\frac{\\partial probability}{\\partial score} = \\frac{0 - (-e^{-score})}{(1 + e^{-score})^2}$\n",
                "\n",
                "##### $ \\frac{\\partial probability}{\\partial score} = \\frac{e^{-score}}{(1 + e^{-score})^2}$\n",
                "\n",
                "##### $ \\frac{\\partial probability}{\\partial score} = \\frac{1}{1 + e^{-score}} \\cdot \\frac{e^{-score}}{1 + e^{-score}}$\n",
                "\n",
                "##### $ \\frac{\\partial probability}{\\partial score} = probability \\cdot \\frac{e^{-score}}{1 + e^{-score}}$\n",
                "\n",
                "##### $ \\frac{\\partial probability}{\\partial score} = probability \\cdot \\frac{1 + e^{-score} - 1}{1 + e^{-score}}$\n",
                "\n",
                "##### $ \\frac{\\partial probability}{\\partial score} = probability \\cdot (\\frac{1 + e^{-score}}{1 + e^{-score}} - \\frac{1}{1 + e^{-score}})$\n",
                "\n",
                "##### $ \\frac{\\partial probability}{\\partial score} = probability \\cdot (1 - \\frac{1}{1 + e^{-score}})$\n",
                "\n",
                "##### $ \\frac{\\partial probability}{\\partial score} = probability \\cdot (1-probability)$\n",
                "\n",
                "---\n",
                "\n",
                "#### 3. Score with respect to Weight ($\\frac{\\partial score}{\\partial weight}$)\n",
                "\n",
                "##### $ score = weight_1 \\cdot input_1 + weight_2 \\cdot input_2 + bias $\n",
                "\n",
                "##### **Using Sum Rule: The derivative of a sum is the sum of derivatives**\n",
                "\n",
                "##### $ \\frac{\\partial score}{\\partial weight_1} = \\frac{\\partial}{\\partial weight_1}(weight_1 \\cdot input_1) + \\frac{\\partial}{\\partial weight_1}(weight_2 \\cdot input_2) + \\frac{\\partial}{\\partial weight_1}(bias) $\n",
                "\n",
                "##### $ \\frac{\\partial score}{\\partial weight_1} = input_1 \\cdot \\frac{\\partial}{\\partial weight_1}(weight_1) + input_2 \\cdot \\frac{\\partial}{\\partial weight_1}(weight_2) + \\frac{\\partial}{\\partial weight_1}(bias) $\n",
                "\n",
                "##### $ \\frac{\\partial score}{\\partial weight_1} = input_1 \\cdot 1 + input_2 \\cdot 0 + 0 $\n",
                "\n",
                "##### $ \\frac{\\partial score}{\\partial weight_1} = input_1 $\n",
                "\n",
                "---\n",
                "\n",
                "#### 4. Score with respect to Bias ($\\frac{\\partial score}{\\partial bias}$)\n",
                "\n",
                "##### $ score = weight_1 \\cdot input_1 + weight_2 \\cdot input_2 + bias $\n",
                "\n",
                "##### **Using Sum Rule: The derivative of a sum is the sum of derivatives**\n",
                "\n",
                "##### $ \\frac{\\partial score}{\\partial bias} = \\frac{\\partial}{\\partial bias}(weight_1 \\cdot input_1) + \\frac{\\partial}{\\partial bias}(weight_2 \\cdot input_2) + \\frac{\\partial}{\\partial bias}(bias) $\n",
                "\n",
                "##### $ \\frac{\\partial score}{\\partial bias} = 0 + 0 + \\frac{\\partial}{\\partial bias}(bias) $\n",
                "\n",
                "##### $ \\frac{\\partial score}{\\partial bias} = 1 $\n",
                "\n",
                "---\n",
                "#### Putting it all together using the chain rule:\n",
                "\n",
                "#### For weights: \n",
                "#### $\\frac{\\partial Loss}{\\partial weight} = \\frac{\\partial Loss}{\\partial probability} \\cdot \\frac{\\partial probability}{\\partial score} \\cdot \\frac{\\partial score}{\\partial weight_1}$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial weight_1} = (\\frac{-y}{probability} + \\frac{1-y}{1-probability}) \\cdot probability(1-probability) \\cdot input_1$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial weight_1} = (\\frac{-y \\cdot probability(1-probability)}{probability} + \\frac{(1-y) \\cdot probability(1-probability)}{1-probability}) \\cdot input_1$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial weight_1} = (\\frac{-y \\cdot \\cancel{probability}(1-probability)}{\\cancel{probability}} + \\frac{(1-y) \\cdot probability(\\cancel{1-probability})}{\\cancel{1-probability}}) \\cdot input_1$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial weight_1} = (-y(1-probability) + (1-y)probability) \\cdot input_1$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial weight_1} = (-y + \\cancel{yprobability} + probability - \\cancel{yprobability}) \\cdot input_1$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial weight_1} = (-y + probability) \\cdot input_1$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial weight_1} = (probability - y) \\cdot input_1$\n",
                "\n",
                "#### For bias:\n",
                "#### $\\frac{\\partial Loss}{\\partial bias} = \\frac{\\partial Loss}{\\partial probability} \\cdot \\frac{\\partial probability}{\\partial score} \\cdot \\frac{\\partial score}{\\partial bias}$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial bias} = (\\frac{-y}{probability} + \\frac{1-y}{1-probability}) \\cdot probability(1-probability) \\cdot 1$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial bias} = (\\frac{-y \\cdot probability(1-probability)}{probability} + \\frac{(1-y) \\cdot probability(1-probability)}{1-probability}) \\cdot 1$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial bias} = (\\frac{-y \\cdot \\cancel{probability}(1-probability)}{\\cancel{probability}} + \\frac{(1-y) \\cdot probability(\\cancel{1-probability})}{\\cancel{1-probability}}) \\cdot 1$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial bias} = (-y(1-probability) + (1-y)probability) \\cdot 1$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial bias} = (-y + \\cancel{yprobability} + probability - \\cancel{yprobability}) \\cdot 1$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial bias} = (-y + probability) \\cdot 1$\n",
                "\n",
                "#### $\\frac{\\partial Loss}{\\partial bias} = (probability - y)$\n",
                "\n",
                "#### Therefore our final results are:\n",
                "#### $\\frac{\\partial Loss}{\\partial weight_i} = (probability - true\\_label) \\cdot input_i$\n",
                "#### $\\frac{\\partial Loss}{\\partial bias} = (probability - true\\_label)$\n",
                "\n",
                "Where y is the true label of the sample and p is the predicted probability of the sample.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Back to Our Implementation\n",
                "\n",
                "The beauty is that whether we have one feature or a thousand, one patient or a million, our core update rules stay the same:\n",
                "```python\n",
                "gradient_of_loss_with_respect_to_weight = (predicted_probability - true_label) * feature_input_value\n",
                "gradient_of_loss_with_respect_to_bias = (predicted_probability - true_label)\n",
                "```\n",
                "\n",
                "### Step 4: Calculate the Gradient using the derived formula! - the backwards pass\n",
                "\n",
                "Recapping on our previous calculations, we calculated the gradient (slope) of the loss with respect to each parameter:\n",
                "\n",
                "```pre\n",
                "For our example, where:\n",
                "- predicted_probability = 0.47             # 47% cancer\n",
                "- true_label            = 1                # is cancer\n",
                "- feature_value         = 2.1              # for feature: size\n",
                "\n",
                "∂Loss/∂w_size           = (0.47 - 1) * 2.1\n",
                "                        = -0.53 * 2.1\n",
                "                        = -1.113\n",
                "\n",
                "∂Loss/∂w_shape          = (0.47 - 1) * 1.9\n",
                "                        = -0.53 * 1.9\n",
                "                        = -1.007\n",
                "\n",
                "∂Loss/∂bias            = (0.47 - 1)\n",
                "                        = -0.53\n",
                "```\n",
                "\n",
                "### Step 5: Calculating the amount to update each parameter by\n",
                "\n",
                "We adjust each parameter in the opposite direction of its gradient because the gradient indicates how the loss would change if we slightly increased each parameter.\n",
                "\n",
                "The learning rate controls how big of a step we take in that direction. For now we'll choose 0.1 as its big enough to learn quickly and small enough to not overshoot the optimal solution. \n",
                "\n",
                "We'll explore how to choose this value optimally later.\n",
                "\n",
                "```pre\n",
                "learning_rate          = 0.1               # How big of steps to take\n",
                "\n",
                "w_size_update_amount   = learning_rate * -(∂Loss/∂w_size)\n",
                "                       = 0.1 * -(-1.113)\n",
                "                       = 0.1113\n",
                "\n",
                "w_shape_update_amount  = learning_rate * -(∂Loss/∂w_shape)\n",
                "                       = 0.1 * -(-1.007)\n",
                "                       = 0.1007\n",
                "\n",
                "bias_update_amount     = learning_rate * -(∂Loss/∂bias)\n",
                "                       = 0.1 * -(-0.53)\n",
                "                       = 0.053\n",
                "```\n",
                "\n",
                "### Step 6: Updating the Parameters\n",
                "```pre\n",
                "updated_w_size         = old_w_size + w_size_update_amount\n",
                "                       = 0.3 + 0.1113\n",
                "                       = 0.4113\n",
                "\n",
                "updated_w_shape        = old_w_shape + w_shape_update_amount\n",
                "                       = -0.4 + 0.1007\n",
                "                       = -0.2993\n",
                "\n",
                "updated_bias          = old_bias + bias_update_amount\n",
                "                       = 0 + 0.053\n",
                "                       = 0.053\n",
                "```\n",
                "\n",
                "### Second Pass - Step 1 again:\n",
                "\n",
                "Let's see if our updated parameters work better:\n",
                "\n",
                "```pre\n",
                "new_z                  = (updated_w_size × 2.1) + (updated_w_shape × 1.9) + updated_bias\n",
                "                       = (0.4113 × 2.1) + (-0.2993 × 1.9) + 0.053\n",
                "                       = 0.864 - 0.569 + 0.053\n",
                "                       = 0.348\n",
                "\n",
                "new_p                  = 1/(1 + e^(-0.348))\n",
                "                       = 0.586                 # Now predicts cancer! (58.6%)\n",
                "```\n",
                "\n",
                "The addition of bias helps by:\n",
                "1. Shifting all predictions up slightly (by 0.053)\n",
                "2. Learning the base rate of cancer in the population\n",
                "3. Making the model more flexible - it can learn both feature importance (weights) and general tendency (bias)\n",
                "\n",
                "### The Learning Process\n",
                "\n",
                "<img src=\"../static/images/logistic-regression-cycle.png\" alt=\"Logistic Regression Cycle\" width=\"800\">\n",
                "\n",
                "Each iteration consists of:\n",
                "\n",
                "The forward pass:\n",
                "\n",
                "1. Compute score (z) from features, weights and bias\n",
                "2. Convert score to probability using sigmoid\n",
                "3. Calculate loss\n",
                "\n",
                "The backward pass:\n",
                "\n",
                "4. Compute gradients for each parameter\n",
                "5. Calculate update amounts using learning rate\n",
                "6. Update parameters in opposite direction of gradients\n",
                "\n",
                "Rinse, Repeat for a set number of epochs (iterations)\n",
                "\n",
                "With each iteration:\n",
                "- Parameters gradually improve\n",
                "- Predictions get more accurate\n",
                "- Loss decreases\n",
                "\n",
                "This is how our model learns from experience, just like a doctor seeing many patients and learning which signs matter most and how common cancer is in general.\n",
                "\n",
                "Now let's see how to turn this elegant math into working code...\n",
                "\n",
                "## Implementing Logistic Regression: From Theory to Code\n",
                "\n",
                "Below is a basic implementation of logistic regression from scratch. This implementation is a simplified version of the logistic regression model we will be using in our practical lesson. We'll run it on the same breast cancer dataset we used in our practical lesson. We'll explore the dataset in more detail in our practical lesson but for now a basic understanding of the dataset is all we need.\n",
                "\n",
                "The Wisconsin Breast Cancer Dataset is a classic dataset used for binary classification tasks. It consists of 569 samples with 30 features each, including measurements like radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, fractal dimension, and more. The target variable is binary, indicating whether the cancer is malignant (1) or benign (0).\n",
                "\n",
                "A display of the dataset is included prior to running our model in the implementation below to help you understand the structure of the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Manual train-test split\n",
                "def train_test_split_with_stratification(features: np.ndarray, labels: np.ndarray, test_size: float = 0.2, random_seed: int = 42) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
                "    \"\"\"\n",
                "    Manually split data into training and testing sets with optional stratification.\n",
                "    \n",
                "    Args:\n",
                "        features: A 2D numpy array where each inner array represents one sample's features.\n",
                "                 Shape: (n_samples, n_features) where each value is a feature measurement.\n",
                "                 Example: [[1.2, 0.5, 3.1],  # First sample's 3 features\n",
                "                          [0.8, 1.2, 2.2]]   # Second sample's 3 features\n",
                "        labels: An array containing the labels that match each row of the input features\n",
                "        test_size: The proportion of the data to use for testing, ranging from 0 to 1\n",
                "        random_seed: A number used to ensure the results are reproducible\n",
                "        stratify: A boolean indicating whether to maintain the same proportion of classes in the split (default is True)\n",
                "    \n",
                "    Returns:\n",
                "        train_features, test_features, train_labels, test_labels\n",
                "    \"\"\"\n",
                "    np.random.seed(random_seed)\n",
                "    n_samples = len(features)\n",
                "    \n",
                "\n",
                "    # Get unique label names in this case \"0\" and \"1\" from the labels array\n",
                "    unique_labels = np.unique(labels)\n",
                "\n",
                "    # Create a dictionary that maps each unique label to the row indices where it appears. \n",
                "    # note: np.where returns a tuple of arrays, hence np.where()[0]\n",
                "    label_indices = {label: np.where(labels == label)[0] for label in unique_labels}\n",
                "    \n",
                "    # Calculate number of test samples needed from each class\n",
                "    test_indices = []\n",
                "    for label in unique_labels:\n",
                "        label_count = len(label_indices[label])\n",
                "        n_test_for_label = int(label_count * test_size)\n",
                "        \n",
                "        # Randomly select indices for this class\n",
                "        label_test_indices = np.random.choice(\n",
                "            label_indices[label], \n",
                "            n_test_for_label, \n",
                "            replace=False\n",
                "        )\n",
                "        test_indices.extend(label_test_indices)\n",
                "\n",
                "    \n",
                "    # Create boolean mask: \n",
                "    # 1. Create an array of zeros the length of the number of samples\n",
                "    # 2. Set array indices that are the test samples to true and split data\n",
                "    is_test = np.zeros(n_samples, dtype=bool)\n",
                "    is_test[test_indices] = True\n",
                "    \n",
                "    # Split the data using the boolean mask:\n",
                "    # ~is_test inverts the mask (True becomes False and vice versa)\n",
                "    # Features/labels where mask is True go to test set\n",
                "    # Features/labels where mask is False go to train set\n",
                "    train_features = features[~is_test]\n",
                "    test_features = features[is_test]\n",
                "    train_labels = labels[~is_test]\n",
                "    test_labels = labels[is_test]\n",
                "    \n",
                "    return train_features, test_features, train_labels, test_labels\n",
                "\n",
                "# Manual standardisation\n",
                "def standardise_features(train_features: np.ndarray, test_features: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
                "    \"\"\"\n",
                "    Manually standardize features to normal distribution using training set statistics.\n",
                "    \n",
                "    Args:\n",
                "        train_features: Training set features\n",
                "        test_features: Test set features\n",
                "    \n",
                "    Returns:\n",
                "        standardized_train, standardized_test, means, stds\n",
                "    \"\"\"\n",
                "    # Calculate mean and standard deviation from training data\n",
                "    feature_means = np.mean(train_features, axis=0)\n",
                "    feature_standard_deviations = np.std(train_features, axis=0)\n",
                "    \n",
                "    # Avoid division by zero\n",
                "    # note: in thise case np.where returns an array\n",
                "    feature_standard_deviations = np.where(feature_standard_deviations == 0, 1e-7, feature_standard_deviations)\n",
                "    \n",
                "    # Standardize both sets using training statistics\n",
                "    standardized_train = (train_features - feature_means) / feature_standard_deviations\n",
                "    standardized_test = (test_features - feature_means) / feature_standard_deviations\n",
                "    \n",
                "    return standardized_train, standardized_test, feature_means, feature_standard_deviations\n",
                "\n",
                "class SimpleLogisticRegression:\n",
                "    \"\"\"A basic implementation of logistic regression for binary classification.\n",
                "    \n",
                "    This class implements logistic regression from scratch to help understand the core concepts.\n",
                "    It uses gradient descent to learn the optimal weights and bias for classification.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, learning_rate: float = 0.1) -> None:\n",
                "        \"\"\"Initialize the model with a learning rate.\n",
                "        \n",
                "        Args:\n",
                "            learning_rate:  How big of steps to take during gradient descent.\n",
                "                            Smaller values (like 0.01) mean slower but more stable learning.\n",
                "                            Larger values (like 0.5) mean faster but potentially unstable learning.\n",
                "        \"\"\"\n",
                "        self.learning_rate = learning_rate\n",
                "        self.model_weights = None  # Will store the weights (w₁, w₂, etc.) after training\n",
                "        self.model_bias = None     # Will store the bias term (b) after training\n",
                "        \n",
                "    def calculate_linear_scores(self, feature_matrix: Union[List[List[float]], NDArray[np.float64]]) -> NDArray[np.float64]:\n",
                "        \"\"\"Calculate raw linear scores (z) for input features using weights and bias.\n",
                "        z = w₁x₁ + w₂x₂ + ... + b\n",
                "        \"\"\"\n",
                "        # Convert input to numpy array if needed\n",
                "        if not isinstance(feature_matrix, np.ndarray):\n",
                "            feature_matrix = np.array(feature_matrix)\n",
                "        \n",
                "        # Check if model has been trained\n",
                "        if self.model_weights is None or self.model_bias is None:\n",
                "            raise ValueError(\"Model needs to be trained first!\")\n",
                "        \n",
                "\n",
                "        # Calculate scores for all samples - (z = w₁x₁ + w₂x₂ + ... + b)\n",
                "        # - Multiply each feature value by its weight and sum (matrix multiplication)\n",
                "        # - Add bias term to each sample's score\n",
                "        return np.dot(feature_matrix, self.model_weights) + self.model_bias\n",
                "    \n",
                "    def convert_scores_to_probabilities(self, scores: NDArray[np.float64]) -> NDArray[np.float64]:\n",
                "        \"\"\"Convert raw linear scores to probabilities using sigmoid function.\n",
                "        probability = 1 / (1 + e^(-z))\n",
                "        \"\"\"\n",
                "        safe_scores = np.clip(scores, -500, 500)  # Prevent numerical overflow\n",
                "        return 1 / (1 + np.exp(-safe_scores))\n",
                "    \n",
                "    def calculate_probabilities(self, feature_matrix: Union[List[List[float]], NDArray[np.float64]]) -> NDArray[np.float64]:\n",
                "        \"\"\"Calculate prediction probabilities for input features.\"\"\"\n",
                "        scores = self.calculate_linear_scores(feature_matrix)\n",
                "        return self.convert_scores_to_probabilities(scores)\n",
                "\n",
                "    def train_model(self, feature_matrix: Union[List[List[float]], NDArray[np.float64]], \n",
                "                   target_values: Union[List[float], NDArray[np.float64]], \n",
                "                   num_epochs: int = 100, \n",
                "                   show_progress: bool = False) -> List[float]:\n",
                "        \"\"\"\n",
                "        This function trains the logistic regression model on the provided training data. \n",
                "        It takes in a feature matrix, target values, the number of epochs to train for, and an optional flag to show progress updates. \n",
                "        The function iterates through the training data for the specified number of epochs\n",
                "        Each epoch the function determines the binary cross-entropy loss for the current weights and bias\n",
                "        Then uses gradient descent to calculate the gradient of the loss with respect to the weights and bias\n",
                "        It updates the weights and bias for the next gradient descent pass\n",
                "        It returns a list of loss values at each epoch, which can be used to monitor the model's training progress.\n",
                "        \n",
                "        Args:\n",
                "            feature_matrix: Training features\n",
                "            target_values: True labels (0 or 1)\n",
                "            num_epochs: Number of training iterations\n",
                "            show_progress: Whether to print progress updates\n",
                "            \n",
                "        Returns:\n",
                "            List of loss values during training\n",
                "        \"\"\"\n",
                "        # Convert inputs to numpy arrays\n",
                "        feature_matrix = np.array(feature_matrix)\n",
                "        target_values = np.array(target_values)\n",
                "            \n",
                "        # Initialize weights using He initialization for better training\n",
                "        num_features = feature_matrix.shape[1]\n",
                "        self.model_weights = np.random.randn(num_features) * np.sqrt(2.0 / num_features)\n",
                "        self.model_bias = 0.0\n",
                "        \n",
                "        training_loss_history = []\n",
                "        \n",
                "        print(f\"Training model for {num_epochs} epochs...\")\n",
                "        for epoch in range(num_epochs):\n",
                "            # Step 1: Calculate an array of prediction values for each sample row from the matrix of feature values using the weights and bias present on the class\n",
                "            predictions = self.calculate_probabilities(feature_matrix)\n",
                "            \n",
                "            # Step 2: Ensure numerical stability when calculating loss \n",
                "            epsilon = 1e-15  # Small number to prevent log(0)\n",
                "            predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
                "            \n",
                "            # Step 3: Calculate gradients\n",
                "            \n",
                "            # For weight gradients: (1/num_samples) * features_transposed * (predicted_probabilities - true_labels)\n",
                "            # 1. feature_matrix = [n_samples_rows × n_features_columns]\n",
                "            # 2. feature_matrix.T = Transposes the feature matrix so each row is now a feature, aligning it with the prediction values array\n",
                "            # 3. (predictions - target_values) = We calculate the error of each sample by subtracting the target values array from the predictions values array\n",
                "            # 4. np.dot multiplies each feature's values by the sample errors and sums them, giving total error contribution for each feature\n",
                "            # 5. Lastly we divide each gradient in the matrix by the number of samples to get the average gradient for each feature\n",
                "            average_weight_gradients = np.dot(feature_matrix.T, (predictions - target_values)) / len(target_values)\n",
                "            \n",
                "            # For bias: (1/num_samples) * (predictions - target_values)\n",
                "            average_bias_gradient = np.mean(predictions - target_values)\n",
                "            \n",
                "            # Step 4: the weight for each feature and the bias are updated by subtracting the learning rate multiplied by the average gradient for each feature and bias\n",
                "            self.model_weights -= self.learning_rate * average_weight_gradients\n",
                "            self.model_bias -= self.learning_rate * average_bias_gradient\n",
                "            \n",
                "            # Step 5: Calculate and store loss\n",
                "            # Using binary cross-entropy loss: -y*log(p) - (1-y)*log(1-p)\n",
                "            binary_cross_entropy_per_sample = -(\n",
                "                target_values * np.log(predictions) + \n",
                "                (1 - target_values) * np.log(1 - predictions)\n",
                "            )\n",
                "            \n",
                "            average_loss_this_epoch = float(np.mean(binary_cross_entropy_per_sample))\n",
                "            \n",
                "            training_loss_history.append(average_loss_this_epoch)\n",
                "            \n",
                "            # Print progress if requested\n",
                "            if show_progress and (epoch + 1) % 100 == 0:\n",
                "                print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss_this_epoch:.4f}\")\n",
                "        \n",
                "        return training_loss_history\n",
                "\n",
                "    def predict_binary_classes(self, feature_matrix: Union[List[List[float]], NDArray[np.float64]], \n",
                "                             threshold: float = 0.5) -> NDArray[np.int64]:\n",
                "        \"\"\"Convert probability predictions to binary (0/1) predictions based on a threshold with default of 0.5\"\"\"\n",
                "        probabilities = self.calculate_probabilities(feature_matrix)\n",
                "        return (probabilities >= threshold).astype(int)\n",
                "\n",
                "\n",
                "# Load the data\n",
                "cancer_data = load_breast_cancer()\n",
                "feature_data, target_labels = cancer_data.data, cancer_data.target\n",
                "\n",
                "# Display the DataFrame\n",
                "df = pd.DataFrame(\n",
                "    feature_data[:5],  # First 5 rows\n",
                "    columns=cancer_data.feature_names  # Column names\n",
                ")\n",
                "print(\"\\nWisconsin Breast Cancer Data Scaled:\")\n",
                "display(df)\n",
                "\n",
                "# train-test split the data\n",
                "train_features, test_features, train_labels, test_labels = train_test_split_with_stratification(\n",
                "    feature_data, target_labels, test_size=0.2, random_seed=42\n",
                ")\n",
                "\n",
                "# Standardize the data fitting to normal distribution\n",
                "train_features_scaled, test_features_scaled, feature_means, feature_stds = standardise_features(\n",
                "    train_features, test_features\n",
                ")\n",
                "\n",
                "# Display the Normalised DataFrame\n",
                "df_scaled = pd.DataFrame(\n",
                "    train_features_scaled[:5],  # First 5 rows\n",
                "    columns=cancer_data.feature_names  # Column names\n",
                ")\n",
                "print(\"\\nWisconsin Breast Cancer Data Normalised:\")\n",
                "display(df_scaled)\n",
                "\n",
                "# Create and train the model with standardized data\n",
                "cancer_classifier = SimpleLogisticRegression(learning_rate=0.01)\n",
                "training_loss_history = cancer_classifier.train_model(\n",
                "    train_features_scaled, train_labels, \n",
                "    num_epochs=1000, \n",
                "    show_progress=True\n",
                ")\n",
                "\n",
                "# Make predictions\n",
                "training_predictions = cancer_classifier.predict_binary_classes(train_features_scaled)\n",
                "testing_predictions = cancer_classifier.predict_binary_classes(test_features_scaled)\n",
                "\n",
                "# Calculate and display accuracy\n",
                "training_accuracy = float(np.mean(training_predictions == train_labels))\n",
                "testing_accuracy = float(np.mean(testing_predictions == test_labels))\n",
                "\n",
                "print(\"\\nModel Performance with Standardized Data:\")\n",
                "print(f\"Training Accuracy: {training_accuracy:.4f}\")\n",
                "print(f\"Testing Accuracy: {testing_accuracy:.4f}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Understanding Our Training Results Through Evaluation\n",
                "\n",
                "Let's analyze what our model achieved with standardized data:\n",
                "\n",
                "```\n",
                "Epoch 100/1000, Loss: 0.2478\n",
                "Epoch 200/1000, Loss: 0.1836\n",
                "Epoch 300/1000, Loss: 0.1558\n",
                "...\n",
                "Epoch 1000/1000, Loss: 0.1037\n",
                "\n",
                "Training Accuracy: 0.9759\n",
                "Testing Accuracy: 0.9735\n",
                "```\n",
                "\n",
                "### Key Outcomes\n",
                "\n",
                "1. **Raw Numbers**: In medical terms, we correctly diagnosed:\n",
                "   - Training: ~98% of cases (455 patients)\n",
                "   - Testing: ~97% of cases (114 new patients)\n",
                "   - Consistently high performance across both sets!\n",
                "\n",
                "2. **Loss Progression**:\n",
                "   - Started relatively low (0.25) - standardization helped initial predictions\n",
                "   - Steady early improvements (0.25 → 0.18)\n",
                "   - Continued refinement (0.18 → 0.10)\n",
                "   - Smooth convergence with minimal fluctuations\n",
                "\n",
                "### Medical Interpretation\n",
                "\n",
                "1. **Training Like a Medical Resident with Standardized Tools**:\n",
                "   - Started with standardized measurements (like calibrated medical equipment)\n",
                "   - Learned patterns efficiently due to normalized feature scales\n",
                "   - Fine-tuned diagnostic skills with consistent metrics\n",
                "   - Achieved near-expert performance\n",
                "\n",
                "2. **Diagnostic Reliability**:\n",
                "   - 97% accuracy on new cases is excellent\n",
                "   - Only ~3% misdiagnosis rate\n",
                "   - But we still need to understand:\n",
                "     - Are errors balanced between false positives and negatives?\n",
                "     - Which type of errors are we making?\n",
                "\n",
                "The dramatic improvement in both accuracy and loss compared to our non-standardized version demonstrates why feature standardization is crucial. By normalizing our features to a standard scale:\n",
                "1. The model learned more efficiently\n",
                "2. Achieved better overall performance\n",
                "3. Showed more stable training progression\n",
                "\n",
                "To fully understand our model's clinical value, we need to examine:\n",
                "1. Different types of diagnostic errors\n",
                "2. How to measure each type\n",
                "3. What these measurements mean for patient care\n",
                "\n",
                "Let's explore these evaluation concepts..."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Basic Evaluation Concepts\n",
                "\n",
                "When evaluating a binary classification model like our cancer detector, we need multiple metrics to fully understand its performance. Let's break down each key metric:\n",
                "\n",
                "### 1. Accuracy\n",
                "The proportion of correct predictions among all predictions:\n",
                "```python\n",
                "Accuracy = (True Positives + True Negatives) / Total Predictions\n",
                "```\n",
                "\n",
                "Example: If our model correctly identifies 90 out of 100 tumors, the accuracy is 90%.\n",
                "\n",
                "### 2. Precision \n",
                "The proportion of correct positive predictions among all positive predictions:\n",
                "```python\n",
                "Precision = True Positives / (True Positives + False Positives)\n",
                "```\n",
                "\n",
                "Example: If our model predicts \"cancer\" for 50 patients and is right for 45 of them:\n",
                "```python\n",
                "Precision = 45 / 50 = 90%\n",
                "```\n",
                "High precision means few false alarms.\n",
                "\n",
                "### 3. Recall (Sensitivity)\n",
                "The proportion of actual positives correctly identified:\n",
                "```python\n",
                "Recall = True Positives / (True Positives + False Negatives)\n",
                "```\n",
                "\n",
                "Example: If there are 60 actual cancer cases and our model finds 54 of them:\n",
                "```python\n",
                "Recall = 54 / 60 = 90%\n",
                "```\n",
                "High recall means few missed cancers.\n",
                "\n",
                "### 4. F1 Score\n",
                "The harmonic mean of precision and recall:\n",
                "```python\n",
                "F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
                "```\n",
                "\n",
                "Example scenarios:\n",
                "```python\n",
                "Scenario 1:\n",
                "- Precision = 80% (accurate cancer predictions)\n",
                "- Recall = 60% (catching most cancers)\n",
                "- F1 = 2 * (0.8 * 0.6) / (0.8 + 0.6) = 0.69\n",
                "\n",
                "Scenario 2:\n",
                "- Precision = 70% \n",
                "- Recall = 70%\n",
                "- F1 = 2 * (0.7 * 0.7) / (0.7 + 0.7) = 0.70\n",
                "```\n",
                "F1 score balances precision and recall.\n",
                "\n",
                "### The Four Possible Outcomes\n",
                "\n",
                "1. **True Positive (TP)** - Correct Cancer Diagnosis\n",
                "   ```python\n",
                "   prediction = \"Cancer\" (1)\n",
                "   reality    = \"Cancer\" (1)\n",
                "   example: Catching a malignant tumor\n",
                "   ```\n",
                "\n",
                "2. **True Negative (TN)** - Correct Healthy Diagnosis\n",
                "   ```python\n",
                "   prediction = \"Healthy\" (0)\n",
                "   reality    = \"Healthy\" (0)\n",
                "   example: Confirming a benign tumor\n",
                "   ```\n",
                "\n",
                "3. **False Positive (FP)** - False Alarm\n",
                "   ```python\n",
                "   prediction = \"Cancer\" (1)\n",
                "   reality    = \"Healthy\" (0)\n",
                "   example: Unnecessary biopsy\n",
                "   cost: Patient anxiety, medical expenses\n",
                "   ```\n",
                "\n",
                "4. **False Negative (FN)** - Missed Cancer\n",
                "   ```python\n",
                "   prediction = \"Healthy\" (0)\n",
                "   reality    = \"Cancer\" (1)\n",
                "   example: Missed malignant tumor\n",
                "   cost: Delayed treatment, potentially fatal\n",
                "   ```\n",
                "\n",
                "### The Problem with Simple Accuracy\n",
                "\n",
                "Consider two models on 100 patients (20 with cancer, 80 healthy):\n",
                "\n",
                "```pre\n",
                "Model A: 97% Accuracy\n",
                "- Catches 17/20 cancers\n",
                "- Correctly identifies 80/80 healthy\n",
                "- Accuracy = (17 + 80)/100 = 97%\n",
                "- But misses 3 cancers!\n",
                "\n",
                "Model B: 95% Accuracy\n",
                "- Catches 19/20 cancers\n",
                "- Correctly identifies 76/80 healthy\n",
                "- Accuracy = (19 + 76)/100 = 95%\n",
                "- Only misses 1 cancer\n",
                "```\n",
                "\n",
                "In medical contexts, Model B might be preferable despite lower accuracy because missing cancer (false negatives) is more dangerous than false alarms (false positives).\n",
                "\n",
                "### The Confusion Matrix\n",
                "\n",
                "To visualize all these metrics at once, we use a confusion matrix:\n",
                "\n",
                "```pre\n",
                "                  Predicted\n",
                "               Healthy │ Cancer\n",
                "Actual  Healthy   TN   │   FP\n",
                "        Cancer    FN   │   TP\n",
                "```\n",
                "\n",
                "Example confusion matrix for Model B:\n",
                "```pre\n",
                "                  Predicted\n",
                "               Healthy │ Cancer\n",
                "Actual  Healthy   76   │   4\n",
                "        Cancer     1   │   19\n",
                "```\n",
                "\n",
                "From this matrix we can calculate:\n",
                "- Accuracy = (76 + 19)/100 = 95%\n",
                "- Precision = 19/(19 + 4) = 83%\n",
                "- Recall = 19/(19 + 1) = 95%\n",
                "- F1 Score = 2 * (0.83 * 0.95)/(0.83 + 0.95) = 0.88"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate and display detailed evaluation metrics\n",
                "def analyze_and_plot_results():\n",
                "    # Calculate confusion matrix and metrics\n",
                "    cm = confusion_matrix(test_labels, testing_predictions)\n",
                "    tn, fp, fn, tp = cm.ravel()\n",
                "    \n",
                "    # Calculate all metrics\n",
                "    metrics = {\n",
                "        'Precision': precision_score(test_labels, testing_predictions),\n",
                "        'Recall': recall_score(test_labels, testing_predictions),\n",
                "        'F1 Score': f1_score(test_labels, testing_predictions),\n",
                "        'Accuracy': accuracy_score(test_labels, testing_predictions)\n",
                "    }\n",
                "    \n",
                "    # Print detailed analysis\n",
                "    print(\"Detailed Model Evaluation Results:\")\n",
                "    print(\"-\" * 40)\n",
                "    print(\"\\nConfusion Matrix Details:\")\n",
                "    print(f\"True Negatives (Correct Benign):     {tn}\")\n",
                "    print(f\"False Positives (False Alarms):      {fp}\")\n",
                "    print(f\"False Negatives (Missed Cancers):    {fn}\")\n",
                "    print(f\"True Positives (Caught Cancers):     {tp}\")\n",
                "    \n",
                "    print(\"\\nPerformance Metrics:\")\n",
                "    for metric, value in metrics.items():\n",
                "        print(f\"{metric:15} {value:.4f}\")\n",
                "    \n",
                "    # Calculate and print medical impact rates\n",
                "    false_negative_rate = fn / (fn + tp)\n",
                "    false_positive_rate = fp / (fp + tn)\n",
                "    \n",
                "    print(\"\\nMedical Impact Analysis:\")\n",
                "    print(f\"Miss Rate:         {false_negative_rate:.1%} of cancers missed\")\n",
                "    print(f\"False Alarm Rate:  {false_positive_rate:.1%} of healthy cases\")\n",
                "    \n",
                "    # Create figure with two subplots\n",
                "    plt.figure(figsize=(15, 6))\n",
                "    \n",
                "    # Plot 1: Confusion Matrix (left subplot)\n",
                "    plt.subplot(1, 2, 1)\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "                xticklabels=['Benign', 'Malignant'],\n",
                "                yticklabels=['Benign', 'Malignant'])\n",
                "    plt.title('Confusion Matrix', pad=20)\n",
                "    plt.xlabel('Predicted')\n",
                "    plt.ylabel('Actual')\n",
                "    \n",
                "    # Plot 2: Performance Metrics (right subplot)\n",
                "    plt.subplot(1, 2, 2)\n",
                "    bars = plt.bar(metrics.keys(), metrics.values())\n",
                "    plt.title('Model Performance Metrics', pad=20)\n",
                "    plt.ylim(0, 1.1)  # Give some space for value labels\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    \n",
                "    # Add value labels on bars\n",
                "    for bar in bars:\n",
                "        height = bar.get_height()\n",
                "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
                "                f'{height:.3f}',\n",
                "                ha='center', va='bottom')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    return metrics, false_negative_rate, false_positive_rate\n",
                "\n",
                "# Generate visualization and store results\n",
                "metrics, miss_rate, false_alarm_rate = analyze_and_plot_results()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Understanding Our Model's Performance\n",
                "\n",
                "Let's analyze what these numbers mean for real-world medical diagnosis:\n",
                "\n",
                "### The Good News\n",
                "\n",
                "1. **Perfect Precision (1.000)**\n",
                "   - Zero false alarms (no false positives)\n",
                "   - Every time we predict cancer, we're right\n",
                "   - Means no unnecessary biopsies or patient anxiety\n",
                "\n",
                "2. **Strong Overall Accuracy (94.74%)**\n",
                "   - 108 correct diagnoses out of 114 cases\n",
                "   - Performing well above random chance (50%)\n",
                "   - Comparable to human expert performance\n",
                "\n",
                "### The Challenges\n",
                "\n",
                "1. **Recall/Sensitivity (0.915)**\n",
                "   - Caught 65 cancers, but missed 6\n",
                "   - 8.5% miss rate on malignant cases\n",
                "   - Each miss could be life-threatening\n",
                "\n",
                "2. **Diagnosis Breakdown**\n",
                "   ```\n",
                "   Total Cases:  114\n",
                "   - Benign:     43 (all correct)\n",
                "   - Malignant:  71 (65 caught, 6 missed)\n",
                "   ```\n",
                "\n",
                "### Clinical Implications\n",
                "\n",
                "1. **Conservative Diagnosis**\n",
                "   - Model only flags clear cancer cases\n",
                "   - No false alarms means high trustworthiness\n",
                "   - But might be too cautious\n",
                "\n",
                "2. **Room for Improvement**\n",
                "   - 6 missed cancers is still too many\n",
                "   - Need to catch more cancers without sacrificing precision\n",
                "   - Could adjust decision threshold\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "These results suggest two key areas for investigation:\n",
                "\n",
                "1. **Learning Rate Impact**\n",
                "   - Could different learning rates catch more cancers?\n",
                "   - Is our current rate (0.01) optimal?\n",
                "   - Would faster learning help or hurt?\n",
                "\n",
                "2. **Decision Threshold**\n",
                "   - Currently using 0.5 as threshold\n",
                "   - Could lower threshold catch more cancers?\n",
                "   - What's the precision-recall tradeoff?\n",
                "\n",
                "Let's explore how different learning rates affect these metrics..."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compare_learning_rates():\n",
                "    # Define learning rates to test\n",
                "    learning_rates = [1.0, 0.001, 0.1, 0.01]\n",
                "    results = []\n",
                "    \n",
                "    # Create figure for two plots\n",
                "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
                "    \n",
                "    print(\"Learning Rate Comparison Results:\\n\")\n",
                "    print(f\"{'Learning Rate':>12} {'Final Loss':>12} {'Accuracy':>10} {'Miss Rate':>10}\")\n",
                "    print(\"-\" * 50)\n",
                "    \n",
                "    # Test each learning rate\n",
                "    for lr in learning_rates:\n",
                "        # Train model\n",
                "        model = SimpleLogisticRegression(learning_rate=lr)\n",
                "        loss_history = model.train_model(\n",
                "            train_features_scaled, \n",
                "            train_labels,\n",
                "            num_epochs=1000,\n",
                "            show_progress=False\n",
                "        )\n",
                "        \n",
                "        # Get predictions\n",
                "        test_preds = model.predict_binary_classes(test_features_scaled)\n",
                "        \n",
                "        # Calculate metrics\n",
                "        accuracy = accuracy_score(test_labels, test_preds)\n",
                "        cm = confusion_matrix(test_labels, test_preds)\n",
                "        fn = cm[1][0]  # False negatives\n",
                "        tp = cm[1][1]  # True positives\n",
                "        miss_rate = fn / (fn + tp)\n",
                "        \n",
                "        # Store results\n",
                "        results.append({\n",
                "            'lr': lr,\n",
                "            'loss_history': loss_history,\n",
                "            'final_loss': loss_history[-1],\n",
                "            'accuracy': accuracy,\n",
                "            'miss_rate': miss_rate\n",
                "        })\n",
                "        \n",
                "        print(f\"{lr:12.3f} {loss_history[-1]:12.4f} {accuracy:10.3f} {miss_rate:9.1%}\")\n",
                "        \n",
                "        # Plot learning curves with semi-transparent colours\n",
                "        if lr == 1.0:\n",
                "            ax1.plot(loss_history, label=f'lr={lr}', color='#4C72B0', alpha=0.8)  # Deep blue\n",
                "        elif lr == 0.001:\n",
                "            ax1.plot(loss_history, label=f'lr={lr}', color='orange', alpha=0.3)  # Burnt orange\n",
                "        elif lr == 0.1:\n",
                "            ax1.plot(loss_history, label=f'lr={lr}', color='#55A868', alpha=0.8)  # Forest green\n",
                "        elif lr == 0.01:\n",
                "            ax1.plot(loss_history, label=f'lr={lr}', color='#C44E52', alpha=0.5)  # Deep red\n",
                "            \n",
                "    # Configure loss plot\n",
                "    ax1.set_xlabel('Epoch')\n",
                "    ax1.set_ylabel('Binary Cross-Entropy Loss')\n",
                "    ax1.set_title('Training Loss Over Time')\n",
                "    ax1.legend()\n",
                "    ax1.grid(True, alpha=0.3)\n",
                "    \n",
                "    # Highlight convergence region of optimal rate\n",
                "    ax1.axvspan(500, 600, color='green', alpha=0.1, label='Convergence Region')\n",
                "    ax1.annotate('Optimal Rate\\nConverges Here', \n",
                "                xy=(550, 3), \n",
                "                xytext=(400, 1.5),\n",
                "                arrowprops=dict(facecolor='orange', shrink=0.05))\n",
                "    \n",
                "    # Plot comparison metrics\n",
                "    metrics = np.array([(r['accuracy'], 1-r['miss_rate']) for r in results])\n",
                "    x = np.arange(len(learning_rates))\n",
                "    width = 0.35\n",
                "    \n",
                "    ax2.bar(x - width/2, metrics[:, 0], width, label='Accuracy', color='lightblue' )\n",
                "    ax2.bar(x + width/2, metrics[:, 1], width, label='Cancer Detection Rate', color='lightgreen')\n",
                "    \n",
                "    # Configure metrics plot\n",
                "    ax2.set_xticks(x)\n",
                "    ax2.set_xticklabels([f'lr={lr}' for lr in learning_rates])\n",
                "    ax2.set_ylabel('Score')\n",
                "    ax2.set_title('Model Performance vs Learning Rate')\n",
                "    ax2.legend()\n",
                "    ax2.grid(True, alpha=0.3)\n",
                "    \n",
                "    # Add value labels on bars\n",
                "    for i in range(len(learning_rates)):\n",
                "        ax2.text(i - width/2, metrics[i,0], f'{metrics[i,0]:.3f}', \n",
                "                 ha='center', va='bottom')\n",
                "        ax2.text(i + width/2, metrics[i,1], f'{metrics[i,1]:.3f}', \n",
                "                 ha='center', va='bottom')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    return results\n",
                "\n",
                "# Run comparison and store results\n",
                "lr_comparison_results = compare_learning_rates()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Understanding Learning Rate Effects\n",
                "\n",
                "Just like a doctor learning to read medical scans, our model's learning speed (controlled by the learning rate) dramatically affects how well it learns to spot cancer. Let's decode the fascinating patterns in our training graphs:\n",
                "\n",
                "### Reading the Loss Curves\n",
                "\n",
                "Our training plots reveal four distinct learning patterns:\n",
                "\n",
                "1. **Large Learning Rate (lr=1.0, blue)**:\n",
                "   - Bold, confident steps in learning\n",
                "   - Like a resident who quickly grasps key patterns\n",
                "   - Achieves remarkably low final loss (0.0496)\n",
                "   - Outstanding accuracy of 98.2%\n",
                "\n",
                "2. **Medium Learning Rate (lr=0.1, green)**:\n",
                "   - Steady, purposeful learning progression\n",
                "   - Similar to an efficient clinician methodically building expertise\n",
                "   - Very effective final performance (loss: 0.0613)\n",
                "   - Strong 97.3% accuracy \n",
                "\n",
                "3. **Moderate Learning Rate (lr=0.01, red)**:\n",
                "   - More cautious learning approach\n",
                "   - Like a careful practitioner double-checking their assessments\n",
                "   - Higher final loss (0.1107)\n",
                "   - Still achieves good accuracy at 94.7%\n",
                "\n",
                "4. **Small Learning Rate (lr=0.001, orange)**:\n",
                "   - Most conservative learning style\n",
                "   - Akin to an over-cautious doctor requiring extensive confirmation\n",
                "   - Highest final loss (0.2943)\n",
                "   - Shows no advantage over faster learning\n",
                "\n",
                "### Understanding the Clinical Impact\n",
                "\n",
                "Let's translate these numbers into real medical outcomes:\n",
                "\n",
                "```pre\n",
                "Learning Rate │ Accuracy │ Miss Rate │ Clinical Interpretation\n",
                "─────────────┼──────────┼───────────┼──────────────────────────\n",
                "1.0          │ 98.2%    │ 1.4%      │ Almost perfect detection\n",
                "0.1          │ 97.3%    │ 1.4%      │ Equally reliable     \n",
                "0.01         │ 94.7%    │ 5.6%      │ More missed cases\n",
                "0.001        │ 94.7%    │ 5.6%      │ Slow learning, no benefit\n",
                "```\n",
                "\n",
                "In practical terms:\n",
                "- Faster learning rates catch significantly more cancers\n",
                "- Only 1.4% missed cases at higher rates vs 5.6% at lower rates\n",
                "- No false alarms with any rate (perfect precision)\n",
                "\n",
                "### Theoretical Insights vs Clinical Reality\n",
                "\n",
                "Our model's exceptional performance with high learning rates is particularly interesting. In machine learning practice, using rates like 1.0 or 0.1 often leads to unstable training - like a student who jumps to conclusions too quickly. Our implementation achieves unusual stability at high rates because:\n",
                "\n",
                "1. **Well-Structured Problem**\n",
                "   - Binary classification (cancer/no cancer)\n",
                "   - Clean, preprocessed medical data\n",
                "   - Clear decision boundaries\n",
                "\n",
                "2. **Careful Implementation**\n",
                "   - Gradient averaging across batches\n",
                "   - Proper weight initialization\n",
                "   - Numerically stable computations\n",
                "\n",
                "This performance demonstrates how well-structured medical data, combined with careful implementation, can enable surprisingly rapid learning.\n",
                "\n",
                "### Key Lessons About Machine Learning\n",
                "\n",
                "Our experiments reveal three fundamental insights:\n",
                "\n",
                "1. **Speed vs Accuracy Trade-off**\n",
                "   - Faster learning can achieve both quicker convergence and better results\n",
                "   - But stability is crucial - especially in medical applications\n",
                "   - Need to balance speed with reliability\n",
                "\n",
                "2. **The Value of Experimentation**\n",
                "   - Different learning rates reveal different model behaviors\n",
                "   - No universal \"best\" learning rate\n",
                "   - Always test multiple rates for your specific case\n",
                "\n",
                "3. **Clinical Significance**\n",
                "   - Learning rate directly impacts missed diagnoses\n",
                "   - Higher rates (when stable) catch more cancers\n",
                "   - Real-world impact of parameter choices\n",
                "\n",
                "### In Practice: A Note of Caution\n",
                "\n",
                "While our implementation shows excellent performance at high learning rates, most production systems opt for more conservative approaches:\n",
                "\n",
                "- Lower base learning rates (0.01 or 0.001)\n",
                "- Learning rate scheduling (gradually decreasing rates)\n",
                "- Adaptive optimization methods (like Adam or RMSprop)\n",
                "- Multiple training runs with different parameters\n",
                "\n",
                "This conservative approach ensures reliability across:\n",
                "- Different types of medical data\n",
                "- Varying problem complexities\n",
                "- Production deployment scenarios\n",
                "\n",
                "### The Big Picture\n",
                "\n",
                "Just as doctors develop their diagnostic skills at different rates, our model's learning speed significantly impacts its performance. While our implementation demonstrates exceptional stability at high learning rates, the key principles remain:\n",
                "\n",
                "1. Test multiple learning approaches\n",
                "2. Monitor performance carefully\n",
                "3. Prioritize reliability in medical applications\n",
                "4. Let empirical results guide your choices\n",
                "\n",
                "These insights into learning rates complete our understanding of how logistic regression learns from data. Now, let's look back at everything we've created..."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion: Our Journey Through Logistic Regression\n",
                "\n",
                "In this lesson, we've achieved something remarkable: we built a logistic regression classifier completely from scratch, understanding every component from first principles. Let's reflect on this journey and its significance.\n",
                "\n",
                "### Building From Ground Up\n",
                "\n",
                "Starting with nothing but basic Python and NumPy, we created three core elements:\n",
                "\n",
                "1. **A Complete Medical Classifier**  \n",
                "   We built a breast cancer diagnostic system achieving over 97% accuracy on the Wisconsin Breast Cancer dataset. From implementing the sigmoid function to gradient descent calculations, we crafted each component to detect cancer effectively and reliably.\n",
                "\n",
                "2. **Rich Visualization Tools**  \n",
                "   We developed tools to see our model in action, from 2D and 3D decision boundaries to dynamic training visualizations. These visuals helped us understand not just what our model was doing, but why it made specific diagnostic decisions - critical for medical applications.\n",
                "\n",
                "3. **Robust Evaluation Framework**  \n",
                "   We created comprehensive tools to measure our model's clinical performance, helping us understand its strengths and potential improvements. This wasn't just about accuracy - we looked at precision, recall, and how our model performs across different medical scenarios.\n",
                "\n",
                "### Deep Mathematical Understanding\n",
                "\n",
                "Beyond just writing code, we developed a thorough understanding of the mathematical foundations:\n",
                "\n",
                "1. **Core Mathematical Concepts**  \n",
                "   We unraveled complex ideas like the sigmoid function and binary cross-entropy, seeing how these mathematical tools help us make accurate predictions. Each equation became more than just symbols - they became practical tools we could use to detect cancer.\n",
                "\n",
                "2. **Optimization and Data Preparation**  \n",
                "   We explored critical concepts like learning rates, gradient descent, and proper data scaling. We saw how standardizing features to common scales dramatically improves model training and performance - essential for combining diverse medical measurements like cell size and shape.\n",
                "\n",
                "3. **Real-World Applications**  \n",
                "   We learned when to apply logistic regression and how to prepare different types of medical data. These practical insights help us bridge the gap between mathematical theory and real-world medical diagnosis.\n",
                "\n",
                "### Comprehensive Evaluation Framework\n",
                "\n",
                "Our deep dive into model evaluation revealed crucial insights for medical applications:\n",
                "\n",
                "1. **Beyond Simple Accuracy**\n",
                "   - Why 97% accuracy isn't always better than 95%\n",
                "   - The importance of understanding different types of errors\n",
                "   - How to balance false positives against false negatives in medical contexts\n",
                "\n",
                "2. **Critical Medical Metrics**\n",
                "   - Precision: Minimizing unnecessary biopsies\n",
                "   - Recall: Catching as many cancer cases as possible\n",
                "   - F1 Score: Balancing precision and recall for optimal patient care\n",
                "\n",
                "3. **Understanding Error Patterns**\n",
                "   - Using confusion matrices to analyze misdiagnoses\n",
                "   - Identifying which types of cases our model struggles with\n",
                "   - Strategies for improving detection of difficult cases\n",
                "\n",
                "### Understanding Our Implementation's Limitations\n",
                "\n",
                "While building from scratch was incredibly educational, it's important to understand what our implementation can't do yet. Think of it like building a medical device by hand - you learn how everything works, but it won't have all the features of a professional system.\n",
                "\n",
                "Our model's current limitations include:\n",
                "- Binary decisions only (cancer/no cancer)\n",
                "- Basic optimization methods\n",
                "- Limited scalability for large datasets\n",
                "- No built-in cross-validation\n",
                "- Simple learning rate management\n",
                "\n",
                "Modern machine learning libraries offer sophisticated features like:\n",
                "- Multi-class classification\n",
                "- Automated hyperparameter tuning\n",
                "- Efficient large-scale training\n",
                "- Advanced optimization algorithms\n",
                "- Comprehensive validation tools\n",
                "\n",
                "### Looking Ahead to Lesson 1B\n",
                "\n",
                "In our next lesson, we'll build on this foundation by exploring modern machine learning libraries. While our from-scratch implementation taught us the fundamentals, we'll now learn how tools like scikit-learn and PyTorch can help us build more sophisticated medical diagnostic models.\n",
                "\n",
                "We'll focus on practical aspects like:\n",
                "- Using optimized implementations for better performance\n",
                "- Handling larger medical datasets efficiently\n",
                "- Implementing advanced training techniques\n",
                "- Preparing models for clinical deployment\n",
                "- Robust validation for medical applications\n",
                "\n",
                "Next: [1b_logistic_regression_practical.ipynb](./1b_logistic_regression_practical.ipynb)\n",
                "\n",
                "### Further Reading\n",
                "\n",
                "For those interested in diving deeper:\n",
                "\n",
                "1. **Mathematical Foundations**\n",
                "   - \"Introduction to Statistical Learning\" by James, Witten, Hastie, and Tibshirani (Chapter 4)\n",
                "   - \"Pattern Recognition and Machine Learning\" by Bishop (Chapter 4)\n",
                "\n",
                "2. **Practical Implementation**\n",
                "   - Stanford CS229 Course Notes\n",
                "   - Scikit-learn Documentation\n",
                "\n",
                "3. **Advanced Topics**\n",
                "   - \"Deep Learning\" by Goodfellow, Bengio, and Courville (Chapter 6.2)\n",
                "   - \"Machine Learning in Medical Imaging\" by Zhou, Greenspan, and Shen\n",
                "\n",
                "4. **Online Resources**\n",
                "   - [CS231n Stanford Course Notes](http://cs231n.github.io/)\n",
                "   - [Distill.pub's Visual Intro to Machine Learning](https://distill.pub/)\n",
                "   - [Medical ML Best Practices](https://www.nature.com/articles/s41591-018-0300-7)\n",
                "\n",
                "Remember: While building a model from scratch was challenging, it gives us a deep understanding that will serve us well as we move into more advanced medical applications. In the next lesson, we'll see how modern tools can help us build on this foundation while keeping the insights we've gained - always with the goal of improving patient care through better diagnostic tools."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
