{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison: Comparing Tree-Based Models\n",
    "\n",
    "In this notebook, we'll create a model comparison engine  - a way to compare different decision tree-based models and feature combinations. \n",
    "\n",
    "**We'll focus on understanding:**\n",
    "\n",
    "1. How to rigorously compare model performance\n",
    "2. The impact of different feature engineering strategies\n",
    "3. Trade-offs between model complexity and performance\n",
    "4. Best practices for model evaluation and selection\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to Model Comparison](#introduction)\n",
    "2. [Understandingthe Beast Pipeline](#understanding-beast)\n",
    "3. [Feature Engineering Deep Dive](#feature-engineering)\n",
    "4. [Model Comparison Framework](#comparison-framework)\n",
    "5. [Results Analysis & Visualization](#results-analysis)\n",
    "6. [Model Selection Guidelines](#model-selection)\n",
    "7. [Production Considerations](#production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Model Comparison\n",
    "\n",
    "When developing machine learning solutions, we often need to compare different:\n",
    "\n",
    "- Model types (Decision Trees, Random Forests, XGBoost)\n",
    "- Feature engineering strategies\n",
    "- Hyperparameter configurations\n",
    "- Training approaches\n",
    "\n",
    "Since we have LLM's these days we could do this in a systematic way all at once but we'll need to make sure we're doing these comparisons while ensuring:\n",
    "\n",
    "- Fair evaluation conditions\n",
    "- No data leakage\n",
    "- Proper cross-validation\n",
    "- Comprehensive metrics\n",
    "- Statistical significance\n",
    "\n",
    "Let's start by importing the necessary libraries and loading our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning - Core\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    KFold, \n",
    ")\n",
    "\n",
    "# Preprocessing and Encoding\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder\n",
    ")\n",
    "\n",
    "# Models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, \n",
    "    r2_score,\n",
    ")\n",
    "\n",
    "# Advanced ML models\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# System utilities\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import pickle\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '{:,.2f}'.format(x))\n",
    "\n",
    "# Set random seeds\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Load the preprocessed data\n",
    "with open('../data/df_with_outcode.pkl', 'rb') as f:\n",
    "    df_with_outcode = pickle.load(f)\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Shape: {df_with_outcode.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(df_with_outcode.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FeatureSet:\n",
    "    \"\"\"Container for a feature set configuration\"\"\"\n",
    "    X_train: pd.DataFrame\n",
    "    X_val: pd.DataFrame\n",
    "    y_train: pd.Series\n",
    "    y_val: pd.Series\n",
    "    name: str\n",
    "    description: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessor:\n",
    "    \"\"\"Handles initial data transformations and train/test splitting\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state: int = RANDOM_STATE):\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def prepare_pre_split_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Creates features that must be calculated before train/test split\"\"\"\n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        # Log transform price\n",
    "        df_processed['log_price'] = np.log(df_processed['Price'])\n",
    "        \n",
    "        # Create price bands for stratification\n",
    "        df_processed['price_band'] = pd.qcut(df_processed['log_price'], q=10, labels=False)\n",
    "        \n",
    "        return df_processed\n",
    "    \n",
    "    def create_train_test_split(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Performs stratified train/test split using price bands\"\"\"\n",
    "        train_data, test_data = train_test_split(\n",
    "            df,\n",
    "            test_size=0.2,\n",
    "            stratify=df['price_band'],\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        return train_data, test_data\n",
    "\n",
    "print(\"PreProcessor class loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEncoder:\n",
    "    \"\"\"Handles all feature engineering and encoding with fold awareness\"\"\"\n",
    "    \n",
    "    def __init__(self, smoothing_factor: int = 10, min_location_freq: int = 5, random_state: int = RANDOM_STATE):\n",
    "        self.smoothing_factor = smoothing_factor\n",
    "        self.min_location_freq = min_location_freq\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def _calculate_outcode_price_per_sqft(self,\n",
    "                                        fold_train: pd.DataFrame,\n",
    "                                        fold_val: pd.DataFrame) -> Dict[str, pd.Series]:\n",
    "        \"\"\"\n",
    "        Calculate mean price per square foot using out-of-fold means for outcodes\n",
    "        \n",
    "        Args:\n",
    "            fold_train: Training data for current fold\n",
    "            fold_val: Validation data for current fold\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing train and validation series of outcode mean price per sqft\n",
    "        \"\"\"\n",
    "        # Initialize empty series for OOF predictions\n",
    "        oof_price_per_sqft = pd.Series(index=fold_train.index, dtype='float64')\n",
    "        \n",
    "        # Calculate OOF means for training data\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=self.random_state)\n",
    "        for train_idx, val_idx in kf.split(fold_train):\n",
    "            inner_train = fold_train.iloc[train_idx]\n",
    "            inner_val = fold_train.iloc[val_idx]\n",
    "            \n",
    "            # Calculate price per sqft for inner training set\n",
    "            inner_price_per_sqft = inner_train['Price'] / inner_train['Area in sq ft']\n",
    "            outcode_means = inner_price_per_sqft.groupby(inner_train['Outcode']).mean()\n",
    "            global_mean = inner_price_per_sqft.mean()\n",
    "            \n",
    "            # Apply to inner validation set\n",
    "            oof_price_per_sqft.iloc[val_idx] = (\n",
    "                inner_val['Outcode']\n",
    "                .map(outcode_means)\n",
    "                .fillna(global_mean)\n",
    "            )\n",
    "        \n",
    "        # Calculate means for validation data using full training set\n",
    "        train_price_per_sqft = fold_train['Price'] / fold_train['Area in sq ft']\n",
    "        outcode_means = train_price_per_sqft.groupby(fold_train['Outcode']).mean()\n",
    "        global_mean = train_price_per_sqft.mean()\n",
    "        \n",
    "        val_price_per_sqft = (\n",
    "            fold_val['Outcode']\n",
    "            .map(outcode_means)\n",
    "            .fillna(global_mean)\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'train': oof_price_per_sqft,\n",
    "            'val': val_price_per_sqft\n",
    "        }\n",
    "\n",
    "    def _encode_house_type(self,\n",
    "                          fold_train: pd.DataFrame,\n",
    "                          fold_val: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Create one-hot encoding for house type\"\"\"\n",
    "        # Initialize encoder for this fold\n",
    "        house_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        \n",
    "        # Fit on fold's training data\n",
    "        train_encoded = pd.DataFrame(\n",
    "            house_encoder.fit_transform(fold_train[['House Type']]),\n",
    "            columns=house_encoder.get_feature_names_out(['House Type']),\n",
    "            index=fold_train.index\n",
    "        )\n",
    "        \n",
    "        # Transform validation data\n",
    "        val_encoded = pd.DataFrame(\n",
    "            house_encoder.transform(fold_val[['House Type']]),\n",
    "            columns=house_encoder.get_feature_names_out(['House Type']),\n",
    "            index=fold_val.index\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'train': train_encoded,\n",
    "            'val': val_encoded\n",
    "        }\n",
    "\n",
    "    def _encode_city_country(self,\n",
    "                           fold_train: pd.DataFrame,\n",
    "                           fold_val: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Create one-hot encoding for city/county\"\"\"\n",
    "        # Initialize encoder for this fold\n",
    "        city_country_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        \n",
    "        # Fit on fold's training data\n",
    "        train_encoded = pd.DataFrame(\n",
    "            city_country_encoder.fit_transform(fold_train[['City/County']]),\n",
    "            columns=city_country_encoder.get_feature_names_out(['City/County']),\n",
    "            index=fold_train.index\n",
    "        )\n",
    "        \n",
    "        # Transform validation data\n",
    "        val_encoded = pd.DataFrame(\n",
    "            city_country_encoder.transform(fold_val[['City/County']]),\n",
    "            columns=city_country_encoder.get_feature_names_out(['City/County']),\n",
    "            index=fold_val.index\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'train': train_encoded,\n",
    "            'val': val_encoded\n",
    "        }\n",
    "\n",
    "    def _encode_outcode_onehot(self,\n",
    "                              fold_train: pd.DataFrame,\n",
    "                              fold_val: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Create one-hot encoding for outcodes\"\"\"\n",
    "        outcode_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        \n",
    "        train_encoded = pd.DataFrame(\n",
    "            outcode_encoder.fit_transform(fold_train[['Outcode']]),\n",
    "            columns=outcode_encoder.get_feature_names_out(['Outcode']),\n",
    "            index=fold_train.index\n",
    "        )\n",
    "        \n",
    "        val_encoded = pd.DataFrame(\n",
    "            outcode_encoder.transform(fold_val[['Outcode']]),\n",
    "            columns=outcode_encoder.get_feature_names_out(['Outcode']),\n",
    "            index=fold_val.index\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'train': train_encoded,\n",
    "            'val': val_encoded\n",
    "        }\n",
    "\n",
    "    def _encode_outcode_postcode_location_target_hierarchical(self,\n",
    "                                                            fold_train: pd.DataFrame,\n",
    "                                                            fold_val: pd.DataFrame\n",
    "                                                            ) -> Tuple[Dict[str, pd.Series],\n",
    "                                                                     Dict[str, pd.Series],\n",
    "                                                                     Dict[str, pd.Series]]:\n",
    "        \"\"\"\n",
    "        Create hierarchical target encoding for geographic features:\n",
    "        - Outcode encoding\n",
    "        - Postcode encoding using outcode as prior\n",
    "        - Location encoding using postcode as prior\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (outcode_encoding, postcode_encoding, location_encoding)\n",
    "        \"\"\"\n",
    "        # 1. Outcode encoding\n",
    "        outcode_encoding = self._encode_outcode_target(fold_train, fold_val)\n",
    "        \n",
    "        # 2. Postcode encoding using outcode as prior\n",
    "        postcode_encoding = self._encode_postcode_target(\n",
    "            fold_train, \n",
    "            fold_val, \n",
    "            outcode_encoding\n",
    "        )\n",
    "        \n",
    "        # 3. Location encoding using postcode as prior\n",
    "        location_encoding = self._encode_location_target(\n",
    "            fold_train,\n",
    "            fold_val,\n",
    "            postcode_encoding\n",
    "        )\n",
    "        \n",
    "        return outcode_encoding, postcode_encoding, location_encoding\n",
    "\n",
    "    def _encode_outcode_target(self,\n",
    "                             train_data: pd.DataFrame,\n",
    "                             eval_data: pd.DataFrame) -> Dict[str, pd.Series]:\n",
    "        \"\"\"Create target encoding for outcodes\"\"\"\n",
    "        if 'cv_fold' in train_data.columns:  # We're in cross-validation\n",
    "            # Use out-of-fold encoding for training data\n",
    "            oof_predictions = pd.Series(index=train_data.index, dtype='float64')\n",
    "            \n",
    "            kf = KFold(n_splits=5, shuffle=True, random_state=self.random_state)\n",
    "            for inner_train_idx, inner_val_idx in kf.split(train_data):\n",
    "                inner_train = train_data.iloc[inner_train_idx]\n",
    "                inner_val = train_data.iloc[inner_val_idx]\n",
    "                \n",
    "                outcode_means = inner_train.groupby('Outcode')['log_price'].mean()\n",
    "                global_mean = inner_train['log_price'].mean()\n",
    "                \n",
    "                oof_predictions.iloc[inner_val_idx] = (\n",
    "                    inner_val['Outcode']\n",
    "                    .map(outcode_means)\n",
    "                    .fillna(global_mean)\n",
    "                )\n",
    "            \n",
    "            # For validation data, use means from all training data\n",
    "            outcode_means = train_data.groupby('Outcode')['log_price'].mean()\n",
    "            global_mean = train_data['log_price'].mean()\n",
    "            \n",
    "            val_encoded = (\n",
    "                eval_data['Outcode']\n",
    "                .map(outcode_means)\n",
    "                .fillna(global_mean)\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'train': oof_predictions,\n",
    "                'val': val_encoded\n",
    "            }\n",
    "            \n",
    "        else:  # We're encoding for the test set\n",
    "            # Use all training data to encode test set\n",
    "            outcode_means = train_data.groupby('Outcode')['log_price'].mean()\n",
    "            global_mean = train_data['log_price'].mean()\n",
    "            \n",
    "            test_encoded = (\n",
    "                eval_data['Outcode']\n",
    "                .map(outcode_means)\n",
    "                .fillna(global_mean)\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'train': train_data['Outcode'].map(outcode_means).fillna(global_mean),\n",
    "                'val': test_encoded\n",
    "            }\n",
    "    \n",
    "    def _encode_postcode_target(self,\n",
    "                              fold_train: pd.DataFrame,\n",
    "                              fold_val: pd.DataFrame,\n",
    "                              outcode_encoding: Dict[str, pd.Series]) -> Dict[str, pd.Series]:\n",
    "        \"\"\"Create hierarchical encoding for postcodes using outcode prior\"\"\"\n",
    "        postcode_means = fold_train.groupby('Postal Code')['log_price'].mean()\n",
    "        postcode_counts = fold_train['Postal Code'].value_counts()\n",
    "        \n",
    "        def encode_postcodes(df: pd.DataFrame, outcode_encoded: pd.Series) -> pd.Series:\n",
    "            counts = df['Postal Code'].map(postcode_counts)\n",
    "            means = df['Postal Code'].map(postcode_means)\n",
    "            \n",
    "            # Handle unseen categories using outcode encoding\n",
    "            means = means.fillna(outcode_encoded)\n",
    "            counts = counts.fillna(0)\n",
    "            \n",
    "            # Calculate smoothed values\n",
    "            weight = counts / (counts + self.smoothing_factor)\n",
    "            return weight * means + (1 - weight) * outcode_encoded\n",
    "        \n",
    "        return {\n",
    "            'train': encode_postcodes(fold_train, outcode_encoding['train']),\n",
    "            'val': encode_postcodes(fold_val, outcode_encoding['val'])\n",
    "        }\n",
    "    \n",
    "    def _encode_location_target(self,\n",
    "                              fold_train: pd.DataFrame,\n",
    "                              fold_val: pd.DataFrame,\n",
    "                              postcode_encoding: Dict[str, pd.Series]) -> Dict[str, pd.Series]:\n",
    "        \"\"\"Create hierarchical encoding for locations using postcode prior\"\"\"\n",
    "        location_means = fold_train.groupby('Location')['log_price'].mean()\n",
    "        location_counts = fold_train['Location'].value_counts()\n",
    "        \n",
    "        def encode_locations(df: pd.DataFrame, postcode_encoded: pd.Series) -> pd.Series:\n",
    "            counts = df['Location'].map(location_counts)\n",
    "            means = df['Location'].map(location_means)\n",
    "            \n",
    "            # Handle missing and unseen locations using postcode encoding\n",
    "            means = means.fillna(postcode_encoded)\n",
    "            counts = counts.fillna(0)\n",
    "            \n",
    "            # Use postcode encoding for low-frequency locations\n",
    "            low_freq_mask = (counts < self.min_location_freq) | counts.isna()\n",
    "            \n",
    "            # Calculate smoothed values\n",
    "            weight = counts / (counts + self.smoothing_factor)\n",
    "            encoded = weight * means + (1 - weight) * postcode_encoded\n",
    "            \n",
    "            # Replace low frequency locations with postcode encoding\n",
    "            encoded[low_freq_mask] = postcode_encoded[low_freq_mask]\n",
    "            \n",
    "            return encoded\n",
    "        \n",
    "        return {\n",
    "            'train': encode_locations(fold_train, postcode_encoding['train']),\n",
    "            'val': encode_locations(fold_val, postcode_encoding['val'])\n",
    "        }\n",
    "\n",
    "    def create_fold_features(self, fold_train: pd.DataFrame, fold_val: pd.DataFrame) -> List[FeatureSet]:\n",
    "        \"\"\"Create all feature set variations for a fold\"\"\"\n",
    "        \n",
    "        house_features = self._encode_house_type(fold_train, fold_val)\n",
    "        city_country_features = self._encode_city_country(fold_train, fold_val)\n",
    "        \n",
    "        # Exploded geographic features with hierarchical encoding\n",
    "        outcode_target_hierarchical, postcode_target_hierarchical, location_target_hierarchical = (\n",
    "            self._encode_outcode_postcode_location_target_hierarchical(fold_train, fold_val)\n",
    "        )\n",
    "        \n",
    "        outcode_onehot = self._encode_outcode_onehot(fold_train, fold_val)\n",
    "        outcode_price_per_sqft = self._calculate_outcode_price_per_sqft(fold_train, fold_val)\n",
    "        \n",
    "        feature_combinations = [\n",
    "            # Base features\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': None,\n",
    "                'city': None,\n",
    "                'geo_target': None,\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': None,\n",
    "                'name': 'area_bedrooms',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms'\n",
    "            },\n",
    "            # Single feature additions\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': house_features,\n",
    "                'city': None,\n",
    "                'geo_target': None,\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': None,\n",
    "                'name': 'area_bedrooms_house',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, House Type'\n",
    "            },\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': None,\n",
    "                'city': city_country_features,\n",
    "                'geo_target': None,\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': None,\n",
    "                'name': 'area_bedrooms_city',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, City/County'\n",
    "            },\n",
    "            # Individual geographic features - Target encoded\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': None,\n",
    "                'city': None,\n",
    "                'geo_target': {'outcode': outcode_target_hierarchical},\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': None,\n",
    "                'name': 'area_bedrooms_outcode_target',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, Outcode (Target)'\n",
    "            },\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': None,\n",
    "                'city': None,\n",
    "                'geo_target': {'postcode': postcode_target_hierarchical},\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': None,\n",
    "                'name': 'area_bedrooms_postcode_target',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, Postcode (Target)'\n",
    "            },\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': None,\n",
    "                'city': None,\n",
    "                'geo_target': {'location': location_target_hierarchical},\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': None,\n",
    "                'name': 'area_bedrooms_location_target',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, Location (Target)'\n",
    "            },\n",
    "            # One-hot encoded outcode\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': None,\n",
    "                'city': None,\n",
    "                'geo_target': None,\n",
    "                'geo_onehot': {'outcode': outcode_onehot},\n",
    "                'price_sqft': None,\n",
    "                'name': 'area_bedrooms_outcode_onehot',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, Outcode (One-hot)'\n",
    "            },\n",
    "            # Price per square foot\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': None,\n",
    "                'city': None,\n",
    "                'geo_target': None,\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': outcode_price_per_sqft,\n",
    "                'name': 'area_bedrooms_pricesqft',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, Price/sqft'\n",
    "            },\n",
    "            # Two feature combinations\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': house_features,\n",
    "                'city': city_country_features,\n",
    "                'geo_target': None,\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': None,\n",
    "                'name': 'area_bedrooms_house_city',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, House Type, City/County'\n",
    "            },\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': None,\n",
    "                'city': None,\n",
    "                'geo_target': {\n",
    "                    'outcode': outcode_target_hierarchical,\n",
    "                    'postcode': postcode_target_hierarchical\n",
    "                },\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': None,\n",
    "                'name': 'area_bedrooms_outcode_postcode_target',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, Outcode & Postcode (Target)'\n",
    "            },\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': None,\n",
    "                'city': None,\n",
    "                'geo_target': {\n",
    "                    'postcode': postcode_target_hierarchical,\n",
    "                    'location': location_target_hierarchical\n",
    "                },\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': None,\n",
    "                'name': 'area_bedrooms_postcode_location_target',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, Postcode & Location (Target)'\n",
    "            },\n",
    "            # Three feature combinations\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': house_features,\n",
    "                'city': city_country_features,\n",
    "                'geo_target': {'outcode': outcode_target_hierarchical},\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': None,\n",
    "                'name': 'area_bedrooms_house_city_outcode_target',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, House Type, City/County, Outcode (Target)'\n",
    "            },\n",
    "            # All geographic features\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': None,\n",
    "                'city': None,\n",
    "                'geo_target': {\n",
    "                    'outcode': outcode_target_hierarchical,\n",
    "                    'postcode': postcode_target_hierarchical,\n",
    "                    'location': location_target_hierarchical\n",
    "                },\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': None,\n",
    "                'name': 'area_bedrooms_all_geo_target',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, All Geographic Features (Target)'\n",
    "            },\n",
    "            # Complex combinations\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': house_features,\n",
    "                'city': None,\n",
    "                'geo_target': {'outcode': outcode_target_hierarchical},\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': outcode_price_per_sqft,\n",
    "                'name': 'area_bedrooms_house_outcode_target_pricesqft',\n",
    "                'desc': 'Area in sq ft, No. of Bedrooms, House Type, Outcode (Target), Price/sqft'\n",
    "            },\n",
    "            # All features\n",
    "            {\n",
    "                'numeric': ['Area in sq ft', 'No. of Bedrooms'],\n",
    "                'house': house_features,\n",
    "                'city': city_country_features,\n",
    "                'geo_target': {\n",
    "                    'outcode': outcode_target_hierarchical,\n",
    "                    'postcode': postcode_target_hierarchical,\n",
    "                    'location': location_target_hierarchical\n",
    "                },\n",
    "                'geo_onehot': None,\n",
    "                'price_sqft': outcode_price_per_sqft,\n",
    "                'name': 'all_features',\n",
    "                'desc': 'All Features Combined'\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        return [self._combine_features(\n",
    "            fold_train, \n",
    "            fold_val,\n",
    "            combo['numeric'],\n",
    "            combo['house'],\n",
    "            combo['city'],\n",
    "            combo['geo_target'],\n",
    "            combo['geo_onehot'],\n",
    "            combo['price_sqft'],\n",
    "            combo['name'],\n",
    "            combo['desc']\n",
    "        ) for combo in feature_combinations]\n",
    "    \n",
    "    def _combine_features(self,\n",
    "                         fold_train: pd.DataFrame,\n",
    "                         fold_val: pd.DataFrame,\n",
    "                         base_numeric: List[str],\n",
    "                         house_features: Optional[Dict[str, pd.DataFrame]],\n",
    "                         city_country_features: Optional[Dict[str, pd.DataFrame]],\n",
    "                         geo_target_features: Optional[Dict[str, Dict[str, pd.Series]]],\n",
    "                         geo_onehot_features: Optional[Dict[str, Dict[str, pd.DataFrame]]],\n",
    "                         price_sqft_features: Optional[Dict[str, pd.Series]],\n",
    "                         name: str,\n",
    "                         description: str) -> FeatureSet:\n",
    "        \"\"\"\n",
    "        Combine different feature types into a single feature set\n",
    "        \"\"\"\n",
    "        # Start with base numeric features\n",
    "        X_train = fold_train[base_numeric].copy()\n",
    "        X_val = fold_val[base_numeric].copy()\n",
    "        \n",
    "        # Add house type features if provided\n",
    "        if house_features:\n",
    "            X_train = pd.concat([X_train, house_features['train']], axis=1)\n",
    "            X_val = pd.concat([X_val, house_features['val']], axis=1)\n",
    "\n",
    "        # Add city/country features if provided\n",
    "        if city_country_features:\n",
    "            X_train = pd.concat([X_train, city_country_features['train']], axis=1)\n",
    "            X_val = pd.concat([X_val, city_country_features['val']], axis=1)\n",
    "        \n",
    "        # Add target-encoded geographic features if provided\n",
    "        if geo_target_features:\n",
    "            for feature_name, feature_dict in geo_target_features.items():\n",
    "                X_train[feature_name] = feature_dict['train']\n",
    "                X_val[feature_name] = feature_dict['val']\n",
    "        \n",
    "        # Add one-hot encoded geographic features if provided\n",
    "        if geo_onehot_features:\n",
    "            for feature_name, feature_dict in geo_onehot_features.items():\n",
    "                X_train = pd.concat([X_train, feature_dict['train']], axis=1)\n",
    "                X_val = pd.concat([X_val, feature_dict['val']], axis=1)\n",
    "        \n",
    "        # Add price per square foot features if provided\n",
    "        if price_sqft_features:\n",
    "            X_train['outcode_price_per_sqft'] = price_sqft_features['train']\n",
    "            X_val['outcode_price_per_sqft'] = price_sqft_features['val']\n",
    "        \n",
    "        return FeatureSet(\n",
    "            X_train=X_train,\n",
    "            X_val=X_val,\n",
    "            y_train=fold_train['log_price'],\n",
    "            y_val=fold_val['log_price'],\n",
    "            name=name,\n",
    "            description=description\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidator:\n",
    "    \"\"\"Handles cross-validation and model evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self, n_folds: int = 5, random_state: int = RANDOM_STATE):\n",
    "        self.n_folds = n_folds\n",
    "        self.random_state = random_state\n",
    "        self.models = {\n",
    "            'decision_tree': DecisionTreeRegressor(random_state=random_state),\n",
    "            'random_forest': RandomForestRegressor(\n",
    "                n_estimators=100, \n",
    "                random_state=random_state\n",
    "            ),\n",
    "            'xgboost': XGBRegressor(\n",
    "                n_estimators=100, \n",
    "                random_state=random_state\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def evaluate_all_combinations(self, train_data: pd.DataFrame, test_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Evaluate all feature set and model combinations\"\"\"\n",
    "        results = []\n",
    "        encoder = FeatureEncoder()\n",
    "        \n",
    "        # K-fold cross-validation\n",
    "        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        for fold_idx, (fold_train_idx, fold_val_idx) in enumerate(kf.split(train_data)):\n",
    "            # Get fold data\n",
    "            fold_train = train_data.iloc[fold_train_idx].copy()\n",
    "            fold_val = train_data.iloc[fold_val_idx].copy()\n",
    "            \n",
    "            # Mark as CV fold\n",
    "            fold_train['cv_fold'] = fold_idx\n",
    "            fold_val['cv_fold'] = fold_idx\n",
    "            \n",
    "            # Create features\n",
    "            feature_sets = encoder.create_fold_features(fold_train, fold_val)\n",
    "            \n",
    "            # Evaluate combinations\n",
    "            for feature_set in feature_sets:\n",
    "                for model_name, model in self.models.items():\n",
    "                    # Train and evaluate\n",
    "                    model.fit(feature_set.X_train, feature_set.y_train)\n",
    "                    fold_val_pred = model.predict(feature_set.X_val)\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    results.append({\n",
    "                        'fold': fold_idx,\n",
    "                        'feature_set': feature_set.name,\n",
    "                        'description': feature_set.description,\n",
    "                        'model': model_name,\n",
    "                        'split_type': 'cv_fold',\n",
    "                        'rmse': self._calculate_rmse(feature_set.y_val, fold_val_pred),\n",
    "                        'r2': r2_score(feature_set.y_val, fold_val_pred),\n",
    "                        'mae': mean_absolute_error(\n",
    "                            np.exp(feature_set.y_val), \n",
    "                            np.exp(fold_val_pred)\n",
    "                        ),\n",
    "                        'pct_mae': np.mean(np.abs(\n",
    "                            (np.exp(feature_set.y_val) - np.exp(fold_val_pred)) / \n",
    "                            np.exp(feature_set.y_val)\n",
    "                        )) * 100,\n",
    "                        'n_features': feature_set.X_train.shape[1]\n",
    "                    })\n",
    "        \n",
    "        # Final evaluation on test set\n",
    "        train_data = train_data.drop('cv_fold', axis=1, errors='ignore')\n",
    "        final_feature_sets = encoder.create_fold_features(train_data, test_data)\n",
    "        \n",
    "        for feature_set in final_feature_sets:\n",
    "            for model_name, model in self.models.items():\n",
    "                model.fit(feature_set.X_train, feature_set.y_train)\n",
    "                test_pred = model.predict(feature_set.X_val)\n",
    "                \n",
    "                results.append({\n",
    "                    'fold': 'final',\n",
    "                    'feature_set': feature_set.name,\n",
    "                    'description': feature_set.description,\n",
    "                    'model': model_name,\n",
    "                    'split_type': 'test',\n",
    "                    'rmse': self._calculate_rmse(feature_set.y_val, test_pred),\n",
    "                    'r2': r2_score(feature_set.y_val, test_pred),\n",
    "                    'mae': mean_absolute_error(\n",
    "                        np.exp(feature_set.y_val), \n",
    "                        np.exp(test_pred)\n",
    "                    ),\n",
    "                    'pct_mae': np.mean(np.abs(\n",
    "                        (np.exp(feature_set.y_val) - np.exp(test_pred)) / \n",
    "                        np.exp(feature_set.y_val)\n",
    "                    )) * 100,\n",
    "                    'n_features': feature_set.X_train.shape[1]\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def _calculate_rmse(self, y_true: pd.Series, y_pred: np.ndarray) -> float:\n",
    "        \"\"\"Calculate Root Mean Squared Error\"\"\"\n",
    "        return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "print(\"CrossValidator class loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Model Comparison Pipeline\n",
    "\n",
    "Now let's run our comparison pipeline to evaluate different model and feature combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_comparison_pipeline(df_with_outcode: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Run complete pipeline from raw data to model comparison\"\"\"\n",
    "    \n",
    "    preprocessor = PreProcessor()\n",
    "    \n",
    "    # Create pre-split features\n",
    "    df_processed = preprocessor.prepare_pre_split_features(df_with_outcode)\n",
    "    \n",
    "    # Create initial train/test split\n",
    "    train_data, test_data = preprocessor.create_train_test_split(df_processed)\n",
    "    \n",
    "    # Run cross-validation evaluation\n",
    "    validator = CrossValidator()\n",
    "    results = validator.evaluate_all_combinations(train_data, test_data)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run pipeline\n",
    "results = run_model_comparison_pipeline(df_with_outcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Display model performance summary with cross-validation and test results.\n",
    "    \n",
    "    Args:\n",
    "        results: DataFrame containing model evaluation results with columns:\n",
    "                feature_set, model, split_type, r2, rmse, mae, pct_mae, description\n",
    "    \"\"\"\n",
    "    print(\"\\nModel Performance Summary:\")\n",
    "    print(\"-\" * 170)\n",
    "\n",
    "    # Print header\n",
    "    header = \"Features - Model\".ljust(100) + \" \"\n",
    "    header += \"CV R²\".ljust(15)\n",
    "    header += \"CV RMSE\".ljust(15)\n",
    "    header += \"CV MAE (£)\".ljust(20)\n",
    "    header += \"CV %Error\".ljust(20)\n",
    "    print(header)\n",
    "    print(\"-\" * 170)\n",
    "\n",
    "    for (feature_set, model), group in results.groupby(['feature_set', 'model']):\n",
    "        cv_results = group[group['split_type'] == 'cv_fold']\n",
    "        test_results = group[group['split_type'] == 'test'].iloc[0]\n",
    "        \n",
    "        # Create feature_model string using description\n",
    "        feature_model = f\"{test_results['description']} - {model}\"\n",
    "        \n",
    "        # Print CV results\n",
    "        cv_line = feature_model.ljust(100) + \" \"\n",
    "        cv_line += f\"{cv_results['r2'].mean():.3f} ±{cv_results['r2'].std():.3f}\".ljust(15)\n",
    "        cv_line += f\"{cv_results['rmse'].mean():.3f} ±{cv_results['rmse'].std():.3f}\".ljust(15)\n",
    "        cv_line += f\"£{cv_results['mae'].mean():,.0f} ±{cv_results['mae'].std():,.0f}\".ljust(20)\n",
    "        cv_line += f\"{cv_results['pct_mae'].mean():.1f} ±{cv_results['pct_mae'].std():.1f}%\"\n",
    "        print(cv_line)\n",
    "        \n",
    "        # Print test results (indented)\n",
    "        test_line = \"→ Test Results\".ljust(100) + \" \"\n",
    "        test_line += f\"{test_results['r2']:.3f}\".ljust(15)\n",
    "        test_line += f\"{test_results['rmse']:.3f}\".ljust(15)\n",
    "        test_line += f\"£{test_results['mae']:,.0f}\".ljust(20)\n",
    "        test_line += f\"{test_results['pct_mae']:.1f}%\"\n",
    "        print(test_line)\n",
    "\n",
    "# Usage:\n",
    "display_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
