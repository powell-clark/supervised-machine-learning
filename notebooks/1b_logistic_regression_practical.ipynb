{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lesson 1B: Logistic Regression PyTorch Practical\n",
                "\n",
                "<a name=\"introduction\"></a>\n",
                "## Introduction\n",
                "\n",
                "In Lesson 1A, we explored logistic regression theory and coded from scratch a logistic regression model to classify breast cancer samples.\n",
                "\n",
                "Now we'll implement a practical breast cancer classifier in PyTorch, one of the most popular deep learning frameworks.\n",
                "\n",
                "This lesson focuses on implementation by:\n",
                "\n",
                "1. Building an efficient PyTorch-based logistic regression model\n",
                "2. Working with real medical data from the Wisconsin breast cancer dataset\n",
                "3. Learning industry-standard code organisation patterns\n",
                "4. Establishing good practices for model development and evaluation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Table of Contents\n",
                "\n",
                "1. [Introduction](#introduction)\n",
                "2. [Required Libraries](#required-libraries)\n",
                "3. [Why PyTorch for logistic regression?](#why-pytorch-for-logistic-regression)\n",
                "4. [What we'll build](#what-well-build)\n",
                "5. [The Wisconsin breast cancer dataset](#the-wisconsin-breast-cancer-dataset)\n",
                "6. [Loading and exploring the dataset](#loading-and-exploring-the-dataset)\n",
                "7. [Exploratory data analysis](#exploratory-data-analysis)\n",
                "8. [Implementing a PyTorch logistic regression for cancer diagnosis](#implementing-a-pytorch-logistic-regression-for-cancer-diagnosis)\n",
                "9. [How a PyTorch Logistic Regression Works](#how-a-pytorch-logistic-regression-works)\n",
                "   - [The core mathematics](#the-core-mathematics)\n",
                "   - [Implementation structure](#implementation-structure)\n",
                "10. [The data pipeline](#the-data-pipeline)\n",
                "    - [Stage 1: Data splitting](#stage-1-data-splitting)\n",
                "    - [Stage 2: Feature standardisation](#stage-2-feature-standardisation)\n",
                "    - [Stage 3: PyTorch dataset creation](#stage-3-pytorch-dataset-creation)\n",
                "    - [What's a Tensor?](#whats-a-tensor)\n",
                "    - [Stage 4: Data Loading and batch processing](#stage-4-data-loading-and-batch-processing)\n",
                "11. [The CancerClassifier: From mathematical principles to PyTorch implementation](#the-cancerclassifier-from-mathematical-principles-to-pytorch-implementation)\n",
                "    - [The mathematical foundation](#the-mathematical-foundation)\n",
                "    - [Understanding nn.Module](#understanding-nnmodule)\n",
                "    - [The linear layer: Modern matrix operations](#the-linear-layer-modern-matrix-operations)\n",
                "    - [Weight initialisation: Xavier initialisation](#weight-initialisation-xavier-initialisation)\n",
                "    - [The Forward Pass: Computing cancer probability](#the-forward-pass-computing-cancer-probability)\n",
                "    - [The prediction method: Making clinical decisions](#the-prediction-method-making-clinical-decisions)\n",
                "    - [End-to-End example: A single cell's journey](#end-to-end-example-a-single-cells-journey)\n",
                "12. [Understanding training: How models learn from data](#understanding-training-how-models-learn-from-data)\n",
                "    - [Full batch gradient descent](#full-batch-gradient-descent)\n",
                "    - [Mini-batch gradient descent](#mini-batch-gradient-descent)\n",
                "    - [Stochastic gradient descent](#stochastic-gradient-descent)\n",
                "    - [Why we use mini-batches with validation](#why-we-use-mini-batches-with-validation)\n",
                "    - [Understanding the Adam optimiser](#understanding-the-adam-optimiser)\n",
                "13. [Understanding the training process](#understanding-the-training-process)\n",
                "    - [Function signature and inputs](#function-signature-and-inputs)\n",
                "    - [Setup phase](#setup-phase)\n",
                "    - [Training phase](#training-phase)\n",
                "    - [Validation phase and early stopping](#validation-phase-and-early-stopping)\n",
                "    - [Final evaluation](#final-evaluation)\n",
                "    - [Monitoring training progress](#monitoring-training-progress)\n",
                "14. [Understanding learning dynamics](#understanding-learning-dynamics)\n",
                "15. [Model hyperparameter optimisation](#model-hyperparameter-optimisation)\n",
                "16. [Model evaluation implementation](#model-evaluation)\n",
                "17. [How to evaluate a classification model](#how-to-evaluate-a-classification-model)\n",
                "    - [Basic classification terms](#basic-classification-terms)\n",
                "    - [Core performance metrics](#core-performance-metrics)\n",
                "    - [Understanding the visualisations](#understanding-the-visualisations)\n",
                "    - [Key insights](#key-insights)\n",
                "    - [Evaluation best practices](#evaluation-best-practices)\n",
                "18. [Persisting and loading our model](#persisting-and-loading-our-model)\n",
                "19. [Looking Forward: From Logistic Regression to Neural Networks](#looking-forward-from-logistic-regression-to-neural-networks)\n",
                "20. [Conclusion](#conclusion)\n",
                "    - [Looking ahead to lesson 2: Decision Trees](#looking-ahead-to-lesson-2-decision-trees)\n",
                "    - [Further Reading](#further-reading)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a name=\"required-libraries\"></a>\n",
                "## Required Libraries\n",
                "\n",
                "In this lesson we will use the following libraries:\n",
                "\n",
                "| Library | Purpose |\n",
                "|---------|---------|\n",
                "| NumPy | Numerical computing and array operations |\n",
                "| Pandas | Data tables and data manipulation |\n",
                "| PyTorch | Deep learning framework |\n",
                "| Matplotlib | Graph plotting functions |\n",
                "| Seaborn | Statistical visualisation built on top of Matplotlib |\n",
                "| Scikit-learn | Machine learning utilities: dataset loading, train/test splitting, preprocessing, metrics |\n",
                "| System Utilities | Logging, file ops, typing, hashing, datetime |\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# System utilities, logging, hashing, typing etc.\n",
                "from typing import List, Optional, Union, Tuple, Dict, Any\n",
                "import json\n",
                "import logging\n",
                "import hashlib\n",
                "import os\n",
                "from datetime import datetime\n",
                "from pathlib import Path\n",
                "\n",
                "# Third party imports - core data science\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from numpy.typing import NDArray\n",
                "\n",
                "# PyTorch imports\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "\n",
                "# Visualisation\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Scikit-learn utilities\n",
                "from sklearn.datasets import load_breast_cancer\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    confusion_matrix, roc_curve, roc_auc_score, auc\n",
                ")\n",
                "\n",
                "# Environment configuration\n",
                "RANDOM_SEED = 42\n",
                "np.random.seed(RANDOM_SEED)\n",
                "torch.manual_seed(RANDOM_SEED)\n",
                "\n",
                "# Jupyter and visualisation settings\n",
                "%matplotlib inline\n",
                "pd.set_option('display.max_columns', None)\n",
                "plt.style.use('seaborn-v0_8')\n",
                "\n",
                "# Device configuration\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Logging configuration\n",
                "logger = logging.getLogger(__name__)\n",
                "logging.basicConfig(level=logging.INFO)\n",
                "\n",
                "print(\"Libraries imported and configured successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a name=\"why-pytorch-for-logistic-regression\"></a>\n",
                "## Why PyTorch for logistic regression?\n",
                "\n",
                "While we built logistic regression from scratch in Lesson 1A, PyTorch offers several key advantages:\n",
                "\n",
                "1. **Efficient computation**\n",
                "   - Automatic differentiation\n",
                "   - GPU acceleration when available\n",
                "   - Optimised numerical operations\n",
                "\n",
                "2. **Production-ready tools**\n",
                "   - Built-in data loading utilities\n",
                "   - Memory-efficient batch processing\n",
                "   - Robust optimisation algorithms\n",
                "\n",
                "3. **Reusable patterns**\n",
                "   - Model organisation with `nn.Module`\n",
                "   - Data handling with `Dataset` and `DataLoader`\n",
                "   - Training loops and evaluation workflows\n",
                "\n",
                "These fundamentals will serve us well throughout our machine learning journey, particularly when we move on to neural networks (Lesson 3), as our PyTorch logistic regression implementation is technically a single-layer neural network.\n",
                "\n",
                "<a name=\"what-well-build\"></a>\n",
                "## What we'll build\n",
                "\n",
                "First, we'll perform exploratory data analysis to understand our dataset and make informed processing decisions.\n",
                "\n",
                "Then, we'll:\n",
                "\n",
                "1. Implement a PyTorch-based logistic regression model for breast cancer classification\n",
                "\n",
                "2. Review our implementation in detail to understand:\n",
                "    \n",
                "    2.1. The data pipeline\n",
                "    - Data preparation and standardisation\n",
                "    - Converting to PyTorch tensors\n",
                "    - Efficient batch loading\n",
                "    \n",
                "    2.2. The model architecture\n",
                "    - Building on nn.Module\n",
                "    - Linear layer and weight initialisation\n",
                "    - Forward pass and prediction interface\n",
                "    \n",
                "    2.3. The training process\n",
                "    - Different gradient descent approaches (full-batch, mini-batch, stochastic)\n",
                "    - Training optimisation with Adam optimiser\n",
                "    - Early stopping and hyperparameter tuning\n",
                "    - Inside the training loop\n",
                "    - Validation and performance monitoring\n",
                "\n",
                "3. Evaluate our model's performance:\n",
                "    - Medical metrics and error analysis\n",
                "    - Model persistence and production considerations\n",
                "\n",
                "By the end of this lesson, you'll have both a working cancer classifier and practical experience with professional PyTorch development - skills that form the foundation for more advanced deep learning projects.\n",
                "\n",
                "Let's begin by getting an understanding of the dataset we'll be working with."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a name=\"the-wisconsin-breast-cancer-dataset\"></a>\n",
                "## The Wisconsin breast cancer dataset\n",
                "\n",
                "When doctors examine breast tissue samples under a microscope, they look for specific cellular characteristics that might indicate cancer:\n",
                "\n",
                "1. **Cell Size and Shape**\n",
                "   - Radius (mean distance from center to perimeter)\n",
                "   - Perimeter (size of the outer boundary)\n",
                "   - Area (total space occupied by the cell)\n",
                "   - Cancer cells often appear larger and more irregular\n",
                "\n",
                "2. **Texture Analysis**\n",
                "   - Surface variations and patterns\n",
                "   - Standard deviation of gray-scale values\n",
                "   - Malignant cells typically show more variation\n",
                "\n",
                "3. **Cell Boundaries**\n",
                "   - Compactness (perimeter² / area)\n",
                "   - Concavity (severity of concave portions)\n",
                "   - Cancer cells often have irregular, ragged boundaries\n",
                "\n",
                "### Dataset Structure\n",
                "\n",
                "The dataset contains 569 samples with confirmed diagnoses. For each biopsy sample, we have:\n",
                "- 30 numeric features capturing the aforementioned cell characteristics\n",
                "- Binary classification: Malignant (1) or Benign (0)\n",
                "\n",
                "This presents an ideal scenario for logistic regression because:\n",
                "1. Clear binary outcome (malignant vs benign)\n",
                "2. Numeric features that can be combined linearly\n",
                "3. Well-documented medical relationships\n",
                "4. Real-world impact of predictions\n",
                "\n",
                "Our task mirrors a real diagnostic challenge: Can we use these cellular measurements to predict whether a tumor is cancerous? \n",
                "\n",
                "This is exactly the kind of high-stakes binary classification problem where logistic regression's interpretable predictions become crucial - doctors need to understand not just what the model predicts, but how confident it is in that prediction.\n",
                "\n",
                "<a name=\"loading-and-exploring-the-dataset\"></a>\n",
                "## Loading and exploring the dataset\n",
                "\n",
                "Let's explore the Wisconsin Breast Cancer dataset through a series of visualisations and analyses to understand our data better. \n",
                "\n",
                "Let's start by:\n",
                " \n",
                "   1. Getting a basic overview of our dataset\n",
                "      - Look at the first few rows of each feature in a table format\n",
                "      - Check how many samples and features we have\n",
                "      - Display summary statistics for each feature (mean, std, min, max, skewness, kurtosis)\n",
                "      \n",
                "   2. Investigating the distribution of our features\n",
                "      - Generate box plots for each feature to compare measurements between cancerous and non-cancerous cases\n",
                "      - Generate histograms with kernel density estimation overlays to visualise each feature's distribution\n",
                "\n",
                "   3. Investigating relationships between features\n",
                "      - Create three sets of paired plots for the most distinct pairs\n",
                "      - Create three sets of paired plots for the least distinct pairs\n",
                "      - Create three sets of paired plots for moderately distinct pairs\n",
                "\n",
                "   4. Examining correlations\n",
                "      - Analyse how each feature correlates with the diagnosis of cancer\n",
                "      - Investigate how features correlate with one another\n",
                "      - Utilise these findings to guide our selection of features\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_cancer_data():\n",
                "   \"\"\"Load and prepare breast cancer dataset.\"\"\"\n",
                "   cancer = load_breast_cancer()\n",
                "   df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
                "   df['target'] = cancer.target\n",
                "   return df\n",
                "\n",
                "def plot_initial_analysis(df):\n",
                "   \"\"\"Plot comprehensive initial data analysis including skewness and kurtosis.\"\"\"\n",
                "   # Print basic information\n",
                "   print(\"=== Dataset Overview ===\")\n",
                "   display(df.head())\n",
                "   print(f\"\\nShape: {df.shape}\")\n",
                "   \n",
                "   print(\"\\n=== Summary Statistics ===\")\n",
                "   stats = pd.DataFrame({\n",
                "       'mean': df.mean(),\n",
                "       'std': df.std(),\n",
                "       'min': df.min(),\n",
                "       'max': df.max(),\n",
                "       'skew': df.skew(),\n",
                "       'kurtosis': df.kurtosis()\n",
                "   }).round(3)\n",
                "   display(stats)\n",
                "   \n",
                "   # Box plots for each feature by diagnosis\n",
                "   n_features = len(df.columns) - 1  # Excluding target column\n",
                "   n_rows = (n_features + 4) // 5\n",
                "   \n",
                "   fig, axes = plt.subplots(n_rows, 5, figsize=(20, 4*n_rows))\n",
                "   axes = axes.ravel()\n",
                "   \n",
                "   tumor_colors = {1: '#4CAF50', 0: '#FF4B4B'}\n",
                "   \n",
                "   for idx, feature in enumerate(df.columns[:-1]):\n",
                "       plot_df = pd.DataFrame({\n",
                "           'value': df[feature],\n",
                "           'diagnosis': df['target'].map({0: 'Malignant', 1: 'Benign'})\n",
                "       })\n",
                "       \n",
                "       sns.boxplot(data=plot_df, x='diagnosis', y='value', \n",
                "                  hue='diagnosis', palette=[tumor_colors[0], tumor_colors[1]],\n",
                "                  legend=False, ax=axes[idx])\n",
                "       axes[idx].set_title(f'{feature}\\nSkew: {df[feature].skew():.2f}\\nKurt: {df[feature].kurtosis():.2f}')\n",
                "       axes[idx].set_xlabel('')\n",
                "       \n",
                "       if max(plot_df['value']) > 1000:\n",
                "           axes[idx].tick_params(axis='y', rotation=45)\n",
                "   \n",
                "   for idx in range(n_features, len(axes)):\n",
                "       axes[idx].set_visible(False)\n",
                "   \n",
                "   plt.suptitle('Feature Distributions by Diagnosis', y=1.02, size=16)\n",
                "   plt.tight_layout()\n",
                "   plt.show()\n",
                "   \n",
                "   # Distribution plots (5 per row)\n",
                "   n_rows = (n_features + 4) // 5\n",
                "   fig, axes = plt.subplots(n_rows, 5, figsize=(20, 4*n_rows))\n",
                "   axes = axes.ravel()\n",
                "   \n",
                "   for idx, feature in enumerate(df.columns[:-1]):\n",
                "       sns.histplot(df[feature], ax=axes[idx], kde=True)\n",
                "       axes[idx].set_title(f'{feature}\\nSkew: {df[feature].skew():.2f}\\nKurt: {df[feature].kurtosis():.2f}')\n",
                "       \n",
                "   for idx in range(n_features, len(axes)):\n",
                "       axes[idx].set_visible(False)\n",
                "       \n",
                "   plt.suptitle('Feature Distributions', y=1.02, size=16)\n",
                "   plt.tight_layout()\n",
                "   plt.show()\n",
                "\n",
                "def plot_feature_pairs(df):\n",
                "    \"\"\"Plot selected informative feature pairs in a 3x3 or 3x5 grid.\"\"\"\n",
                "    # Get feature correlations with target\n",
                "    target_corr = df.corr()['target'].abs().sort_values(ascending=False)\n",
                "    \n",
                "    # Get feature pair correlations\n",
                "    corr_matrix = df.iloc[:, :-1].corr().abs()\n",
                "    \n",
                "    # 1. Top 5 most separating pairs (highest correlation with target)\n",
                "    top_features = target_corr[1:6].index\n",
                "    top_pairs = [(f1, f2) for i, f1 in enumerate(top_features) \n",
                "                 for j, f2 in enumerate(top_features[i+1:], i+1)][:5]\n",
                "    \n",
                "    # 2. 5 pairs with minimal separation\n",
                "    # Get features with low target correlation\n",
                "    low_corr_features = target_corr[target_corr < 0.3].index\n",
                "    low_sep_pairs = [(f1, f2) for i, f1 in enumerate(low_corr_features) \n",
                "                     for j, f2 in enumerate(low_corr_features[i+1:], i+1)][:5]\n",
                "    \n",
                "    # 3. 5 interesting pairs showing partial separation\n",
                "    # Features with moderate target correlation\n",
                "    mod_corr_features = target_corr[(target_corr >= 0.3) & (target_corr < 0.6)].index\n",
                "    mod_sep_pairs = [(f1, f2) for i, f1 in enumerate(mod_corr_features) \n",
                "                     for j, f2 in enumerate(mod_corr_features[i+1:], i+1)][:5]\n",
                "    \n",
                "    # Combine all pairs\n",
                "    all_pairs = top_pairs + low_sep_pairs + mod_sep_pairs\n",
                "    \n",
                "    # Plot pairs\n",
                "    fig, axes = plt.subplots(3, 5, figsize=(20, 12))\n",
                "    axes = axes.ravel()\n",
                "    \n",
                "    tumor_colors = {1: '#4CAF50', 0: '#FF4B4B'}\n",
                "    \n",
                "    for idx, (feat1, feat2) in enumerate(all_pairs):\n",
                "        sns.scatterplot(data=df, x=feat1, y=feat2, hue='target',\n",
                "                       palette=tumor_colors, ax=axes[idx], alpha=0.6)\n",
                "        corr_val = corr_matrix.loc[feat1, feat2]\n",
                "        target_corr1 = target_corr[feat1]\n",
                "        target_corr2 = target_corr[feat2]\n",
                "        \n",
                "        title = f'Correlation: {corr_val:.2f}\\nTarget corr: {target_corr1:.2f}, {target_corr2:.2f}'\n",
                "        axes[idx].set_title(title)\n",
                "        axes[idx].set_xlabel(feat1, rotation=45)\n",
                "        axes[idx].set_ylabel(feat2, rotation=45)\n",
                "        axes[idx].tick_params(axis='both', labelsize=8)\n",
                "        if idx >= 10:  # Only show legend on last row\n",
                "            axes[idx].legend(title='Diagnosis')\n",
                "        else:\n",
                "            axes[idx].legend().remove()\n",
                "    \n",
                "    plt.suptitle('Feature Pair Relationships\\nTop: Best Separation | Middle: Poor Separation | Bottom: Partial Separation', \n",
                "                y=1.02, size=16)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Execute analysis\n",
                "df = load_cancer_data()\n",
                "plot_initial_analysis(df)\n",
                "plot_feature_pairs(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a name=\"exploratory-data-analysis\"></a>\n",
                "## Exploratory data analysis\n",
                "\n",
                "Our data summary, exploration and visualisations above highlight several key characteristics of our Wisconsin Breast Cancer dataset. \n",
                "\n",
                "Let's analyse what we've discovered to both understand the characteristics of our data and how we'll handle them with widely-used machine learning frameworks like PyTorch and Scikit-learn.\n",
                "\n",
                "### Dataset overview\n",
                "\n",
                "The dataset contains 569 breast tissue biopsies with confirmed diagnoses:\n",
                "```python\n",
                "# Class distribution\n",
                "Benign:    357 (62.7%)  # Non-cancerous samples\n",
                "Malignant: 212 (37.3%)  # Cancerous samples\n",
                "```\n",
                "\n",
                "Each biopsy sample contains 30 measurements that capture cell characteristics. \n",
                "\n",
                "These measurements provide a comprehensive view of cellular features that may indicate malignancy.\n",
                "\n",
                "For proper model evaluation, we'll split this data into three sets:\n",
                "```python\n",
                "# Three-way split for robust evaluation\n",
                "Training:    364 samples (64%)  # Learning patterns\n",
                "Validation:   91 samples (16%)  # Tuning decisions\n",
                "Test:        114 samples (20%)  # Final evaluation\n",
                "```\n",
                "\n",
                "This split ensures:\n",
                "1. Sufficient training data to learn patterns\n",
                "2. Independent validation set for early stopping\n",
                "3. Held-out test set matching Lesson 1A's size\n",
                "\n",
                "### Key data characteristics\n",
                "\n",
                "1. **Feature scale variations**\n",
                "   ```python\n",
                "   # Primary measurements show wide scale differences\n",
                "   radius:     14.127 ± 3.524   # Base cell measurements\n",
                "   area:      654.889 ± 351.914 # Derived measurements\n",
                "   smoothness:  0.096 ± 0.014   # Texture measurements\n",
                "   \n",
                "   # Range spans multiple orders of magnitude\n",
                "   area:        143.5 - 2501.0  \n",
                "   radius:        6.9 - 28.1    \n",
                "   smoothness:    0.05 - 0.16   \n",
                "   ```\n",
                "\n",
                "The features in our dataset span several orders of magnitude, from microscopic texture measurements to larger area calculations. This variation in scale is typical in medical data where we measure different aspects of the same sample. Importantly, our standardisation will be based only on training set statistics to prevent information leakage.\n",
                "\n",
                "2. **Distribution patterns**\n",
                "   ```python\n",
                "   # Feature distributions by skewness\n",
                "   Normal:       smoothness (0.46), texture (0.50)  # Linear relationships\n",
                "   Right-skewed: radius (0.94), area (1.65)         # Size features\n",
                "   Heavy-tailed: perimeter error (3.44)             # Diagnostic signals\n",
                "   \n",
                "   # Error terms show important variations\n",
                "   perimeter error: 2.866 ± 2.022  # Outliers indicate malignancy\n",
                "   area error:     40.337 ± 45.491 # Keep these variations\n",
                "   ```\n",
                "\n",
                "Our features show varying distribution patterns. Some measurements like smoothness follow normal distributions, while others, particularly size-related features, show right-skewed patterns. The error terms exhibit heavy-tailed distributions, which often carry important diagnostic information. These patterns remain consistent across our three data splits, indicating good stratification.\n",
                "\n",
                "3. **Feature-target relationships**\n",
                "   ```python\n",
                "   # Strong linear correlations with diagnosis\n",
                "   worst concave points: -0.794  # Key diagnostic feature\n",
                "   worst perimeter:      -0.783  # Size indicator\n",
                "   mean concave points:  -0.777  # Shape characteristic\n",
                "   \n",
                "   # Multiple strong predictors\n",
                "   Top 5 features: r = -0.794 to -0.743  # Linear model suitable\n",
                "   ```\n",
                "\n",
                "Several features show strong correlations with the diagnosis, particularly measurements related to cell shape and size. These strong linear relationships support our choice of logistic regression as a modelling approach. The correlations maintain similar strengths across our three data splits, suggesting reliable generalisation.\n",
                "\n",
                "### From manual to industry-standard implementation\n",
                "\n",
                "In Lesson 1A, we wrote manual implementations to understand the mathematics. Now we'll use PyTorch and Scikit-learn to provide the same functionality while adding proper validation:\n",
                "\n",
                "1. **Data processing**\n",
                "   ```python\n",
                "   # Feature standardisation\n",
                "   # Lesson 1A: Manual implementation\n",
                "   def standardise_features(X):\n",
                "       mean = np.mean(X, axis=0)\n",
                "       std = np.std(X, axis=0)\n",
                "       return (X - mean) / std\n",
                "\n",
                "   # Lesson 1B: Industry standard with validation\n",
                "   from sklearn.preprocessing import StandardScaler\n",
                "   scaler = StandardScaler()\n",
                "   training_features_scaled = scaler.fit_transform(training_features)\n",
                "   validation_features_scaled = scaler.transform(validation_features)\n",
                "   test_features_scaled = scaler.transform(test_features)\n",
                "\n",
                "   # Dataset creation\n",
                "   # Lesson 1A: Simple numpy arrays\n",
                "   X_train, y_train = training_features, training_labels\n",
                "\n",
                "   # Lesson 1B: PyTorch datasets and dataloaders\n",
                "   training_dataset = CancerDataset(training_features_scaled, training_labels)\n",
                "   validation_dataset = CancerDataset(validation_features_scaled, validation_labels)\n",
                "   test_dataset = CancerDataset(test_features_scaled, test_labels)\n",
                "\n",
                "   training_loader = DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
                "   validation_loader = DataLoader(validation_dataset, batch_size=32)\n",
                "   test_loader = DataLoader(test_dataset, batch_size=32)\n",
                "   ```\n",
                "\n",
                "2. **Model implementation**\n",
                "   ```python\n",
                "   # Lesson 1A: Manual implementation\n",
                "   class SimpleLogisticRegression:\n",
                "       def __init__(self, num_features):\n",
                "           self.weights = np.zeros(num_features)\n",
                "           self.bias = 0\n",
                "           \n",
                "       def calculate_linear_scores(self, X):\n",
                "           return np.dot(X, self.weights) + self.bias\n",
                "           \n",
                "       def sigmoid(self, scores):\n",
                "           return 1 / (1 + np.exp(-scores))\n",
                "\n",
                "   # Lesson 1B: PyTorch implementation\n",
                "   class CancerClassifier(nn.Module):\n",
                "       def __init__(self, input_features):\n",
                "           super().__init__()\n",
                "           self.linear = nn.Linear(input_features, 1)\n",
                "           self.sigmoid = nn.Sigmoid()\n",
                "           \n",
                "           # Proper weight initialisation using Xavier/Glorot\n",
                "           nn.init.xavier_uniform_(self.linear.weight)\n",
                "           nn.init.zeros_(self.linear.bias)\n",
                "           \n",
                "       def forward(self, x):\n",
                "           # Step 1: Compute weighted sum (z = wx + b)\n",
                "           z = self.linear(x)\n",
                "           # Step 2: Convert to probability using sigmoid\n",
                "           p = self.sigmoid(z)\n",
                "           return p\n",
                "           \n",
                "       def predict(self, x):\n",
                "           # Disable gradient tracking for efficiency\n",
                "           with torch.no_grad():\n",
                "               probabilities = self(x)\n",
                "               # Default threshold of 0.5\n",
                "               return (probabilities > 0.5).float()\n",
                "   ```\n",
                "\n",
                "3. **Training process**\n",
                "   ```python\n",
                "   # Lesson 1A: Manual implementation\n",
                "   def train_model(self, X, y, learning_rate, epochs):\n",
                "       for epoch in range(epochs):\n",
                "           scores = self.calculate_linear_scores(X)\n",
                "           probs = self.sigmoid(scores)\n",
                "           loss = self.calculate_loss(y, probs)\n",
                "           gradients = self.calculate_gradients(X, y, probs)\n",
                "           self.weights -= learning_rate * gradients\n",
                "\n",
                "   # Lesson 1B: PyTorch implementation with early stopping\n",
                "   def train_model(model, training_loader, validation_loader, test_loader,\n",
                "                  epochs=1000, lr=0.001, patience=5):\n",
                "       criterion = nn.BCELoss()\n",
                "       optimiser = optim.Adam(model.parameters(), lr=lr)\n",
                "       \n",
                "       best_val_loss = float('inf')\n",
                "       best_weights = None\n",
                "       no_improve = 0\n",
                "       \n",
                "       for epoch in range(epochs):\n",
                "           # Training phase\n",
                "           model.train()\n",
                "           for features_batch, labels_batch in training_loader:\n",
                "               predictions = model(features_batch)\n",
                "               loss = criterion(predictions, labels_batch)\n",
                "               \n",
                "               optimiser.zero_grad()\n",
                "               loss.backward()\n",
                "               optimiser.step()\n",
                "           \n",
                "           # Validation phase\n",
                "           model.eval()\n",
                "           with torch.no_grad():\n",
                "               val_loss = validate_epoch(model, validation_loader, criterion)\n",
                "               \n",
                "           # Early stopping check\n",
                "           if val_loss < best_val_loss:\n",
                "               best_val_loss = val_loss\n",
                "               best_weights = model.state_dict().copy()\n",
                "               no_improve = 0\n",
                "           else:\n",
                "               no_improve += 1\n",
                "               if no_improve == patience:\n",
                "                   print(f'Early stopping at epoch {epoch+1}')\n",
                "                   break\n",
                "       \n",
                "       # Restore best weights\n",
                "       model.load_state_dict(best_weights)\n",
                "       return model\n",
                "   ```\n",
                "\n",
                "### Next steps\n",
                "\n",
                "Going forward we'll implement a PyTorch logistic regression model that properly separates concerns and follows industry standards:\n",
                "\n",
                "1. **Enhanced data pipeline**\n",
                "   - Implements proper three-way data splitting with stratification\n",
                "   - Uses StandardScaler for robust feature scaling\n",
                "   - Leverages PyTorch's DataLoader for efficient batch processing\n",
                "   - Maintains data integrity across all splits\n",
                "\n",
                "2. **Modernised model architecture**\n",
                "   - Utilises PyTorch's Module system for clean implementation\n",
                "   - Implements proper weight initialisation\n",
                "   - Separates prediction logic from training\n",
                "   - Provides clear interfaces for training and inference\n",
                "\n",
                "3. **Robust training process**\n",
                "   - Implements mini-batch processing for efficiency\n",
                "   - Uses Adam optimiser for adaptive learning rates\n",
                "   - Incorporates validation-based early stopping\n",
                "   - Maintains proper separation of training, validation and test sets\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a name=\"implementing-a-pytorch-logistic-regression-for-cancer-diagnosis\"></a>\n",
                "## Implementing a PyTorch logistic regression for cancer diagnosis\n",
                "\n",
                "Building on our theoretical understanding from Lesson 1A, let's implement a logistic regression model using PyTorch.\n",
                "\n",
                "This modern implementation introduces several powerful features and optimisations while maintaining the same core mathematical principles we learned previously."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def prepare_data(df: pd.DataFrame) -> Tuple[NDArray, NDArray, NDArray, NDArray, NDArray, NDArray, StandardScaler]:\n",
                "    \"\"\"Prepare data for PyTorch model training by implementing a three-way split.\n",
                "    \n",
                "    This function extends our preprocessing from Lesson 1A with an additional\n",
                "    validation split for proper early stopping:\n",
                "    1. Separates features and target\n",
                "    2. Creates stratified train/validation/test split\n",
                "    3. Standardises features using only training data statistics\n",
                "    \n",
                "    Args:\n",
                "        df: DataFrame containing cancer measurements and diagnosis\n",
                "            Features should be numeric measurements (e.g., cell size, shape)\n",
                "            Target should be binary (0=benign, 1=malignant)\n",
                "    \n",
                "    Returns:\n",
                "        Tuple containing:\n",
                "        - training_features_scaled: Standardised training features\n",
                "        - validation_features_scaled: Standardised validation features\n",
                "        - test_features_scaled: Standardised test features\n",
                "        - training_labels: Training labels\n",
                "        - validation_labels: Validation labels\n",
                "        - test_labels: Test labels\n",
                "        - scaler: Fitted StandardScaler for future use\n",
                "    \"\"\"\n",
                "    # Separate features and target\n",
                "    features = df.drop('target', axis=1).values  # Features as numpy array\n",
                "    labels = df['target'].values                 # Labels as numpy array\n",
                "\n",
                "    # First split: Separate out test set (20% of total data)\n",
                "    train_val_features, test_features, train_val_labels, test_labels = train_test_split(\n",
                "        features, labels, \n",
                "        test_size=0.2,           # 20% test set (same as Lesson 1A)\n",
                "        random_state=42,         # For reproducibility\n",
                "        stratify=labels          # Maintain class balance\n",
                "    )\n",
                "    \n",
                "    # Second split: Split remaining data into train and validation (80/20 split of 80%)\n",
                "    training_features, validation_features, training_labels, validation_labels = train_test_split(\n",
                "        train_val_features, train_val_labels,\n",
                "        test_size=0.2,           # 20% of 80% ≈ 16% of total\n",
                "        random_state=42,         # For reproducibility\n",
                "        stratify=train_val_labels # Maintain class balance\n",
                "    )\n",
                "    \n",
                "    # Scale features using only training data statistics\n",
                "    scaler = StandardScaler()\n",
                "    training_features_scaled = scaler.fit_transform(training_features)\n",
                "    validation_features_scaled = scaler.transform(validation_features)\n",
                "    test_features_scaled = scaler.transform(test_features)\n",
                "    \n",
                "    return (\n",
                "        training_features_scaled, validation_features_scaled, test_features_scaled,\n",
                "        training_labels, validation_labels, test_labels, \n",
                "        scaler\n",
                "    )\n",
                "\n",
                "class CancerDataset(Dataset):\n",
                "    \"\"\"PyTorch Dataset wrapper for cancer data.\n",
                "    \n",
                "    This class bridges our numpy arrays from prepare_data() to PyTorch's\n",
                "    efficient data loading system. It:\n",
                "    1. Converts numpy arrays to PyTorch tensors\n",
                "    2. Provides length information for batch creation\n",
                "    3. Enables indexed access for efficient mini-batch sampling\n",
                "    \n",
                "    Args:\n",
                "        features: Feature array (standardised measurements)\n",
                "        labels: Label array (0=benign, 1=malignant)\n",
                "    \"\"\"\n",
                "    def __init__(self, features: NDArray, labels: NDArray):\n",
                "        # Convert numpy arrays to PyTorch tensors with appropriate types\n",
                "        self.features = torch.FloatTensor(features)      # Features as 32-bit float\n",
                "        self.labels = torch.FloatTensor(labels).reshape(-1, 1)  # Labels as 2D tensor\n",
                "        \n",
                "    def __len__(self) -> int:\n",
                "        \"\"\"Return dataset size for batch calculations.\"\"\"\n",
                "        return len(self.features)\n",
                "    \n",
                "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
                "        \"\"\"Enable indexing for batch sampling.\"\"\"\n",
                "        return self.features[idx], self.labels[idx]\n",
                "\n",
                "class CancerClassifier(nn.Module):\n",
                "    \"\"\"PyTorch binary classifier for cancer diagnosis.\n",
                "    \n",
                "    This implements logistic regression with explicit steps to show the mathematical\n",
                "    progression from inputs to prediction:\n",
                "    1. Linear layer: Computes weighted sum (z = wx + b)\n",
                "    2. Sigmoid activation: Converts sum to probability\n",
                "    \n",
                "    The weights are initialised using Xavier/Glorot initialisation for the weights\n",
                "    and zeros for the bias, ensuring:\n",
                "    - Weights: Scaled based on input/output dimensions for stable gradients\n",
                "    - Bias: Started at zero to learn the true data offset\n",
                "    \n",
                "    Args:\n",
                "        input_features: Number of measurements used for diagnosis\n",
                "    \"\"\"\n",
                "    def __init__(self, input_features: int):\n",
                "        super().__init__()\n",
                "        # Single linear layer for computing weighted sum\n",
                "        self.linear = nn.Linear(input_features, 1)\n",
                "        # Sigmoid activation for converting to probability\n",
                "        self.sigmoid = nn.Sigmoid()\n",
                "        \n",
                "        # Initialise weights using Xavier/Glorot initialisation\n",
                "        nn.init.xavier_uniform_(self.linear.weight)\n",
                "        nn.init.zeros_(self.linear.bias)\n",
                "    \n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        \"\"\"Compute diagnosis probability.\n",
                "        \n",
                "        This method explicitly shows each step of logistic regression:\n",
                "        1. Compute weighted sum: z = wx + b\n",
                "        2. Convert to probability: p = sigmoid(z)\n",
                "        \n",
                "        Args:\n",
                "            x: Input features as tensor of shape [batch_size, num_features]\n",
                "            \n",
                "        Returns:\n",
                "            Probability tensor of shape [batch_size, 1]\n",
                "        \"\"\"\n",
                "        z = self.linear(x)\n",
                "        p = self.sigmoid(z)\n",
                "        return p\n",
                "    \n",
                "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        \"\"\"Convert probabilities to binary predictions.\n",
                "        \n",
                "        This method:\n",
                "        1. Disables gradient tracking for efficiency\n",
                "        2. Computes probabilities using forward()\n",
                "        3. Applies threshold for binary prediction\n",
                "        \n",
                "        Args:\n",
                "            x: Input features as tensor\n",
                "            \n",
                "        Returns:\n",
                "            Binary predictions (0=benign, 1=malignant)\n",
                "        \"\"\"\n",
                "        with torch.no_grad():\n",
                "            probabilities = self(x)\n",
                "            return (probabilities > 0.5).float()\n",
                "\n",
                "def evaluate_model(model: CancerClassifier, data_loader: DataLoader) -> Tuple[float, float]:\n",
                "    \"\"\"Evaluate model performance on given dataset.\n",
                "    \n",
                "    Args:\n",
                "        model: Trained cancer classifier\n",
                "        data_loader: DataLoader for evaluation\n",
                "        \n",
                "    Returns:\n",
                "        Tuple of (loss, accuracy)\n",
                "    \"\"\"\n",
                "    model.eval()\n",
                "    criterion = nn.BCELoss()\n",
                "    losses = []\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for features_batch, labels_batch in data_loader:\n",
                "            predictions = model(features_batch)\n",
                "            losses.append(criterion(predictions, labels_batch).item())\n",
                "            correct += ((predictions > 0.5) == labels_batch).sum().item()\n",
                "            total += len(labels_batch)\n",
                "    \n",
                "    avg_loss = sum(losses) / len(losses)\n",
                "    accuracy = correct / total\n",
                "    return avg_loss, accuracy\n",
                "\n",
                "def train_model(\n",
                "    model: CancerClassifier, \n",
                "    training_loader: DataLoader,\n",
                "    validation_loader: DataLoader,\n",
                "    epochs: int = 1000,\n",
                "    lr: float = 0.001,\n",
                "    patience: int = 5\n",
                ") -> Tuple[CancerClassifier, Dict]:\n",
                "    \"\"\"Train cancer classifier with validation-based early stopping.\n",
                "    \n",
                "    This implements the same training process as Lesson 1A but with important improvements:\n",
                "    1. Automatic differentiation for gradients\n",
                "    2. Mini-batch processing for efficiency\n",
                "    3. Adam optimiser for adaptive learning rates\n",
                "    4. Validation-based early stopping to prevent overfitting\n",
                "    5. Separate test set for final evaluation\n",
                "    \n",
                "    Args:\n",
                "        model: PyTorch cancer classifier\n",
                "        training_loader: DataLoader for training batches\n",
                "        validation_loader: DataLoader for validation batches (early stopping)\n",
                "        epochs: Maximum training iterations\n",
                "        lr: Learning rate for optimisation\n",
                "        patience: Epochs to wait before early stopping\n",
                "        \n",
                "    Returns:\n",
                "        Tuple of (trained model, training history)\n",
                "    \"\"\"\n",
                "    criterion = nn.BCELoss()  # Binary Cross Entropy - same loss as Lesson 1A\n",
                "    optimiser = optim.Adam(model.parameters(), lr=lr)  # Adam optimiser for adaptive learning\n",
                "    \n",
                "    # Early stopping setup\n",
                "    best_val_loss = float('inf')\n",
                "    best_weights = None\n",
                "    no_improve = 0\n",
                "    \n",
                "    # Training history for visualisation\n",
                "    history = {\n",
                "        'training_loss': [], 'validation_loss': [],\n",
                "        'training_acc': [], 'validation_acc': []\n",
                "    }\n",
                "    \n",
                "    for epoch in range(epochs):\n",
                "        # Training phase\n",
                "        model.train()\n",
                "        training_losses = []\n",
                "        training_correct = 0\n",
                "        training_total = 0\n",
                "        \n",
                "        for features_batch, labels_batch in training_loader:\n",
                "            predictions = model(features_batch)\n",
                "            loss = criterion(predictions, labels_batch)\n",
                "            \n",
                "            optimiser.zero_grad()\n",
                "            loss.backward()\n",
                "            optimiser.step()\n",
                "            \n",
                "            training_losses.append(loss.item())\n",
                "            training_correct += ((predictions > 0.5) == labels_batch).sum().item()\n",
                "            training_total += len(labels_batch)\n",
                "        \n",
                "        # Calculate training metrics\n",
                "        training_loss = sum(training_losses) / len(training_losses)\n",
                "        training_acc = training_correct / training_total\n",
                "        \n",
                "        # Validation phase\n",
                "        val_loss, val_acc = evaluate_model(model, validation_loader)\n",
                "        \n",
                "        # Store history\n",
                "        history['training_loss'].append(training_loss)\n",
                "        history['validation_loss'].append(val_loss)\n",
                "        history['training_acc'].append(training_acc)\n",
                "        history['validation_acc'].append(val_acc)\n",
                "        \n",
                "        # Print progress every 10 epochs\n",
                "        if (epoch + 1) % 10 == 0:\n",
                "            print(f'Epoch {epoch+1}/{epochs}')\n",
                "            print(f'Training Loss: {training_loss:.4f}, Accuracy: {training_acc:.4f}')\n",
                "            print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\\n')\n",
                "        \n",
                "        # Early stopping check\n",
                "        if val_loss < best_val_loss:\n",
                "            best_val_loss = val_loss\n",
                "            best_weights = model.state_dict().copy()\n",
                "            no_improve = 0\n",
                "        else:\n",
                "            no_improve += 1\n",
                "            if no_improve == patience:\n",
                "                print(f'Early stopping at epoch {epoch+1}')\n",
                "                break\n",
                "    \n",
                "    # Restore best weights\n",
                "    model.load_state_dict(best_weights)\n",
                "    \n",
                "    return model, history\n",
                "\n",
                "def plot_training_curves(history: Dict[str, List[float]], test_metrics: Optional[Dict[str, float]] = None) -> None:\n",
                "    \"\"\"Visualise training progression with optional test results.\n",
                "    \n",
                "    Creates side-by-side plots of:\n",
                "    1. Loss curves - Shows learning progression\n",
                "    2. Accuracy curves - Shows diagnostic performance\n",
                "    \n",
                "    Args:\n",
                "        history: Dict containing training/validation metrics\n",
                "        test_metrics: Optional dict containing test loss and accuracy\n",
                "    \"\"\"\n",
                "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
                "    \n",
                "    # Loss curves\n",
                "    ax1.plot(history['training_loss'], label='Training')\n",
                "    ax1.plot(history['validation_loss'], label='Validation')\n",
                "    if test_metrics:\n",
                "        ax1.axhline(y=test_metrics['test_loss'], color='r', \n",
                "                   linestyle='--', label='Final Test')\n",
                "    ax1.set_title('Loss Over Time')\n",
                "    ax1.set_xlabel('Epoch')\n",
                "    ax1.set_ylabel('Binary Cross Entropy Loss')\n",
                "    ax1.legend()\n",
                "    ax1.grid(True)\n",
                "    \n",
                "    # Accuracy curves\n",
                "    ax2.plot(history['training_acc'], label='Training')\n",
                "    ax2.plot(history['validation_acc'], label='Validation')\n",
                "    if test_metrics:\n",
                "        ax2.axhline(y=test_metrics['test_acc'], color='r', \n",
                "                   linestyle='--', label='Final Test')\n",
                "    ax2.set_title('Accuracy Over Time')\n",
                "    ax2.set_xlabel('Epoch')\n",
                "    ax2.set_ylabel('Accuracy')\n",
                "    ax2.legend()\n",
                "    ax2.grid(True)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Load and prepare data with three-way split\n",
                "df = load_cancer_data()\n",
                "(\n",
                "    training_features_scaled, validation_features_scaled, test_features_scaled,\n",
                "    training_labels, validation_labels, test_labels,\n",
                "    scaler\n",
                ") = prepare_data(df)\n",
                "\n",
                "# Create datasets for all three splits\n",
                "batch_size = 32  # Small enough for precise updates, large enough for efficiency\n",
                "training_dataset = CancerDataset(training_features_scaled, training_labels)\n",
                "validation_dataset = CancerDataset(validation_features_scaled, validation_labels)\n",
                "test_dataset = CancerDataset(test_features_scaled, test_labels)\n",
                "\n",
                "# Create data loaders\n",
                "training_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
                "validation_loader = DataLoader(validation_dataset, batch_size=batch_size)\n",
                "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
                "\n",
                "# Initialise model\n",
                "model = CancerClassifier(input_features=training_features_scaled.shape[1])\n",
                "\n",
                "# Train model using only training and validation data\n",
                "model, history = train_model(\n",
                "    model, \n",
                "    training_loader,\n",
                "    validation_loader\n",
                ")\n",
                "\n",
                "# Final test set evaluation\n",
                "test_loss, test_acc = evaluate_model(model, test_loader)\n",
                "print(f\"\\nTest Set Performance:\")\n",
                "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
                "\n",
                "# Create test metrics dict for visualisation\n",
                "test_metrics = {\n",
                "    'test_loss': test_loss,\n",
                "    'test_acc': test_acc\n",
                "}\n",
                "\n",
                "# Plot final curves including test performance\n",
                "plot_training_curves(history, test_metrics)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Above is a complete working PyTorch implementation, which achieves robust results on the Wisconsin Breast Cancer dataset. \n",
                "\n",
                "Running the model 10 times shows:\n",
                "\n",
                "```python\n",
                "Training Accuracy:   98.63-98.90%  # Consistently high performance on 64% of data  \n",
                "Validation Accuracy: 97.80%        # Stable early stopping signal on 16% of data  \n",
                "Test Accuracy:       94.74-97.37%  # Final evaluation on 20% of data  \n",
                "Early Stopping:      229-509 epochs  \n",
                "```\n",
                "\n",
                "Comparing this to our Lesson 1A NumPy implementation (97.59% training accuracy, 97.35% test accuracy in 1000 epochs), we observe several useful patterns:\n",
                "\n",
                "- **Training stability**: Training accuracy consistently reaches ~98.9%, showing robust learning despite different random initialisations.\n",
                "- **Better training speed**: Early stopping occurs between 229-509 epochs, significantly earlier than Lesson 1A's fixed 1000 epochs.\n",
                "- **Comparable test performance**: Test accuracy varies between 94.74-97.37%, centering around Lesson 1A's 97.35%, whilst using less training data.\n",
                "\n",
                "The variations in stopping epochs and test accuracy are expected due to three main factors:\n",
                "\n",
                "    1. Mini-batch processing with random batch ordering\n",
                "    2. Different optimisation paths taken by the Adam optimiser\n",
                "    3. A smaller training set (64% vs. 80% in Lesson 1A)\n",
                "\n",
                "This shows how we can achieve similar results more efficiently using standard PyTorch practices which will be important for larger datasets.\n",
                "\n",
                "#### Key Differences from Lesson 1A\n",
                "Before diving into how each function works, let’s highlight the key improvements in our PyTorch implementation:\n",
                "\n",
                "- **Automatic differentiation**: PyTorch’s autograd system eliminates the need for manually computing gradients, improving efficiency and reducing implementation errors.\n",
                "\n",
                "- **Mini-batch processing**: Instead of processing all 364 training samples at once, we use batches of 32 samples, improving memory efficiency and training stability.\n",
                "\n",
                "- **Validation-based early stopping**: Training stops automatically when validation performance plateaus, preventing overfitting.\n",
                "\n",
                "- **Advanced optimisation**: The Adam optimiser, with adaptive learning rates, replaces basic gradient descent, leading to faster convergence.\n",
                "\n",
                "- **Production-ready model structure**: Using nn.Module ensures proper model persistence, structured data validation, and performance monitoring.\n",
                "\n",
                "- **GPU support**: The implementation is ready for hardware acceleration without code modifications.\n",
                "\n",
                "- **Industry-standard best practices**: The model follows PyTorch’s structured approach, making it easier to extend and maintain.\n",
                "\n",
                "<a name=\"how-a-pytorch-logistic-regression-works\"></a>\n",
                "## How a PyTorch Logistic Regression Works\n",
                "\n",
                "In Lesson 1A, we built logistic regression from scratch to understand the core mathematics. Here, we've reimplemented that same model using PyTorch's optimised framework, adding proper validation practices for medical applications.\n",
                "\n",
                "While the mathematical foundations remain unchanged, our implementation organises the code into production-ready components with robust evaluation.\n",
                "\n",
                "<a name=\"the-core-mathematics\"></a>\n",
                "### The core mathematics\n",
                "\n",
                "Our model still follows the same mathematical steps as Lesson 1A:\n",
                "\n",
                "    1. Linear combination of inputs: z = wx + b\n",
                "    2. Sigmoid activation: σ(z) = 1/(1 + e^(-z))\n",
                "    3. Binary cross-entropy loss: -(y log(p) + (1-y)log(1-p))\n",
                "    4. Backward pass: Compute gradients of the loss with respect to the parameters and update the parameters\n",
                "\n",
                "<a name=\"implementation-structure\"></a>\n",
                "### Implementation structure \n",
                "\n",
                "1. **Data pipeline**\n",
                "\n",
                "   Our data pipeline starts with a three-way split and standardisation:\n",
                "   ```python\n",
                "   # Stage 1: Split data\n",
                "   train_val_features, test_features, train_val_labels, test_labels = train_test_split(\n",
                "       features, labels, test_size=0.2  # Hold out 20% for testing\n",
                "   )\n",
                "   train_features, val_features, train_labels, val_labels = train_test_split(\n",
                "       train_val_features, train_val_labels, test_size=0.2  # 16% of total for validation\n",
                "   )\n",
                "\n",
                "   # Stage 2: Standardise using only training statistics\n",
                "   scaler = StandardScaler()\n",
                "   train_scaled = scaler.fit_transform(train_features)  # Learn from training\n",
                "   val_scaled = scaler.transform(val_features)          # Apply to validation\n",
                "   test_scaled = scaler.transform(test_features)        # Apply to test\n",
                "   \n",
                "   # Stage 3: Convert to PyTorch format\n",
                "   train_dataset = CancerDataset(train_scaled, train_labels)\n",
                "   val_dataset = CancerDataset(val_scaled, val_labels)\n",
                "   test_dataset = CancerDataset(test_scaled, test_labels)\n",
                "   \n",
                "   # Stage 4: Create efficient loaders\n",
                "   train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
                "   val_loader = DataLoader(val_dataset, batch_size=32)\n",
                "   test_loader = DataLoader(test_dataset, batch_size=32)\n",
                "   ```\n",
                "\n",
                "   This pipeline ensures:\n",
                "   - No information leakage (standardisation only learns from training data)\n",
                "   - Proper validation split for early stopping\n",
                "   - Truly held-out test set for final evaluation\n",
                "   - Efficient batched data loading for all three sets\n",
                "\n",
                "2. **Model architecture**\n",
                "   \n",
                "   Our CancerClassifier inherits from nn.Module, providing automatic gradient computation:\n",
                "\n",
                "   ```python\n",
                "    class CancerClassifier(nn.Module):\n",
                "        def __init__(self, input_features):\n",
                "           super().__init__()\n",
                "           self.linear = nn.Linear(input_features, 1)  # wx + b layer\n",
                "           self.sigmoid = nn.Sigmoid()                 # Activation\n",
                "           nn.init.xavier_uniform_(self.linear.weight) # Stable initialisation\n",
                "           \n",
                "        def forward(self, x):\n",
                "            return self.sigmoid(self.linear(x))         # Compute probability\n",
                "           \n",
                "        def predict(self, x):\n",
                "            with torch.no_grad():                       # Efficient inference\n",
                "               return (self.forward(x) > 0.5).float()  # Get diagnosis\n",
                "   ```\n",
                "\n",
                "   Key components:\n",
                "   - Linear layer computes weighted sum (z = wx + b)\n",
                "   - Sigmoid converts to probability\n",
                "   - Xavier initialisation for stable training\n",
                "   - Efficient prediction mode for inference\n",
                "\n",
                "3. **Training Process**\n",
                "\n",
                "   The training loop now properly separates training, validation, and testing:\n",
                "\n",
                "   ```python\n",
                "   def train_model(model, training_loader, validation_loader, epochs=1000, lr=0.001, patience=5):\n",
                "        criterion = nn.BCELoss()                        # Loss function\n",
                "        optimiser = optim.Adam(model.parameters())      # Optimiser\n",
                "        ...\n",
                "        for epoch in range(epochs):\n",
                "           # Training phase\n",
                "            model.train()\n",
                "            ...\n",
                "            for features_batch, labels_batch in training_loader:       # Learn from training data\n",
                "                predictions = model(features_batch)\n",
                "                loss = criterion(predictions, labels_batch)\n",
                "               \n",
                "                optimiser.zero_grad()                   # Clear gradients\n",
                "                loss.backward()                         # Compute updates\n",
                "                optimiser.step()                        # Apply updates\n",
                "                ...\n",
                "            # Validation phase\n",
                "            ...\n",
                "            val_loss, val_acc = evaluate_model(model, validation_loader)\n",
                "            ...\n",
                "            # Early stopping check\n",
                "            if val_loss < best_val_loss:\n",
                "                best_val_loss = val_loss\n",
                "                best_weights = model.state_dict().copy()\n",
                "                no_improve = 0\n",
                "            else:\n",
                "                no_improve += 1\n",
                "                if no_improve == patience:\n",
                "                    print(f'Early stopping at epoch {epoch+1}')\n",
                "                    break\n",
                "        \n",
                "        # Restore best weights\n",
                "        model.load_state_dict(best_weights)\n",
                "        \n",
                "        return model, history          \n",
                "   ```\n",
                "\n",
                "4. **Performance Monitoring**\n",
                "\n",
                "    We track metrics for all training and validation datasets throughout training and compare them to the test set:\n",
                "    ```python\n",
                "    history = {\n",
                "       'training_loss': [], 'validation_loss': [], \n",
                "       'training_acc': [], 'validation_acc': [],    \n",
                "    }\n",
                "\n",
                "    # Final test set evaluation\n",
                "    test_loss, test_acc = evaluate_model(model, test_loader)\n",
                "    ...\n",
                "\n",
                "    # Create test metrics dict for visualisation\n",
                "    test_metrics = {\n",
                "        'test_loss': test_loss,\n",
                "        'test_acc': test_acc\n",
                "    }\n",
                "\n",
                "    # Plot final curves including test performance\n",
                "    plot_training_curves(history, test_metrics)\n",
                "    ```\n",
                "\n",
                "    This helps us understand:\n",
                "    - Learning progress (training metrics)\n",
                "    - When to stop (validation metrics)\n",
                "    - True generalisation (test metrics)\n",
                "\n",
                "In the following sections, we'll examine each component in detail, understanding how this three-way evaluation approach helps us build more trustworthy medical diagnostic models.\n",
                "\n",
                "<a name=\"the-data-pipeline\"></a>\n",
                "## The data pipeline\n",
                "\n",
                "In Lesson 1A, we manually prepared our cancer data step by step, handwriting each function. Now let's see how PyTorch and Scikit-learn help us build a more robust pipeline. Our data journey has four key stages: splitting the data, preparing features, converting to PyTorch's format, and setting up efficient loading.\n",
                "\n",
                "<a name=\"stage-1-data-splitting\"></a>\n",
                "### Stage 1: Data splitting\n",
                "\n",
                "First, let's load our medical data and split it properly:\n",
                "\n",
                "```python\n",
                "df = load_cancer_data()  # Load the Wisconsin breast cancer dataset\n",
                "```\n",
                "\n",
                "Our dataset contains cell measurements and their diagnoses. But before we can use them, we need to:\n",
                "\n",
                "1. **Separate features from target**\n",
                "   ```python\n",
                "   features = df.drop('target', axis=1).values  # All cell measurements\n",
                "   labels = df['target'].values                 # Cancer diagnosis (0 or 1)\n",
                "   ```\n",
                "   This gives us two arrays: one containing all 30 cell measurements (like radius, texture, perimeter), and another containing the diagnosis (benign or malignant).\n",
                "\n",
                "2. **Create three distinct sets**\n",
                "   ```python\n",
                "   # First split: Set aside our test set\n",
                "   train_val_features, test_features, train_val_labels, test_labels = train_test_split(\n",
                "       features, labels, \n",
                "       test_size=0.2,           # Keep 20% for final testing\n",
                "       random_state=42,         # For reproducibility\n",
                "       stratify=labels          # Maintain cancer/healthy ratio\n",
                "   )\n",
                "\n",
                "   # Second split: Separate training and validation\n",
                "   train_features, val_features, train_labels, val_labels = train_test_split(\n",
                "       train_val_features, train_val_labels,\n",
                "       test_size=0.2,           # 20% of remaining 80% ≈ 16% of total\n",
                "       random_state=42,\n",
                "       stratify=train_val_labels\n",
                "   )\n",
                "   ```\n",
                "   We're keeping 20% of our data completely separate for final testing, and then splitting the remaining data into training (64%) and validation (16%). The `stratify` parameter is super important here - it ensures each set has the same proportion of cancer cases as our original dataset. This is absolutely critical for medical applications!\n",
                "\n",
                "<a name=\"stage-2-feature-standardisation\"></a>\n",
                "### Stage 2: Feature standardisation\n",
                "\n",
                "Just like in Lesson 1A, we need to standardise our measurements. But this time, we'll be extra careful to avoid information leakage:\n",
                "\n",
                "```python\n",
                "scaler = StandardScaler()\n",
                "\n",
                "# Learn standardisation from training data only\n",
                "train_features_scaled = scaler.fit_transform(train_features)\n",
                "\n",
                "# Apply same scaling to validation and test sets\n",
                "val_features_scaled = scaler.transform(val_features)\n",
                "test_features_scaled = scaler.transform(test_features)\n",
                "```\n",
                "\n",
                "Using Sci-kit learn's `scaler.fit_transform` we only compute the scaling parameters (mean and standard deviation) from the training data. Then we apply those same parameters using `scaler.transform` to our validation and test sets. This keeps our evaluation sets truly independent!\n",
                "\n",
                "<a name=\"stage-3-pytorch-dataset-creation\"></a>\n",
                "### Stage 3: PyTorch dataset creation\n",
                "\n",
                "Now we need to wrap our prepared data in PyTorch's dataset format:\n",
                "\n",
                "```python\n",
                "from torch.utils.data import Dataset\n",
                "\n",
                "class CancerDataset(Dataset):\n",
                "    def __init__(self, features: NDArray, labels: NDArray):\n",
                "        self.features = torch.FloatTensor(features)               # Convert features to tensor\n",
                "        self.labels = torch.FloatTensor(labels).reshape(-1, 1)    # Convert labels to 2D tensor\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.features)  # Total number of samples\n",
                "        \n",
                "    def __getitem__(self, idx):\n",
                "        return self.features[idx], self.labels[idx]  # Get one sample and label\n",
                "\n",
                "# Create our three datasets\n",
                "training_dataset = CancerDataset(training_features_scaled, training_labels)\n",
                "validation_dataset = CancerDataset(validation_features_scaled, validation_labels)\n",
                "test_dataset = CancerDataset(test_features_scaled, test_labels)\n",
                "```\n",
                "\n",
                "<a name=\"whats-a-tensor\"></a>\n",
                "# What's a Tensor?\n",
                "\n",
                "Before we move on, let's understand what happened when we converted our numpy arrays to tensors. The term \"tensor\" has two related but distinct meanings:\n",
                "\n",
                "1. **In Mathematics**: A tensor is a geometric object that represents multilinear relationships between vectors, with strict rules about how it transforms when coordinates change. For example, stress and strain in materials science are true mathematical tensors. \n",
                "\n",
                "    The key thing about mathematical tensors is their rank:\n",
                "    - Rank 0: A scalar (just a number)\n",
                "    - Rank 1: A vector (a list of numbers that transforms in a special way)\n",
                "    - Rank 2: A matrix (a table of numbers with specific transformation properties)\n",
                "    - Rank 3+: Higher-dimensional arrays that follow similar rules\n",
                "\n",
                "2. **In PyTorch/ML**: A tensor is a container for numbers arranged in multiple dimensions - similar to a numpy array but with special powers for machine learning. \n",
                "\n",
                "    In PyTorch and other ML frameworks, we've borrowed the term \"tensor\" because we're also working with multi-dimensional arrays of numbers. While our ML tensors don't strictly follow all the mathematical transformation rules, they share the core idea of organising data in multiple dimensions:\n",
                "\n",
                "    ```python\n",
                "    # Different tensor dimensions\n",
                "    scalar = tensor(3.14)                      # 0D: just a single number\n",
                "    vector = tensor([1.2, 0.5, 3.1])           # 1D: like a list of numbers\n",
                "    matrix = tensor([[1.2, 0.5], [0.8, 1.5]])  # 2D: like a table of numbers\n",
                "    ```\n",
                "\n",
                "Their special powers that make them perfect for neural networks are:\n",
                "\n",
                "1. **Automatic gradient tracking**\n",
                "   ```python\n",
                "   x = torch.tensor([1.0], requires_grad=True)\n",
                "   y = x * 2    # y remembers it came from x\n",
                "   z = y ** 2   # z remembers the whole computation chain\n",
                "   ```\n",
                "   When we compute gradients during training, tensors automatically track how changes should flow backward through the computations. In Lesson 1A, we had to derive and implement these gradients manually!\n",
                "\n",
                "2. **GPU acceleration**\n",
                "   ```python\n",
                "   if torch.cuda.is_available():\n",
                "       x = x.cuda()  # Move to GPU\n",
                "   ```\n",
                "   Tensors can easily be moved to a GPU for parallel processing. Our numpy arrays in Lesson 1A could only use the CPU.\n",
                "\n",
                "3. **Broadcasting**\n",
                "   ```python\n",
                "   # Automatically handles operations between different shapes\n",
                "   matrix = torch.tensor([[1, 2], [3, 4]])\n",
                "   vector = torch.tensor([10, 20])\n",
                "   result = matrix + vector  # Broadcasting happens automatically\n",
                "   # result = [[11, 22], [13, 24]]\n",
                "   ```\n",
                "   PyTorch tensors automatically handle operations between tensors of different shapes, making many computations more concise.\n",
                "\n",
                "4. **Memory efficiency**\n",
                "   ```python\n",
                "   # Create a tensor\n",
                "   x = torch.tensor([[1, 2, 3],\n",
                "                    [4, 5, 6]])\n",
                "   \n",
                "   # Memory layout (numbers stored sequentially)\n",
                "   Memory:  1000   1004   1008   1012   1016   1020\n",
                "           ┌──────┬──────┬──────┬──────┬──────┬──────┐\n",
                "   Values: │  1   │  2   │  3   │  4   │  5   │  6   │\n",
                "           └──────┴──────┴──────┴──────┴──────┴──────┘\n",
                "   \n",
                "   # View just points to same memory\n",
                "   y = x.view(-1)  # Reshape without copying\n",
                "   y[0] = 100      # Changes x[0,0] too!\n",
                "   ```\n",
                "   This sequential storage makes operations fast and efficient. When we create a view, we're just looking at the same memory in a different way, rather than copying all the numbers to a new location.\n",
                "\n",
                "**In our cancer detection pipeline, we're using 2D tensors:**\n",
                "```python\n",
                "# Feature tensors (standardised measurements)\n",
                "X_tensor = torch.FloatTensor([\n",
                "    [1.2, 0.8, 1.5, ...],  # First cell's measurements\n",
                "    [0.5, 1.1, 0.7, ...],  # Second cell's measurements\n",
                "    # ... more cells\n",
                "])\n",
                "\n",
                "# Label tensors (diagnoses)\n",
                "y_tensor = torch.FloatTensor([\n",
                "    [1],  # First cell: malignant\n",
                "    [0],  # Second cell: benign\n",
                "    # ... more diagnoses\n",
                "])\n",
                "```\n",
                "\n",
                "The `FloatTensor` part means we're using 32-bit precision - generally the best balance of accuracy and speed for machine learning.\n",
                "\n",
                "<a name=\"stage-4-data-loading-and-batch-processing\"></a>\n",
                "### Stage 4: Data Loading and batch processing\n",
                "\n",
                "Having standardised our measurements and converted them to tensors, we need to prepare our data for efficient learning. Each sample contains 30 measurements plus a diagnosis label, requiring approximately 124 bytes of memory (31 values × 4 bytes per float). Our entire dataset of 455 samples needs only 56KB of memory - tiny by modern standards.\n",
                "\n",
                "Let's set up our data pipeline using industry-standard batch processing:\n",
                "\n",
                "\n",
                "```python\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "training_loader = DataLoader(\n",
                "    training_dataset,     # Our CancerDataset from earlier\n",
                "    batch_size=32,        # Process 32 samples at once\n",
                "    shuffle=True          # Randomize order each epoch\n",
                ")\n",
                "\n",
                "validation_loader = DataLoader(\n",
                "    validation_dataset,\n",
                "    batch_size=32,        # Same batch size for consistency\n",
                "    shuffle=False         # Not shuffled for reproducibility of validation data\n",
                ")\n",
                "\n",
                "test_loader = DataLoader(\n",
                "    test_dataset,\n",
                "    batch_size=32,\n",
                "    shuffle=False          # Not shuffled for reproducibility of test data\n",
                ")\n",
                "```\n",
                "The batch size of 32 might seem puzzlingly small. A typical gaming GPU like the NVIDIA RTX 3060 has 3584 cores and 12GB of memory - surely we could process more data at once? To understand why we use batches, let's compare CPU and GPU processing:\n",
                "\n",
                "- A CPU might have 8-16 powerful cores, each able to handle complex tasks independently\n",
                "- A GPU has thousands of simpler cores, designed to perform the same operation on different data simultaneously\n",
                "\n",
                "Think of the GPU like a restaurant kitchen where a head chef (CPU) oversees multiple stations of sous chefs (GPU cores). Each station excels at one specific task - chopping, sautéing, plating - but together they can process many identical orders in parallel. At the start of each epoch, the head chef:\n",
                "1. Shuffles all orders (training samples)\n",
                "2. Divides them into batches of 32 orders\n",
                "3. Sends each batch through the kitchen's stations in parallel\n",
                "4. Reviews the results and adjusts the recipe before the next batch\n",
                "\n",
                "For our cancer detection task with only 30 features per sample, we're barely engaging the GPU's parallel processing power. But consider a medical imaging task where each sample is a 1000×1000 pixel image:\n",
                "- Each sample has 1 million features (1000×1000 pixels)\n",
                "- Using matrix notation [rows × columns], the computation is:\n",
                "  [32 × 1M features] @ [1M features × 1] = [32 × 1] predictions\n",
                "- Each prediction requires 1M multiply-accumulate operations\n",
                "- The GPU parallelises these 32 dot products and their internal operations across its cores\n",
                "- This larger computation better utilises GPU parallel processing capabilities, though still may not fully saturate modern GPUs\n",
                "\n",
                "Here's how we use these loaders during training and evaluation:\n",
                "```python\n",
                "def evaluate_model(model, data_loader):\n",
                "    model.eval()\n",
                "    criterion = nn.BCELoss()\n",
                "    losses = []\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for features_batch, labels_batch in data_loader:\n",
                "            predictions = model(features_batch)\n",
                "            losses.append(criterion(predictions, labels_batch).item())\n",
                "            correct += ((predictions > 0.5) == labels_batch).sum().item()\n",
                "            total += len(labels_batch)\n",
                "    \n",
                "    avg_loss = sum(losses) / len(losses)\n",
                "    accuracy = correct / total\n",
                "    return avg_loss, accuracy\n",
                "\n",
                "def train_model(...):\n",
                "    ...\n",
                "    for epoch in range(num_epochs):\n",
                "        ...\n",
                "        for features_batch, labels_batch in training_loader:\n",
                "            ...\n",
                "            predictions = model(features_batch)\n",
                "            loss = criterion(predictions, labels_batch)\n",
                "            ...\n",
                "            loss.backward()\n",
                "            optimiser.step()\n",
                "            ...\n",
                "        # After each epoch the evaluate_model function performs a similar batched loop over the validation dataset\n",
                "        val_loss, val_acc = evaluate_model(model, validation_loader)\n",
                "    ...\n",
                "# After training, again we evalute the the model performing a batched loop over the test set\n",
                "test_loss, test_acc = evaluate_model(model, test_loader)\n",
                "```\n",
                "\n",
                "The DataLoader acts as a smart iterator that:\n",
                "1. Automatically creates batches of 32 samples\n",
                "2. Shuffles the training data each epoch (but keeps validation and test data in order)\n",
                "3. Handles all the memory management for us\n",
                "\n",
                "This pipeline sets us up for efficient training by:\n",
                "1. Properly separating our data into training, validation, and test sets without information leakage\n",
                "2. Enabling parallel computation within each batch\n",
                "3. Providing frequent weight updates for effective learning\n",
                "4. Managing memory transfers between CPU and GPU\n",
                "\n",
                "In the next section, we'll see how our CancerClassifier model uses this carefully prepared data to learn diagnosis patterns! Later, we'll also compare this mini-batch approach with alternatives like full-batch (455 samples) and stochastic (1 sample) gradient descent.\n",
                "\n",
                "a name=\"the-cancerclassifier-from-mathematical-principles-to-pytorch-implementation\"></a>\n",
                "## The CancerClassifier: From mathematical principles to PyTorch implementation\n",
                "\n",
                "In Lesson 1A, we built logistic regression from scratch using numpy, carefully deriving each mathematical component. Now we'll translate this same mathematical foundation into PyTorch's framework, understanding how each piece maps to our previous implementation while gaining powerful new capabilities.\n",
                "\n",
                "<a name=\"the-mathematical-foundation\"></a>\n",
                "### The mathematical foundation\n",
                "\n",
                "Let's recall our core logistic regression equations from Lesson 1A:\n",
                "\n",
                "For a single cell sample with 30 measurements x₁, x₂, ..., x₃₀, our model:\n",
                "1. Computes a weighted sum: z = w₁x₁ + w₂x₂ + ... + w₃₀x₃₀ + b\n",
                "2. Converts to probability: p = 1/(1 + e^(-z))\n",
                "3. Makes a diagnosis: ŷ = 1 if p > 0.5 else 0\n",
                "\n",
                "Our PyTorch implementation preserves this exact mathematical structure while adding modern optimisation capabilities:\n",
                "\n",
                "```python\n",
                "class CancerClassifier(nn.Module):\n",
                "    def __init__(self, input_features: int):\n",
                "        super().__init__()\n",
                "        self.linear = nn.Linear(input_features, 1)\n",
                "        self.sigmoid = nn.Sigmoid()\n",
                "        \n",
                "        # Initialise weights optimally\n",
                "        nn.init.xavier_uniform_(self.linear.weight)\n",
                "        nn.init.zeros_(self.linear.bias)\n",
                "\n",
                "    def forward(self, x):\n",
                "        z = self.linear(x)     # Weighted sum\n",
                "        p = self.sigmoid(z)    # Convert to probability\n",
                "        return p\n",
                "\n",
                "    def predict(self, x):\n",
                "        with torch.no_grad():\n",
                "            p = self(x)\n",
                "            return (p > 0.5).float()\n",
                "```\n",
                "\n",
                "<a name=\"understanding-nnmodule\"></a>\n",
                "### Understanding nn.Module\n",
                "\n",
                "The first key difference from our numpy implementation is inheritance from nn.Module:\n",
                "\n",
                "```python\n",
                "class CancerClassifier(nn.Module):\n",
                "    def __init__(self, input_features: int):\n",
                "        super().__init__()\n",
                "```\n",
                "\n",
                "This inheritance provides three crucial capabilities:\n",
                "1. Parameter Management: Automatically tracks all learnable parameters (weights and biases)\n",
                "2. GPU Support: Can move entire model to GPU with single command\n",
                "3. Gradient Computation: Enables automatic differentiation through the model\n",
                "\n",
                "When we call super().__init__(), we're setting up this infrastructure. Think of nn.Module as providing a laboratory full of sophisticated equipment, whereas in Lesson 1A we had to build everything by hand.\n",
                "\n",
                "<a name=\"the-linear-layer-modern-matrix-operations\"></a>\n",
                "### The linear layer: Modern matrix operations\n",
                "\n",
                "In Lesson 1A, we explicitly created weight and bias arrays:\n",
                "```python\n",
                "# Lesson 1A approach:\n",
                "self.weights = np.random.randn(input_features) * 0.01\n",
                "self.bias = 0.0\n",
                "\n",
                "def compute_weighted_sum(self, x):\n",
                "    return np.dot(x, self.weights) + self.bias\n",
                "```\n",
                "\n",
                "PyTorch's nn.Linear encapsulates this same computation:\n",
                "```python\n",
                "# PyTorch approach:\n",
                "self.linear = nn.Linear(input_features, 1)\n",
                "```\n",
                "\n",
                "But there's much more happening under the hood. The linear layer:\n",
                "1. Creates a weight matrix of shape [1, input_features]\n",
                "2. Creates a bias vector of shape [1]\n",
                "3. Implements optimal memory layouts for matrix operations using Tensors\n",
                "4. Tracks gradients for both weights and bias\n",
                "5. Supports batched computations automatically\n",
                "\n",
                "For our cancer detection task with 30 features, this means:\n",
                "```python\n",
                "model.linear.weight.shape  # torch.Size([1, 30])  ->  a Tensor with 1 row of 30 feature weights\n",
                "model.linear.bias.shape    # torch.Size([1])      ->  a Tensor with 1 bias value\n",
                "```\n",
                "\n",
                "<a name=\"weight-initialisation-xavier-initialisation\"></a>\n",
                "### Weight initialisation: Xavier initialisation\n",
                "\n",
                "In Lesson 1A, we learned that Xavier initialisation reduces weight ranges as feature count increases. With normalised inputs (mean=0, variance=1), this keeps the combined score z with a variance of 1 around a mean of 0.\n",
                "\n",
                "This score z is called an \"activation\" because, like a neuron's electrical signal, it represents how strongly our model is activated by the combination of input features it receives.\n",
                "\n",
                "Using the Xavier initialisation we can ensure these activations typically fall within these ranges:\n",
                "- 68% of z values fall between -1 and +1\n",
                "- 95% of z values fall between -2 and +2\n",
                "- 99.7% of z values fall between -3 and +3\n",
                "\n",
                "This is crucial for logistic regression because:\n",
                "1. The sigmoid function is most sensitive between -3 and +3\n",
                "2. The steepest gradient (best for learning) is around 0\n",
                "3. Extreme z values (>|3|) slow down training\n",
                "\n",
                "In Lesson 1A, we used simple random initialisation:\n",
                "```python\n",
                "weights = np.random.randn(input_features) * 0.01\n",
                "```\n",
                "\n",
                "Our PyTorch implementation uses Xavier initialisation as follows:\n",
                "```python\n",
                "nn.init.xavier_uniform_(self.linear.weight)\n",
                "nn.init.zeros_(self.linear.bias)\n",
                "```\n",
                "\n",
                "The mathematics of Xavier comes from analysing how the variance of signals changes as they flow through the network:\n",
                "\n",
                "```python\n",
                "# Xavier calculates the optimal standard deviation (std) based on:\n",
                "# - nin: number of input features\n",
                "# - nout: number of outputs\n",
                "\n",
                "std = sqrt(2.0 / (nin + nout))\n",
                "\n",
                "# For our breast cancer classifier:\n",
                "nin = 30    # 30 cell measurements (features)\n",
                "nout = 1    # 1 output (cancer probability)\n",
                "std = sqrt(2.0 / 31) ≈ 0.25\n",
                "\n",
                "# Weights are then uniformly distributed in [-0.25, 0.25]\n",
                "```\n",
                "This produces similar weight ranges to what we saw in Lesson 1A:\n",
                "\n",
                "```python\n",
                "# Example ranges for different numbers of features:\n",
                "2 features:   random_uniform(-1.000, 1.000)    # sqrt(2/2)   -> Var(z) ≈ 1.000\n",
                "6 features:   random_uniform(-0.577, 0.577)    # sqrt(2/6)   -> Var(z) ≈ 1.001\n",
                "10 features:  random_uniform(-0.447, 0.447)    # sqrt(2/10)  -> Var(z) ≈ 1.002\n",
                "30 features:  random_uniform(-0.258, 0.258)    # sqrt(2/30)  -> Var(z) ≈ 1.000\n",
                "```\n",
                "\n",
                "<a name=\"the-forward-pass-computing-cancer-probability\"></a>\n",
                "### The Forward Pass: Computing cancer probability\n",
                "\n",
                "The forward method defines our computational graph:\n",
                "```python\n",
                "def forward(self, x):\n",
                "    z = self.linear(x)     # Step 1: Linear combination\n",
                "    p = self.sigmoid(z)    # Step 2: Probability conversion\n",
                "    return p\n",
                "```\n",
                "\n",
                "When processing a single cell's measurements:\n",
                "```python\n",
                "# Example standardised measurements\n",
                "x = tensor([\n",
                "    1.2,   # Radius: 1.2 standard deviations above mean\n",
                "    -0.3,  # Texture: 0.3 standard deviations below mean\n",
                "    1.8,   # Perimeter: 1.8 standard deviations above mean\n",
                "    # ... 27 more measurements\n",
                "])\n",
                "\n",
                "# Step 1: Linear combination\n",
                "z = w₁(1.2) + w₂(-0.3) + w₃(1.8) + ... + b\n",
                "\n",
                "# Step 2: Sigmoid conversion\n",
                "p = 1/(1 + e^(-z))\n",
                "```\n",
                "\n",
                "PyTorch's autograd system tracks all these computations, building a graph for backpropagation. Each operation remembers:\n",
                "1. What inputs it received\n",
                "2. How to compute gradients for those inputs\n",
                "3. Which operations used its outputs\n",
                "\n",
                "<a name=\"the-prediction-method-making-clinical-decisions\"></a>\n",
                "### The prediction method: Making clinical decisions\n",
                "\n",
                "Finally, we provide a clean method for making diagnoses that inherits from nn.Module's utilities to make things cleaner:\n",
                "```python\n",
                "def predict(self, x):\n",
                "    with torch.no_grad():  # Prediction only - saves memory\n",
                "        p = self(x)        # CancerClassifier calls forward() for us\n",
                "        return (p > 0.5).float()  # Convert to 0.0 or 1.0\n",
                "```\n",
                "\n",
                "When we write p = self(x), CancerClassifier automatically calls our forward() method for us (thanks to nn.Module inheritance), which gets the probability. We then convert anything above 50% to a cancer diagnosis (1) and anything below to benign (0).\n",
                "\n",
                "This magic happens because CancerClassifier inherits from nn.Module, which provides this functionality:\n",
                "```python\n",
                "# Inside nn.Module (simplified)\n",
                "def __call__(self, *input, **kwargs):\n",
                "    # ... setup ...\n",
                "    result = self.forward(*input, **kwargs)  # Calls our forward method\n",
                "    # ... cleanup ...\n",
                "    return result\n",
                "```\n",
                "\n",
                "The `with torch.no_grad()` tells PyTorch \"we're just predicting, not training\" which:\n",
                "1. Saves memory (doesn't store calculations for training)\n",
                "2. Makes predictions faster\n",
                "3. Is the right thing to do at diagnosis time\n",
                "\n",
                "So when we pass in cell measurements:\n",
                "\n",
                "```python\n",
                "# Input: Cell measurements (32 samples)\n",
                "measurements = [\n",
                "    [1.2, 0.8, 1.5, ...],  # First cell (30 numbers)\n",
                "    [0.5, 1.1, 0.7, ...],  # Second cell\n",
                "    # ... 30 more cells\n",
                "]\n",
                "\n",
                "# Output: Diagnoses (32 answers)\n",
                "diagnoses = [\n",
                "    [1],  # First cell: Cancer\n",
                "    [0],  # Second cell: No cancer\n",
                "    # ... 30 more diagnoses\n",
                "]\n",
                "```\n",
                "\n",
                "Our PyTorch implementation maintains Lesson 1A's mathematical clarity while adding:\n",
                "    1. Efficient batch processing\n",
                "    2. Automatic differentiation\n",
                "    3. GPU support\n",
                "    4. Memory-efficient inference\n",
                "\n",
                "In the next section, we'll explore how this classifier learns from medical data using mini-batch processing and validation-set based early stopping.\n",
                "\n",
                "<a name=\"end-to-end-example-a-single-cells-journey\"></a>\n",
                "### End-to-End example: A single cell's journey\n",
                "\n",
                "Let's follow a single cell sample through our model:\n",
                "\n",
                "```python\n",
                "# 1. Input: Standardised cell measurements\n",
                "x = tensor([\n",
                "    1.2,   # Radius (high)\n",
                "    -0.3,  # Texture (normal)\n",
                "    1.8,   # Perimeter (very high)\n",
                "    0.5,   # Area (moderately high)\n",
                "    # ... 26 more measurements\n",
                "])\n",
                "\n",
                "# 2. Linear Layer: Combine evidence\n",
                "z = self.linear(x)\n",
                "  = 1.2w₁ - 0.3w₂ + 1.8w₃ + 0.5w₄ + ... + b\n",
                "  = 2.45  # Example weighted sum\n",
                "\n",
                "# 3. Sigmoid: Convert to probability\n",
                "p = self.sigmoid(z)\n",
                "  = 1/(1 + e^(-2.45))\n",
                "  = 0.92  # 92% chance of cancer\n",
                "\n",
                "# 4. Prediction: Make diagnosis\n",
                "diagnosis = self.predict(x)\n",
                "         = (0.92 > 0.5).float()\n",
                "         = 1  # Model predicts cancer\n",
                "```\n",
                "\n",
                "Our PyTorch implementation maintains the clear mathematical reasoning of Lesson 1A while adding powerful capabilities:\n",
                "1. Automatic differentiation for learning\n",
                "2. Efficient batch processing\n",
                "3. GPU acceleration\n",
                "4. Optimal initialisation\n",
                "5. Memory-efficient computation\n",
                "\n",
                "In the next section, we'll explore how this classifier learns from medical data using mini-batch processing and the Adam optimiser, which provides adaptive learning rates for each parameter.\n",
                "\n",
                "<a name=\"understanding-training-how-models-learn-from-data\"></a>\n",
                "## Understanding training: How models learn from data\n",
                "\n",
                "Before diving into our train_model function's code, let's understand the fundamental concept of batch processing in machine learning. There are three main ways models can learn from data:\n",
                "\n",
                "<a name=\"full-batch-gradient-descent\"></a>\n",
                "### Full batch gradient descent (Like Our Numpy Version)\n",
                "\n",
                "Remember our Lesson 1A implementation? It processed all training data at once:\n",
                "\n",
                "```python\n",
                "# Simple numpy version (full batch)\n",
                "for epoch in range(num_epochs):\n",
                "    # Calculate predictions for ALL training samples\n",
                "    predictions = self.calculate_probabilities(all_features)  # All 364 samples\n",
                "    \n",
                "    # Calculate average error across ALL samples\n",
                "    average_error = np.mean(predictions - true_labels)  # Average of 364 errors\n",
                "    \n",
                "    # Update weights ONCE using this average\n",
                "    self.weights -= learning_rate * average_error\n",
                "```\n",
                "\n",
                "Think of this like a teacher waiting until every student (364 of them) takes a test, calculating the class average, and only then adjusting their teaching method. This is:\n",
                "- Most accurate (uses all data)\n",
                "- Most memory intensive (needs all data at once)\n",
                "- Slowest to react (only updates once per epoch)\n",
                "\n",
                "<a name=\"mini-batch-gradient-descent\"></a>\n",
                "### Mini-batch gradient descent (Our PyTorch Version)\n",
                "\n",
                "Our current implementation processes data in small groups and includes proper validation:\n",
                "\n",
                "```python\n",
                "# PyTorch version with validation\n",
                "for epoch in range(epochs):\n",
                "    # Training phase\n",
                "    for features_batch, labels_batch in training_loader:     # Batches of 32\n",
                "        predictions = model(features_batch)                  # Process 32 samples\n",
                "        loss = criterion(predictions, labels_batch)          # Loss for 32 samples\n",
                "        optimiser.step()                                     # Frequent updates\n",
                "    \n",
                "    # Validation phase\n",
                "    val_loss, val_acc = evaluate_model(model, validation_loader)\n",
                "    if early_stopping(val_loss):                             # Use validation\n",
                "        break                                                # for stopping\n",
                "```\n",
                "\n",
                "This is like a teacher giving quizzes to groups of 32 students and adjusting their teaching after each group's results, while keeping a separate class for validation. This approach:\n",
                "- Balances accuracy and speed\n",
                "- Uses less memory\n",
                "- Updates weights more frequently\n",
                "- Provides proper validation checks\n",
                "\n",
                "<a name=\"stochastic-gradient-descent\"></a>\n",
                "### Stochastic gradient descent \n",
                "\n",
                "An alternative approach processes one sample at a time:\n",
                "\n",
                "```python\n",
                "# Stochastic version (not used in our code)\n",
                "for epoch in range(epochs):\n",
                "    for single_sample, single_label in samples:  # One at a time\n",
                "        prediction = model(single_sample)        # Just 1 sample\n",
                "        loss = criterion(prediction, single_label)\n",
                "        optimiser.step()                         # Updates very frequently\n",
                "```\n",
                "\n",
                "Like a teacher adjusting their method after each individual student's answer. This:\n",
                "- Uses minimal memory\n",
                "- Updates very frequently\n",
                "- Can be very noisy (bounces around a lot)\n",
                "- Makes validation trickier\n",
                "\n",
                "<a name=\"why-we-use-mini-batches-with-validation\"></a>\n",
                "### Why we use mini-batches with validation\n",
                "\n",
                "For our cancer detection task, we chose mini-batch processing with proper validation because:\n",
                "\n",
                "1. **Data Management**\n",
                "   ```python\n",
                "   # Training samples divided efficiently\n",
                "   Training:   364 samples ÷ 32 = 11.4 batches\n",
                "   Validation:  91 samples ÷ 32 = 2.8 batches\n",
                "   Test:       114 samples ÷ 32 = 3.6 batches\n",
                "   ```\n",
                "   - Each batch fits easily in memory\n",
                "   - Validation set provides stopping signal\n",
                "   - Test set gives unbiased evaluation\n",
                "\n",
                "2. **Learning Benefits**\n",
                "   ```python\n",
                "   # Each epoch processes:\n",
                "   11 training batches           # Learn from training data\n",
                "   3 validation batches          # Check for overfitting\n",
                "   4 test batches                # Monitor true performance\n",
                "   ```\n",
                "   - Frequent weight updates\n",
                "   - Regular validation checks\n",
                "   - Independent test monitoring\n",
                "\n",
                "3. **Production Features**\n",
                "   ```python\n",
                "   # Industry-standard practice\n",
                "   model.train()                # Enable training mode\n",
                "   for batch in train_loader:\n",
                "       train_step(batch)        # Update weights\n",
                "   \n",
                "   model.eval()                 # Disable training mode\n",
                "   validate(val_loader)         # Check progress\n",
                "   evaluate(test_loader)        # Monitor performance\n",
                "   ```\n",
                "   - Proper training/evaluation modes\n",
                "   - Scales well to larger datasets\n",
                "   - Ready for deployment\n",
                "\n",
                "<a name=\"understanding-the-adam-optimiser\"></a>\n",
                "### Understanding the Adam optimiser\n",
                "\n",
                "Now that we're processing our cancer data in mini-batches, we need a sophisticated way to learn from these groups of patients. While Lesson 1A used basic gradient descent:\n",
                "```python\n",
                "# Basic gradient descent from Lesson 1A:\n",
                "new_weight = old_weight - learning_rate * gradient\n",
                "```\n",
                "\n",
                "Our PyTorch implementation uses something smarter called Adam. The beauty of Adam is that it works whether we're learning from individual patients (stochastic), groups of patients (mini-batch), or all patients at once (full batch). To understand how it works, let's imagine two doctors learning from patient data: a trainee using basic gradient descent (from Lesson 1A), and Dr. Adam using adaptive learning.\n",
                "\n",
                "Here's how Dr. Adam thinks:\n",
                "1. Remember what they've learned from past patients (momentum)\n",
                "2. Know how much to trust each measurement (velocity)\n",
                "3. Learn effectively from the very first patient or batch (bias correction)\n",
                "\n",
                "#### The complete Adam formula:\n",
                "```python\n",
                "# 1. Build up memory of past gradients (momentum)\n",
                "m = β₁ * m + (1 - β₁) * gradient\n",
                "# where: β₁ = 0.9 (remember 90% of past, learn 10% new)\n",
                "#        m = momentum (our running average)\n",
                "#        gradient = what we're learning right now\n",
                "\n",
                "# 2. Track how consistent each feature is (velocity)\n",
                "v = β₂ * v + (1 - β₂) * gradient²\n",
                "# where: β₂ = 0.999 (even longer memory)\n",
                "#        v = velocity (running average of squared gradients)\n",
                "#        gradient² = squared to track size, ignore direction\n",
                "\n",
                "# 3. Fix the cold start problem (bias correction)\n",
                "m_corrected = m / (1 - β₁ᵗ)\n",
                "v_corrected = v / (1 - β₂ᵗ)\n",
                "# where: t = timestep (patient number: 1, 2, 3...)\n",
                "#        This powers β₁ and β₂ by t to undo early bias\n",
                "\n",
                "# 4. Combine everything for the final update\n",
                "new_weight = old_weight - learning_rate * m_corrected / sqrt(v_corrected + ε)\n",
                "# where: learning_rate = 0.001 (base step size)\n",
                "#        ε = 1e-8 (tiny number to prevent division by zero)\n",
                "```\n",
                "\n",
                "Let's see this in action with real cancer detection examples. These patterns emerge whether we're looking at individual patient samples, batches of samples or the whole cohort each epoch:\n",
                "\n",
                "#### Clear cancer indicator: cell radius\n",
                "```python\n",
                "# Each batch contains 32 samples of standardised measurements (mean=0, std=1)\n",
                "Samples batch 1: Large radii (2.1 std above mean) → cancer     # gradient = -0.5\n",
                "Samples batch 2: Large radii (1.9 std above mean) → cancer     # gradient = -0.4\n",
                "Samples batch 3: Large radii (2.3 std above mean) → cancer     # gradient = -0.6\n",
                "\n",
                "# Building momentum (m):\n",
                "Step 1 (t=1):\n",
                "m = 0.9 * 0 + 0.1 * (-0.5) = -0.05         # Raw momentum looks tiny\n",
                "correction = 1 - 0.9¹ = 0.1                 # β₁ to first power\n",
                "m_corrected = -0.05 / 0.1 = -0.5           # Much better!\n",
                "\n",
                "Step 2 (t=2):\n",
                "m = 0.9 * (-0.05) + 0.1 * (-0.4) = -0.085  # Still looks small\n",
                "correction = 1 - 0.9² = 1 - 0.81 = 0.19     # β₁ squared\n",
                "m_corrected = -0.085 / 0.19 = -0.447       # Strong signal maintained\n",
                "\n",
                "Step 3 (t=3):\n",
                "m = 0.9 * (-0.085) + 0.1 * (-0.6) = -0.137 # Growing\n",
                "correction = 1 - 0.9³ = 1 - 0.729 = 0.271   # β₁ cubed\n",
                "m_corrected = -0.137 / 0.271 = -0.506      # Clear cancer signal\n",
                "\n",
                "# Building velocity (v) - similar process with β₂:\n",
                "Step 1: v = 0.999 * 0 + 0.001 * 0.25 = 0.00025     # Tracking consistency\n",
                "Step 2: v = 0.999 * 0.00025 + 0.001 * 0.16 = 0.00040\n",
                "Step 3: v = 0.999 * 0.00040 + 0.001 * 0.36 = 0.00076\n",
                "```\n",
                "\n",
                "#### Tricky indicator: cell texture\n",
                "```python\n",
                "Samples batch 1: Rough textures (0.3 std above mean) → cancer     # gradient = +0.3\n",
                "Samples batch 2: Rough textures (0.4 std above mean) → not cancer # gradient = -0.4\n",
                "Samples batch 3: Rough textures (0.2 std above mean) → cancer     # gradient = +0.2\n",
                "\n",
                "# Building momentum (m):\n",
                "Step 1 (t=1):\n",
                "m = 0.9 * 0 + 0.1 * (0.3) = 0.03         # Small start\n",
                "correction = 1 - 0.9¹ = 0.1                # First power correction\n",
                "m_corrected = 0.03 / 0.1 = 0.3            # Full signal\n",
                "\n",
                "Step 2 (t=2):\n",
                "m = 0.9 * (0.03) + 0.1 * (-0.4) = -0.013  # Pattern breaks\n",
                "correction = 1 - 0.9² = 0.19               # Squared correction\n",
                "m_corrected = -0.013 / 0.19 = -0.068      # Weak signal (good!)\n",
                "\n",
                "Step 3 (t=3):\n",
                "m = 0.9 * (-0.013) + 0.1 * (0.2) = 0.008  # Very uncertain\n",
                "correction = 1 - 0.9³ = 0.271              # Cubed correction\n",
                "m_corrected = 0.008 / 0.271 = 0.029       # Still uncertain (perfect!)\n",
                "\n",
                "# Building velocity (v):\n",
                "Step 1: v = 0.999 * 0 + 0.001 * 0.09 = 0.00009     # Start tracking\n",
                "Step 2: v = 0.999 * 0.00009 + 0.001 * 0.16 = 0.00024\n",
                "Step 3: v = 0.999 * 0.00024 + 0.001 * 0.04 = 0.00028\n",
                "```\n",
                "\n",
                "Why is this so clever?\n",
                "\n",
                "1. **Momentum handles signal strength:**\n",
                "   - Clear patterns (radius) → strong momentum (-0.506)\n",
                "   - Mixed signals (texture) → weak momentum (0.029)\n",
                "\n",
                "2. **Velocity handles learning speed:**\n",
                "   - Consistent features (radius) → high velocity (0.00076) → small, precise steps\n",
                "   - Inconsistent features (texture) → low velocity (0.00028) → larger, exploratory steps\n",
                "\n",
                "3. **Bias correction handles cold starts:**\n",
                "   - Early steps (t=1,2,3): Strong correction (divide by 0.1, 0.19, 0.271)\n",
                "   - Later steps (t=10,20,50): Correction fades (0.651, 0.878, 0.995)\n",
                "\n",
                "In our training loop, this sophisticated learning happens with one line:\n",
                "```python\n",
                "optimiser = optim.Adam(\n",
                "    model.parameters(),\n",
                "    lr=0.001,           # Base learning rate\n",
                "    betas=(0.9, 0.999), # Our β₁ and β₂\n",
                "    eps=1e-8            # Our ε\n",
                ")\n",
                "```\n",
                "\n",
                "This combination of mini-batch processing and Adam optimisation gives us:\n",
                "- Efficient processing of patient data (thanks to batching)\n",
                "- Smart learning from each batch (thanks to Adam)\n",
                "- Reliable validation checks (thanks to our data split)\n",
                "\n",
                "The result? Our model:\n",
                "- Learns from fewer patients (229-509 vs 1000 in Lesson 1A)\n",
                "- Makes more reliable diagnoses (96.5% accuracy)\n",
                "- Handles both clear and subtle cancer indicators effectively\n",
                "\n",
                "Now let's see how this all comes together in our complete training process.\n",
                "\n",
                "<a name=\"understanding-the-training-process\"></a>\n",
                "## Understanding the training process\n",
                "\n",
                "Now that we understand our model's architecture and optimisation approach, let's review the full execution flow of the model's training and evaluation. Our training process combines mini-batch learning, validation-based stopping, and comprehensive monitoring:\n",
                "\n",
                "```python\n",
                "def train_model(\n",
                "    model: CancerClassifier,\n",
                "    training_loader: DataLoader,\n",
                "    validation_loader: DataLoader,\n",
                "    epochs: int = 1000,\n",
                "    lr: float = 0.001,\n",
                "    patience: int = 5\n",
                ") -> Tuple[CancerClassifier, Dict]:\n",
                "    criterion = nn.BCELoss()\n",
                "    optimiser = optim.Adam(model.parameters(), lr=lr)\n",
                "    \n",
                "    # Early stopping setup\n",
                "    best_val_loss = float('inf')\n",
                "    best_weights = None\n",
                "    no_improve = 0\n",
                "    \n",
                "    # Training history\n",
                "    history = {\n",
                "        'training_loss': [], 'validation_loss': [],\n",
                "        'training_acc': [], 'validation_acc': []\n",
                "    }\n",
                "    \n",
                "    for epoch in range(epochs):\n",
                "        # Training phase\n",
                "        model.train()\n",
                "        training_losses = []\n",
                "        training_correct = 0\n",
                "        training_total = 0\n",
                "        \n",
                "        for features_batch, labels_batch in training_loader:\n",
                "            predictions = model(features_batch)\n",
                "            loss = criterion(predictions, labels_batch)\n",
                "            \n",
                "            optimiser.zero_grad()\n",
                "            loss.backward()\n",
                "            optimiser.step()\n",
                "            \n",
                "            training_losses.append(loss.item())\n",
                "            training_correct += ((predictions > 0.5) == labels_batch).sum().item()\n",
                "            training_total += len(labels_batch)\n",
                "        \n",
                "        # Calculate epoch metrics\n",
                "        training_loss = sum(training_losses) / len(training_losses)\n",
                "        training_acc = training_correct / training_total\n",
                "        \n",
                "        # Validation phase\n",
                "        val_loss, val_acc = evaluate_model(model, validation_loader)\n",
                "        \n",
                "        # Store history\n",
                "        history['training_loss'].append(training_loss)\n",
                "        history['validation_loss'].append(val_loss)\n",
                "        history['training_acc'].append(training_acc)\n",
                "        history['validation_acc'].append(val_acc)\n",
                "        \n",
                "        # Early stopping check\n",
                "        if val_loss < best_val_loss:\n",
                "            best_val_loss = val_loss\n",
                "            best_weights = model.state_dict().copy()\n",
                "            no_improve = 0\n",
                "        else:\n",
                "            no_improve += 1\n",
                "            if no_improve == patience:\n",
                "                print(f'Early stopping at epoch {epoch+1}')\n",
                "                break\n",
                "    \n",
                "    # Restore best weights\n",
                "    model.load_state_dict(best_weights)\n",
                "    \n",
                "    return model, history\n",
                "```\n",
                "\n",
                "Let's examine each component of this training process:\n",
                "\n",
                "<a name=\"function-signature-and-inputs\"></a>\n",
                "### Function signature and inputs\n",
                "```python\n",
                "def train_model(\n",
                "    model: CancerClassifier,\n",
                "    training_loader: DataLoader,\n",
                "    validation_loader: DataLoader,\n",
                "    epochs: int = 1000,\n",
                "    lr: float = 0.001,\n",
                "    patience: int = 5\n",
                ") -> Tuple[CancerClassifier, Dict]:\n",
                "```\n",
                "\n",
                "The function takes our cancer classifier and two data loaders - one each for training and one for validation. We do not include a test loader as we will evaluate the final model on the test set after training. The epochs parameter sets maximum training iterations, lr controls learning speed, and patience determines how long we wait for improvement before stopping.\n",
                "\n",
                "<a name=\"setup-phase\"></a>\n",
                "### Setup phase\n",
                "```python\n",
                "criterion = nn.BCELoss()\n",
                "optimiser = optim.Adam(model.parameters(), lr=lr)\n",
                "\n",
                "# Early stopping setup\n",
                "best_val_loss = float('inf')\n",
                "best_weights = None\n",
                "no_improve = 0\n",
                "\n",
                "# Training history\n",
                "history = {\n",
                "    'training_loss': [], 'validation_loss': [],\n",
                "    'training_acc': [], 'validation_acc': []\n",
                "}\n",
                "```\n",
                "\n",
                "This initialisation sets up our training tools. The BCELoss (Binary Cross Entropy) measures how far our predictions are from the true diagnoses - a perfect prediction would give zero loss. The Adam optimiser handles weight updates intelligently, adjusting each weight's learning rate based on its gradient history. We initialise early stopping variables to track the best model we find, and create a history dictionary to store performance metrics for later analysis.\n",
                "\n",
                "<a name=\"training-phase\"></a>\n",
                "### Training phase\n",
                "```python\n",
                "for epoch in range(epochs):\n",
                "    # Training phase\n",
                "    model.train()\n",
                "    training_losses = []\n",
                "    training_correct = 0\n",
                "    training_total = 0\n",
                "    \n",
                "    for features_batch, labels_batch in training_loader:\n",
                "        predictions = model(features_batch)\n",
                "        loss = criterion(predictions, labels_batch)\n",
                "        \n",
                "        optimiser.zero_grad()\n",
                "        loss.backward()\n",
                "        optimiser.step()\n",
                "        \n",
                "        training_losses.append(loss.item())\n",
                "        training_correct += ((predictions > 0.5) == labels_batch).sum().item()\n",
                "        training_total += len(labels_batch)\n",
                "    \n",
                "    # Calculate epoch metrics\n",
                "    training_loss = sum(training_losses) / len(training_losses)\n",
                "    training_acc = training_correct / training_total\n",
                "```\n",
                "\n",
                "The training phase consists of two nested loops:\n",
                "\n",
                "1. **Epoch loop**: Iterates through the entire dataset multiple times\n",
                "   - Each epoch represents one complete pass through all training data\n",
                "   - Sets up tracking variables for this epoch's performance\n",
                "   - Maximum 1000 epochs, but early stopping usually triggers sooner\n",
                "\n",
                "2. **Batch loop**: Processes 32 samples at a time\n",
                "   - model.train() enables gradient tracking for learning\n",
                "   - Forward pass generates cancer predictions\n",
                "   - Loss function measures prediction errors\n",
                "   - optimiser.zero_grad() clears accumulated gradients\n",
                "   - loss.backward() computes new gradients\n",
                "   - optimiser.step() updates weights\n",
                "   - Metrics are tracked per batch for monitoring\n",
                "\n",
                "After processing all batches in an epoch:\n",
                "- Average loss is calculated from all batch losses\n",
                "- Total accuracy is computed from correct predictions\n",
                "- These metrics show how well the model learned this epoch\n",
                "\n",
                "<a name=\"validation-phase-and-early-stopping\"></a>\n",
                "### Validation phase and early stopping\n",
                "```python\n",
                "    val_loss, val_acc = evaluate_model(model, validation_loader)\n",
                "\n",
                "    # Store history\n",
                "    history['training_loss'].append(training_loss)\n",
                "    history['validation_loss'].append(val_loss)\n",
                "    history['training_acc'].append(training_acc)\n",
                "    history['validation_acc'].append(val_acc)\n",
                "\n",
                "    # Early stopping check \n",
                "    # best_val_loss variable and no_improve counter variable initialised in setup\n",
                "    if val_loss < best_val_loss:\n",
                "        best_val_loss = val_loss\n",
                "        best_weights = model.state_dict().copy()\n",
                "        no_improve = 0\n",
                "    else:\n",
                "        no_improve += 1\n",
                "        if no_improve == patience:\n",
                "            print(f'Early stopping at epoch {epoch+1}')\n",
                "            break\n",
                "\n",
                "# Restore best weights\n",
                "model.load_state_dict(best_weights)\n",
                "\n",
                "return model, history\n",
                "```\n",
                "\n",
                "After each epoch, we check if our model is actually learning useful patterns by testing it on unseen validation data. Using the variables initialised in our setup phase - best_val_loss (tracking our best performance), best_weights (storing the model's state), and no_improve (counting epochs without improvement) - we can implement early stopping. If validation loss improves, we save those model weights as our best so far. If we go 5 epochs (our patience limit) without improvement, we stop training early - this prevents overfitting by catching the point where the model stops learning general patterns and starts memorising training data. Once training is complete, we restore the best weights and return the final model and its training history.\n",
                "\n",
                "<a name=\"final-evaluation\"></a>\n",
                "### Final evaluation\n",
                "```python\n",
                "# Train model using only training and validation data\n",
                "model, history = train_model(\n",
                "    model, \n",
                "    training_loader,\n",
                "    validation_loader\n",
                ")\n",
                "\n",
                "# Final test set evaluation\n",
                "test_loss, test_acc = evaluate_model(model, test_loader)\n",
                "...\n",
                "# Create test metrics dict for visualisation\n",
                "test_metrics = {\n",
                "    'test_loss': test_loss,\n",
                "    'test_acc': test_acc\n",
                "}\n",
                "\n",
                "# Plot final curves including test performance\n",
                "plot_training_curves(history, test_metrics)\n",
                "```\n",
                "\n",
                "Once training is complete, we evaluate the model on the test set. This gives us an unbiased estimate of how well our model will perform on completely new data, since we never used the test set for any training decisions. We combine the test metrics with the training history and then plot the results for a comprehensive visualisation.\n",
                "\n",
                "<a name=\"monitoring-training-progress\"></a>\n",
                "### Monitoring training progress\n",
                "\n",
                "To understand how our model learns, we need to visualise its progress effectively. Our monitoring system creates side-by-side plots of loss and accuracy:\n",
                "\n",
                "```python\n",
                "def plot_training_curves(history: Dict[str, List[float]], test_metrics: Optional[Dict[str, float]] = None) -> None:\n",
                "    \"\"\"Visualise training progression with optional test results.\n",
                "    \n",
                "    Creates side-by-side plots of:\n",
                "    1. Loss curves - Shows learning progression\n",
                "    2. Accuracy curves - Shows diagnostic performance\n",
                "    \n",
                "    Args:\n",
                "        history: Dict containing training/validation metrics\n",
                "        test_metrics: Optional dict containing test loss and accuracy\n",
                "    \"\"\"\n",
                "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
                "    \n",
                "    # Loss curves\n",
                "    ax1.plot(history['training_loss'], label='Training')\n",
                "    ax1.plot(history['validation_loss'], label='Validation')\n",
                "    if test_metrics:\n",
                "        ax1.axhline(y=test_metrics['test_loss'], color='r', \n",
                "                   linestyle='--', label='Final Test')\n",
                "    ax1.set_title('Loss Over Time')\n",
                "    ax1.set_xlabel('Epoch')\n",
                "    ax1.set_ylabel('Binary Cross Entropy Loss')\n",
                "    ax1.legend()\n",
                "    ax1.grid(True)\n",
                "    \n",
                "    # Accuracy curves\n",
                "    ax2.plot(history['training_acc'], label='Training')\n",
                "    ax2.plot(history['validation_acc'], label='Validation')\n",
                "    if test_metrics:\n",
                "        ax2.axhline(y=test_metrics['test_acc'], color='r', \n",
                "                   linestyle='--', label='Final Test')\n",
                "    ax2.set_title('Accuracy Over Time')\n",
                "    ax2.set_xlabel('Epoch')\n",
                "    ax2.set_ylabel('Accuracy')\n",
                "    ax2.legend()\n",
                "    ax2.grid(True)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "```\n",
                "\n",
                "These visualisations provide three key insights:\n",
                "\n",
                "1. **Learning Progress**\n",
                "   - Loss curves show how well the model is fitting\n",
                "   - Sharp initial drop indicates rapid learning\n",
                "   - Gradual flattening shows diminishing returns\n",
                "   - Gap between training and validation indicates fit quality\n",
                "\n",
                "2. **Model Convergence**\n",
                "   - Accuracy curves show diagnostic capability\n",
                "   - Training accuracy shows basic learning capacity\n",
                "   - Validation accuracy shows generalisation\n",
                "   - Test performance shows real-world capability\n",
                "\n",
                "3. **Early Stopping Impact**\n",
                "   - Validation curves reveal optimal stopping point\n",
                "   - Best model found before overfitting begins\n",
                "   - Test performance validates stopping decision\n",
                "   - Clear visualisation of model stability\n",
                "\n",
                "Let's examine how these mechanisms drive our model's learning process.\n",
                "\n",
                "<a name=\"understanding-learning-dynamics\"></a>\n",
                "## Understanding learning dynamics\n",
                "\n",
                "Let's examine how our model's performance evolves throughout training by monitoring its metrics at different phases. Our monitoring tools reveal a consistent learning pattern:\n",
                "\n",
                "### Initial learning phase\n",
                "During the first few epochs, the model moves from random guessing to basic pattern recognition:\n",
                "```python\n",
                "Epoch 1/1000:\n",
                "    Training Loss: 0.693, Accuracy: 0.512  # Random initialisation\n",
                "    Validation Loss: 0.685, Accuracy: 0.527\n",
                "\n",
                "Epoch 10/1000:\n",
                "    Training Loss: 0.423, Accuracy: 0.789  # Basic patterns emerging\n",
                "    Validation Loss: 0.412, Accuracy: 0.775\n",
                "```\n",
                "\n",
                "The initial 0.693 loss is exactly what we expect for binary classification with random weights - it represents maximum uncertainty (50-50 guesses). The rapid improvement by epoch 10 shows our model is discovering meaningful patterns in the cell measurements.\n",
                "\n",
                "### Main learning phase\n",
                "By epoch 50, the model starts showing strong diagnostic capability:\n",
                "```python\n",
                "Epoch 50/1000:\n",
                "    Training Loss: 0.234, Accuracy: 0.892  # Strong learning\n",
                "    Validation Loss: 0.245, Accuracy: 0.878\n",
                "\n",
                "Epoch 100/1000:\n",
                "    Training Loss: 0.156, Accuracy: 0.945  # Refined patterns\n",
                "    Validation Loss: 0.165, Accuracy: 0.934\n",
                "```\n",
                "\n",
                "During this phase:\n",
                "- Loss drops substantially as predictions become more confident\n",
                "- Accuracy climbs as the model learns to distinguish cancer indicators\n",
                "- Training and validation metrics remain close, showing good generalisation\n",
                "- The model learns to weight different cell measurements appropriately\n",
                "\n",
                "### Fine-tuning phase\n",
                "The later epochs show more subtle improvements:\n",
                "```python\n",
                "Epoch 300/1000:\n",
                "    Training Loss: 0.042, Accuracy: 0.982  # Polishing performance\n",
                "    Validation Loss: 0.048, Accuracy: 0.967\n",
                "```\n",
                "\n",
                "Key observations:\n",
                "- Learning rate slows as model approaches optimal performance\n",
                "- Small gap between training and validation metrics indicates good fit\n",
                "- Model maintains strong generalisation without overfitting\n",
                "- Predictions become increasingly confident\n",
                "\n",
                "### Early stopping patterns\n",
                "A typical stopping sequence looks like this:\n",
                "```python\n",
                "Epoch 342: val_loss = 0.048  # Best performance\n",
                "Epoch 343: val_loss = 0.051  # Counter = 1\n",
                "Epoch 344: val_loss = 0.053  # Counter = 2\n",
                "Epoch 345: val_loss = 0.054  # Counter = 3\n",
                "Epoch 346: val_loss = 0.056  # Counter = 4\n",
                "Epoch 347: val_loss = 0.057  # Stop, revert to epoch 342\n",
                "```\n",
                "\n",
                "Our patience of 5 epochs ensures we don't stop too early, while preventing overfitting by catching the point where validation performance starts to degrade.\n",
                "\n",
                "### Performance stability\n",
                "Over 10 complete training runs with different random initialisations:\n",
                "```python\n",
                "Training metrics (364 samples):\n",
                "    Accuracy: 98.63-98.90%\n",
                "    Loss: 0.042-0.048\n",
                "    Convergence: 229-509 epochs\n",
                "\n",
                "Validation metrics (91 samples):\n",
                "    Accuracy: 97.80%\n",
                "    Loss: 0.051-0.058\n",
                "\n",
                "Test metrics (114 samples):\n",
                "    Accuracy: 94.74-97.37%\n",
                "    Loss: 0.082-0.095\n",
                "```\n",
                "\n",
                "These results show:\n",
                "1. Consistent high performance across different initialisations\n",
                "2. Strong generalisation to validation data\n",
                "3. Reliable final test set performance\n",
                "4. Variable convergence speed\n",
                "\n",
                "The variation in stopping epochs (229-509) and test accuracy (94.74-97.37%) suggests potential for improvement through hyperparameter optimisation.\n",
                "\n",
                "\n",
                "### Preparation for optimisation\n",
                "\n",
                "Our implementation achieves strong but variable performance. Let's analyse our current settings and identify opportunities for optimisation:\n",
                "\n",
                "### Current performance baseline\n",
                "```python\n",
                "Model performance over 10 runs:\n",
                "    Training accuracy:   98.63-98.90%  # Learning capability\n",
                "    Validation accuracy: ~97.80%       # Generalisation indicator\n",
                "    Test accuracy:       94.74-97.37%  # Real-world performance\n",
                "    Convergence speed:   229-509 epochs\n",
                "```\n",
                "\n",
                "### Learning rate configuration\n",
                "Current implementation:\n",
                "```python\n",
                "optimiser = optim.Adam(model.parameters(), lr=0.001)  # Default rate\n",
                "```\n",
                "\n",
                "The wide range in convergence times (229-509 epochs) suggests our learning rate might not be optimal:\n",
                "- Higher rates could speed up initial learning\n",
                "- Lower rates might provide more stable final performance\n",
                "- Learning rate schedules could combine fast learning with stability\n",
                "\n",
                "We should investigate rates between 0.0001 and 0.01 to find the optimal balance.\n",
                "\n",
                "### Batch size effects\n",
                "Current implementation:\n",
                "```python\n",
                "batch_size = 32  # Processes 32 samples per update\n",
                "training_loader = DataLoader(\n",
                "    training_dataset, \n",
                "    batch_size=batch_size,\n",
                "    shuffle=True\n",
                ")\n",
                "```\n",
                "\n",
                "Our batch size choice affects several aspects:\n",
                "1. **Gradient quality**\n",
                "   - Larger batches (64, 128): More stable gradients\n",
                "   - Smaller batches (16, 8): More noise, might escape local minima\n",
                "\n",
                "2. **Training speed**\n",
                "   - Current: ~11 updates per epoch (364/32)\n",
                "   - Smaller batches: More frequent updates\n",
                "   - Larger batches: Better parallelisation\n",
                "\n",
                "3. **Memory usage**\n",
                "   - Current: 32 * 30 features = 960 values per batch\n",
                "   - Scales linearly with batch size\n",
                "   - Important for larger datasets\n",
                "\n",
                "### Early stopping configuration\n",
                "Current implementation:\n",
                "```python\n",
                "patience = 5  # Stop after 5 non-improving epochs\n",
                "```\n",
                "\n",
                "Our patience value affects training dynamics:\n",
                "- Too low (3): Might stop before finding better solutions\n",
                "- Too high (10): Wastes computation\n",
                "- Current (5): Might not be optimal for all learning rates\n",
                "\n",
                "### Systematic optimisation plan\n",
                "We should investigate:\n",
                "1. **Learning rates**\n",
                "   - Test: [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
                "   - Measure: Convergence speed, final accuracy\n",
                "\n",
                "2. **Batch sizes**\n",
                "   - Test: [16, 32, 64, 128]\n",
                "   - Measure: Training stability, resource usage\n",
                "\n",
                "3. **Patience values**\n",
                "   - Test: [3, 5, 7, 10]\n",
                "   - Measure: Final performance, training time\n",
                "\n",
                "Note on weight initialisation: While we could test different initialisation strategies (e.g., normal, uniform, or other Xavier variants), our current Xavier initialisation provides stable results. Given our focus on practical improvements, we'll maintain our current initialisation and focus on the hyperparameters that more directly affect training dynamics.\n",
                "\n",
                "In the next section, we'll implement this optimisation plan using a systematic grid search approach."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a name=\"model-hyperparameter-optimisation\"></a>\n",
                "## Model hyperparameter optimisation\n",
                "\n",
                "Our initial implementation achieves test accuracy between 94.74% and 97.37%, but takes anywhere from 229 to 509 epochs to converge.\n",
                "\n",
                "Let's create a framework to explore how different hyperparameters - learning rates, batch sizes and patience values - affect these results. For educational purposes, we'll conduct an extensive grid search testing 80 different combinations:\n",
                "\n",
                "- Learning rates: 0.0001, 0.001, 0.01, 0.1\n",
                "- Batch sizes: 16, 32, 64, 128, 256\n",
                "- Patience values: 3, 5, 7, 9\n",
                "\n",
                "This is admittedly excessive for a real-world scenario - with 80 combinations each training for up to 1000 epochs, we're potentially running 80,000 training iterations. However, by exploring this large parameter space, we'll gain valuable insights into how these hyperparameters interact and affect model performance.\n",
                "\n",
                "We'll implement a ModelOptimiser class that runs controlled experiments, along with visualisations to help us understand how these choices impact model performance. Our goal is to find settings that provide both reliable accuracy and consistent training times."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ModelOptimiser:\n",
                "    \"\"\"Systematic optimisation framework for cancer detection models.\"\"\"\n",
                "    \n",
                "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
                "        self.X_train = X_train\n",
                "        self.y_train = y_train\n",
                "        self.X_val = X_val\n",
                "        self.y_val = y_val\n",
                "        self.X_test = X_test\n",
                "        self.y_test = y_test\n",
                "        self.results = []\n",
                "    \n",
                "    def run_experiments(self, \n",
                "                       learning_rates=[0.0001, 0.001, 0.01, 0.1],\n",
                "                       batch_sizes=[16, 32, 64, 128, 256],\n",
                "                       patience_values=[3, 5, 7, 9]):\n",
                "        \"\"\"Run systematic grid search across hyperparameters.\"\"\"\n",
                "        \n",
                "        total_combinations = len(learning_rates) * len(batch_sizes) * len(patience_values)\n",
                "        current_combination = 0\n",
                "        \n",
                "        for lr in learning_rates:\n",
                "            for batch_size in batch_sizes:\n",
                "                for patience in patience_values:\n",
                "                    current_combination += 1\n",
                "                    print(f\"\\nTesting combination {current_combination}/{total_combinations}\")\n",
                "                    print(f\"LR: {lr}, Batch Size: {batch_size}, Patience: {patience}\")\n",
                "                    \n",
                "                    # Create datasets and loaders\n",
                "                    train_dataset = CancerDataset(self.X_train, self.y_train)\n",
                "                    val_dataset = CancerDataset(self.X_val, self.y_val)\n",
                "                    test_dataset = CancerDataset(self.X_test, self.y_test)\n",
                "                    \n",
                "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
                "                    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
                "                    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
                "                    \n",
                "                    # Train model with these hyperparameters\n",
                "                    model = CancerClassifier(input_features=self.X_train.shape[1])\n",
                "                    trained_model, history = train_model(\n",
                "                        model, train_loader, val_loader,\n",
                "                        epochs=1000, lr=lr, patience=patience\n",
                "                    )\n",
                "                    \n",
                "                    # Evaluate on test set\n",
                "                    test_loss, test_acc = evaluate_model(model, test_loader)\n",
                "                    \n",
                "                    # Record results\n",
                "                    self.results.append({\n",
                "                        'learning_rate': lr,\n",
                "                        'batch_size': batch_size,\n",
                "                        'patience': patience,\n",
                "                        'val_accuracy': max(history['validation_acc']),\n",
                "                        'test_accuracy': test_acc,\n",
                "                        'val_loss': min(history['validation_loss']),\n",
                "                        'test_loss': test_loss,\n",
                "                        'convergence_epoch': len(history['validation_acc']),\n",
                "                        'history': history\n",
                "                    })\n",
                "        \n",
                "        return pd.DataFrame(self.results)\n",
                "\n",
                "    def plot_results(self, results_df):\n",
                "        \"\"\"Create comprehensive visualisation of optimisation results.\"\"\"\n",
                "        fig = plt.figure(figsize=(8, 20))\n",
                "        \n",
                "        # Plot 1: Heatmap of test accuracy\n",
                "        plt.subplot(3, 1, 1)\n",
                "        pivot_acc = results_df.pivot_table(\n",
                "            values='test_accuracy',\n",
                "            index='batch_size',\n",
                "            columns='learning_rate',\n",
                "            aggfunc='max'  # Best accuracy for each learning rate/batch size combo\n",
                "        )\n",
                "        sns.heatmap(pivot_acc, annot=True, fmt='.3f', cmap='viridis')\n",
                "        plt.title('Best Test Accuracy for each Learning Rate/Batch Size')\n",
                "        \n",
                "        # Plot 2: Heatmap of convergence epochs\n",
                "        plt.subplot(3, 1, 2)\n",
                "        pivot_epoch = results_df.pivot_table(\n",
                "            values='convergence_epoch',\n",
                "            index='batch_size',\n",
                "            columns='learning_rate',\n",
                "            aggfunc='min'  # Fastest convergence for each combo\n",
                "        )\n",
                "        sns.heatmap(pivot_epoch, annot=True, fmt='.0f', cmap='viridis_r')\n",
                "        plt.title('Fastest Convergence (epochs) for each Configuration')\n",
                "        \n",
                "        # Plot 3: Training curves for top 5 configurations\n",
                "        plt.subplot(3, 1, 3)\n",
                "        top_configs = results_df.nlargest(5, 'test_accuracy')\n",
                "        for idx, row in top_configs.iterrows():\n",
                "            history = row['history']\n",
                "            plt.plot(history['validation_acc'], \n",
                "                    label=f'LR={row[\"learning_rate\"]}, Batch={row[\"batch_size\"]}, P={row[\"patience\"]}')\n",
                "        plt.xlabel('Epoch')\n",
                "        plt.ylabel('Validation Accuracy')\n",
                "        plt.title('Training Curves - Top 5 Configurations')\n",
                "        plt.grid(True)\n",
                "        plt.legend()\n",
                "        \n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "        \n",
                "        # Print patience analysis table\n",
                "        patience_impact = results_df.groupby('patience').agg({\n",
                "            'test_accuracy': ['mean', 'std', 'max'],\n",
                "            'convergence_epoch': 'mean'\n",
                "        }).round(3)\n",
                "        patience_impact.columns = ['Mean Test Accuracy', 'Standard Deviation', 'Maximum Test Accuracy', 'Average Epochs']\n",
                "        print(\"\\nImpact of Patience Values:\")\n",
                "        display(patience_impact)\n",
                "        \n",
                "        # Return top configurations without history\n",
                "        return results_df[['learning_rate', 'batch_size', 'patience', \n",
                "                          'val_accuracy', 'test_accuracy', 'convergence_epoch']]\\\n",
                "            .sort_values('test_accuracy', ascending=False)\\\n",
                "            .head()\n",
                "\n",
                "# Run optimisation experiments\n",
                "optimiser = ModelOptimiser(training_features_scaled, training_labels,\n",
                "                          validation_features_scaled, validation_labels,\n",
                "                          test_features_scaled, test_labels)\n",
                "\n",
                "# Run grid search with extended parameter ranges\n",
                "results = optimiser.run_experiments(\n",
                "    learning_rates=[0.0001, 0.001, 0.01, 0.1],\n",
                "    batch_sizes=[16, 32, 64, 128, 256],\n",
                "    patience_values=[3, 5, 7, 9]\n",
                ")\n",
                "print(results.to_string())\n",
                "# Plot results\n",
                "top_configs = optimiser.plot_results(results)\n",
                "\n",
                "print(\"\\nTop Configurations:\")\n",
                "display(top_configs)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Optimisation results\n",
                "\n",
                "Running our systematic optimisation took about 5 minutes (T4 GPU) and 7 minutes (CPU) in Google Colab on using its free compute environment. For those with access to a mid-range gaming GPU, the same grid search completes in around 4 minutes. These relatively quick execution times highlight how logistic regression's simplicity allows us to thoroughly explore different training approaches - something that becomes prohibitively expensive with deeper neural networks where a single configuration might train for hours even on high-end hardware.\n",
                "\n",
                "The speed of our grid search, even in Colab's free environment, makes this kind of thorough hyperparameter exploration practical for students and researchers. The occasional print statements for monitoring progress had negligible impact on execution time - the computational tasks of forward passes, loss calculations, gradient computations, and weight updates dominated the runtime.\n",
                "\n",
                "### The learning rate's crucial role\n",
                "\n",
                "The learning rate proved to be the most influential parameter in our experiments, with some surprising results thanks to the Adam optimiser. Our slowest rate of 0.0001 consistently maxed out at 1000 epochs without proper convergence, though it eventually achieved respectable accuracy of 97.37%. This matches what we saw in Lesson 1A - too small a step size and our model inches toward the solution.\n",
                "\n",
                "At the other extreme, a learning rate of 0.1 produced our highest accuracy of 98.25%, converging in just 15 epochs. This remarkably fast convergence, which might seem risky at first glance, is made possible by Adam's adaptive learning rates. Unlike the basic gradient descent we implemented in Lesson 1A, Adam adjusts the effective learning rate for each parameter based on gradient history. This allows it to:\n",
                "1. Take large steps when gradients are consistent\n",
                "2. Take smaller steps when gradients oscillate\n",
                "3. Adapt differently for each feature\n",
                "4. Maintain stability even with high initial learning rates\n",
                "\n",
                "The middle ground of 0.001 still proved most reliable, consistently achieving 96-97% accuracy across different batch sizes and typically converging between 235-696 epochs. This matches common practice - start conservative with learning rates around 0.001, but don't be afraid to experiment with higher rates when using Adam.\n",
                "\n",
                "### Batch size considerations\n",
                "\n",
                "Our exploration of batch sizes revealed an interesting pattern: smaller batches of 16-32 samples consistently outperformed larger groupings. With 16 samples per batch, our model achieved the top three accuracy scores in our entire grid search, regardless of other parameters.\n",
                "\n",
                "This might seem counterintuitive - surely processing more data at once would help? The key insight is that smaller batches provide more frequent feedback during training. With our dataset of 364 training samples, a batch size of 16 gives us 22 weight updates per epoch, while a batch size of 256 provides only 1 update. Those extra course corrections early in training seem to guide the model toward better final performance.\n",
                "\n",
                "The optimal batch size depends heavily on the specific problem, available memory, and optimisation dynamics. While our cancer dataset achieved best results with small batches, other applications might benefit from larger ones to stabilize training or handle larger scale data. This highlights why testing multiple batch sizes matters - the best choice emerges from systematic experimentation rather than theoretical assumptions.\n",
                "\n",
                "### The patience factor\n",
                "\n",
                "The role of patience in early stopping revealed interesting patterns. Looking at our top-performing configurations:\n",
                "\n",
                "```python\n",
                "Patience  Mean Acc  Std Dev  Max Acc   Avg Epochs\n",
                "3         0.960    0.014    0.974     430.8\n",
                "5         0.957    0.017    0.974     443.6\n",
                "7         0.959    0.017    0.982     463.1\n",
                "9         0.951    0.036    0.974     456.0\n",
                "```\n",
                "\n",
                "While the differences in mean accuracy are small, we observe that patience values between 3-7 epochs provide similar performance with low variability (standard deviations around 0.014-0.017). The slightly lower mean accuracy and higher variability at patience=9 might suggest diminishing returns from longer waiting periods, though the differences aren't large enough to draw definitive conclusions given our dataset size.\n",
                "\n",
                "This pattern aligns with logistic regression's convex optimisation landscape - unlike neural networks with their complex loss surfaces, our model tends to either find improvements quickly or not at all. A patience value of 5 epochs provides a good balance between allowing the model to find better solutions and maintaining efficient training times.\n",
                "\n",
                "### Practical recommendations\n",
                "\n",
                "After exploring these 80 combinations, we can recommend two configurations depending on priorities:\n",
                "\n",
                "For maximum accuracy:\n",
                "```python\n",
                "learning_rate = 0.1\n",
                "batch_size = 16\n",
                "patience = 7\n",
                "```\n",
                "\n",
                "This achieved our best test accuracy of 98.25% in just 15 epochs, though it might prove too aggressive for different datasets.\n",
                "\n",
                "For reliable production use:\n",
                "```python\n",
                "learning_rate = 0.001\n",
                "batch_size = 32\n",
                "patience = 5\n",
                "```\n",
                "\n",
                "This more conservative approach consistently achieves 97% accuracy with stable convergence, making it suitable for clinical deployment where reliability matters more than squeezing out that last 1% of accuracy.\n",
                "\n",
                "The ability to thoroughly explore these options in just a few minutes, even in free environments like Google Colab, demonstrates one of logistic regression's key advantages - while more complex models might achieve higher accuracy on difficult problems, their training dynamics require much more careful tuning with far longer experimentation times."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a name=\"model-evaluation\"></a>\n",
                "## Model evaluation\n",
                "Now that we have optimised our model, let's build a comprehensive evaluation framework to understand its performance. We'll create a ModelEvaluator class that provides:\n",
                "\n",
                "1. Standard performance metrics (accuracy, precision, recall, F1 score)\n",
                "2. Clear visualisations including confusion matrices and ROC curves\n",
                "3. Confidence distribution analysis\n",
                "4.Decision threshold analysis capabilities\n",
                "\n",
                "By thoroughly evaluating our model's performance across multiple metrics, we'll gain a complete understanding of its strengths and limitations. This evaluation framework will also serve as a foundation for evaluating more complex neural networks in future lessons.\n",
                "\n",
                "Let's implement this framework with proper PyTorch practices, focusing on clear visualisations and efficient metric calculations:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ModelEvaluator:\n",
                "    \"\"\"Comprehensive evaluation framework for binary classification models in PyTorch.\n",
                "    \n",
                "    Provides methods for computing metrics, generating visualisations,\n",
                "    and analysing model performance across different decision thresholds.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, model: nn.Module, X_test: np.ndarray, y_test: np.ndarray):\n",
                "        \"\"\"Initialise evaluator with a trained model and test data.\"\"\"\n",
                "        self.model = model\n",
                "        self.X_test = X_test\n",
                "        self.y_test = y_test\n",
                "        \n",
                "    def evaluate_metrics(self) -> Dict[str, float]:\n",
                "        \"\"\"Calculate and return dictionary of performance metrics.\"\"\"\n",
                "        with torch.no_grad():\n",
                "            X_tensor = torch.FloatTensor(self.X_test)\n",
                "            probabilities = self.model(X_tensor).numpy().flatten()\n",
                "            predictions = (probabilities > 0.5).astype(int)\n",
                "            \n",
                "            return {\n",
                "                'accuracy': accuracy_score(self.y_test, predictions),\n",
                "                'precision': precision_score(self.y_test, predictions),\n",
                "                'recall': recall_score(self.y_test, predictions),\n",
                "                'f1': f1_score(self.y_test, predictions),\n",
                "                'roc_auc': roc_auc_score(self.y_test, probabilities)\n",
                "            }\n",
                "    \n",
                "    def plot_roc_curve(self):\n",
                "        \"\"\"Plot the ROC curve and display AUC score.\"\"\"\n",
                "        with torch.no_grad():\n",
                "            probabilities = self.model(torch.FloatTensor(self.X_test)).numpy().flatten()\n",
                "        \n",
                "        false_positive_rate, true_positive_rate, _ = roc_curve(self.y_test, probabilities)\n",
                "        roc_auc = auc(false_positive_rate, true_positive_rate)\n",
                "        \n",
                "        plt.figure(figsize=(8, 6))\n",
                "        plt.plot(false_positive_rate, true_positive_rate, color='darkorange', lw=2, \n",
                "                label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
                "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
                "                label='Random chance')\n",
                "        plt.xlim([0.0, 1.0])\n",
                "        plt.ylim([0.0, 1.05])\n",
                "        plt.xlabel('False Positive Rate')\n",
                "        plt.ylabel('True Positive Rate')\n",
                "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
                "        plt.legend(loc=\"lower right\")\n",
                "        plt.grid(True, alpha=0.3)\n",
                "        plt.show()\n",
                "        \n",
                "    def plot_confusion_matrix(self):\n",
                "        \"\"\"Plot confusion matrix showing prediction error patterns.\"\"\"\n",
                "        with torch.no_grad():\n",
                "            predictions = (self.model(torch.FloatTensor(self.X_test)).numpy().flatten() > 0.5).astype(int)\n",
                "            \n",
                "        confusion_mat = confusion_matrix(self.y_test, predictions)\n",
                "        plt.figure(figsize=(8, 6))\n",
                "        sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues')\n",
                "        plt.title('Confusion Matrix')\n",
                "        plt.ylabel('True Label')\n",
                "        plt.xlabel('Predicted Label')\n",
                "        plt.show()\n",
                "        \n",
                "    def analyse_confidence_distribution(self):\n",
                "        \"\"\"Plot distribution of model's prediction confidence for each class.\"\"\"\n",
                "        with torch.no_grad():\n",
                "            probabilities = self.model(torch.FloatTensor(self.X_test)).numpy().flatten()\n",
                "            \n",
                "        plt.figure(figsize=(8, 6))\n",
                "        for label in [0, 1]:\n",
                "            mask = self.y_test == label\n",
                "            plt.hist(probabilities[mask], bins=20, alpha=0.5,\n",
                "                    label=f'Class {label}',\n",
                "                    density=True)\n",
                "        plt.xlabel('Predicted Probability')\n",
                "        plt.ylabel('Density')\n",
                "        plt.title('Distribution of Model Confidence by True Class')\n",
                "        plt.legend()\n",
                "        plt.grid(True, alpha=0.3)\n",
                "        plt.show()\n",
                "        \n",
                "    def analyse_thresholds(self, thresholds=[0.3, 0.5, 0.7]) -> pd.DataFrame:\n",
                "        \"\"\"Analyse model performance using different decision thresholds.\"\"\"\n",
                "        with torch.no_grad():\n",
                "            probabilities = self.model(torch.FloatTensor(self.X_test)).numpy().flatten()\n",
                "            \n",
                "        results = []\n",
                "        for threshold in thresholds:\n",
                "            predictions = (probabilities > threshold).astype(int)\n",
                "            results.append({\n",
                "                'threshold': threshold,\n",
                "                'accuracy': accuracy_score(self.y_test, predictions),\n",
                "                'precision': precision_score(self.y_test, predictions),\n",
                "                'recall': recall_score(self.y_test, predictions),\n",
                "                'f1': f1_score(self.y_test, predictions)\n",
                "            })\n",
                "            \n",
                "        return pd.DataFrame(results).set_index('threshold')\n",
                "\n",
                "# Create evaluator instance\n",
                "evaluator = ModelEvaluator(model, test_features_scaled, test_labels)\n",
                "\n",
                "# Get overall performance metrics\n",
                "print(\"\\nModel Performance Metrics:\")\n",
                "metrics = evaluator.evaluate_metrics()\n",
                "for metric, value in metrics.items():\n",
                "    print(f\"{metric}: {value:.3f}\")\n",
                "\n",
                "# Plot ROC curve\n",
                "evaluator.plot_roc_curve()\n",
                "\n",
                "# Plot confusion matrix\n",
                "evaluator.plot_confusion_matrix()\n",
                "\n",
                "# Plot confidence distribution\n",
                "evaluator.analyse_confidence_distribution()\n",
                "\n",
                "# Analyse different decision thresholds\n",
                "threshold_results = evaluator.analyse_thresholds([0.3, 0.4, 0.5, 0.6, 0.7])\n",
                "print(threshold_results)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a name=\"how-to-evaluate-a-classification-model\"></a>\n",
                "## How to evaluate a classification model\n",
                "\n",
                "After training a model, thorough evaluation helps us understand its strengths and limitations. Let's explore each evaluation method and what it tells us about our model's performance.\n",
                "\n",
                "<a name=\"basic-classification-terms\"></a>\n",
                "### Basic classification terms\n",
                "\n",
                "First, let's understand the four possible prediction outcomes:\n",
                "\n",
                "#### True Positive (TP)\n",
                "- Model predicted positive (1) and actual was positive (1)\n",
                "- In our case: Model correctly identified a sample as class 1\n",
                "- Our model had 68 true positives\n",
                "\n",
                "#### True Negative (TN)\n",
                "- Model predicted negative (0) and actual was negative (0)\n",
                "- In our case: Model correctly identified a sample as class 0\n",
                "- Our model had 41 true negatives\n",
                "\n",
                "#### False Positive (FP) - Type I Error\n",
                "- Model predicted positive (1) but actual was negative (0)\n",
                "- Also called a \"false alarm\" or \"Type I error\"\n",
                "- Our model had 1 false positive\n",
                "\n",
                "#### False Negative (FN) - Type II Error\n",
                "- Model predicted negative (0) but actual was positive (1)\n",
                "- Also called a \"miss\" or \"Type II error\"\n",
                "- Our model had 4 false negatives\n",
                "\n",
                "<a name=\"core-performance-metrics\"></a>\n",
                "### Core performance metrics\n",
                "\n",
                "Our model achieved:\n",
                "- Accuracy: 0.956 (95.6%)\n",
                "- Precision: 0.986 (98.6%)\n",
                "- Recall: 0.944 (94.4%)\n",
                "- F1 Score: 0.965 (96.5%)\n",
                "- ROC-AUC: 0.994 (99.4%)\n",
                "\n",
                "Let's understand what each metric means and how it's calculated:\n",
                "\n",
                "#### Accuracy\n",
                "The proportion of correct predictions among all predictions.\n",
                "\n",
                "Formula: $Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$\n",
                "\n",
                "For our model: $\\frac{68 + 41}{68 + 41 + 1 + 4} = 0.956$\n",
                "\n",
                "#### Precision\n",
                "Of all cases our model predicted as positive, what proportion were actually positive.\n",
                "\n",
                "Formula: $Precision = \\frac{TP}{TP + FP}$\n",
                "\n",
                "For our model: $\\frac{68}{68 + 1} = 0.986$\n",
                "\n",
                "#### Recall (Sensitivity)\n",
                "Of all actual positive cases, what proportion did our model identify.\n",
                "\n",
                "Formula: $Recall = \\frac{TP}{TP + FN}$\n",
                "\n",
                "For our model: $\\frac{68}{68 + 4} = 0.944$\n",
                "\n",
                "#### F1 score\n",
                "The harmonic mean of precision and recall, providing a balanced measure.\n",
                "\n",
                "Formula: $F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$\n",
                "\n",
                "For our model: $2 \\times \\frac{0.986 \\times 0.944}{0.986 + 0.944} = 0.965$\n",
                "\n",
                "#### Specificity\n",
                "The proportion of actual negatives correctly identified.\n",
                "\n",
                "Formula: $Specificity = \\frac{TN}{TN + FP}$\n",
                "\n",
                "For our model: $\\frac{41}{41 + 1} = 0.976$\n",
                "\n",
                "<a name=\"understanding-the-visualisations\"></a>\n",
                "### Understanding the visualisations\n",
                "\n",
                "#### ROC curve\n",
                "The ROC curve plots True Positive Rate (Recall) against False Positive Rate (1-Specificity) as we vary the classification threshold:\n",
                "\n",
                "- True Positive Rate (y-axis): $TPR = \\frac{TP}{TP + FN}$\n",
                "- False Positive Rate (x-axis): $FPR = \\frac{FP}{FP + TN} = 1 - Specificity$\n",
                "\n",
                "Our curve shows:\n",
                "- Sharp rise to the top-left corner - excellent class separation\n",
                "- Huge gap above the diagonal line - far better than random chance\n",
                "- AUC of 0.994 - outstanding discriminative ability\n",
                "\n",
                "#### Confusion matrix\n",
                "Reading clockwise from top-left:\n",
                "```\n",
                "[TN FP]  =  [41  1]\n",
                "[FN TP]     [4  68]\n",
                "```\n",
                "\n",
                "This pattern shows our model is:\n",
                "- Very precise (few false positives)\n",
                "- Reasonably balanced (good at both classes)\n",
                "- Slightly more likely to miss positives than give false alarms\n",
                "\n",
                "#### Confidence distribution\n",
                "This histogram shows how confident our model is in its predictions for each class:\n",
                "- Class 0 (blue): Strong peak near 0 - very confident in negative predictions\n",
                "- Class 1 (green): Strong peak near 1 - very confident in positive predictions\n",
                "- Little overlap between classes - model clearly distinguishes between them\n",
                "- Few predictions in middle range - model is rarely uncertain\n",
                "\n",
                "#### Threshold analysis\n",
                "By varying the decision threshold from 0.3 to 0.7, we see:\n",
                "\n",
                "```\n",
                "threshold  accuracy  precision  recall     f1\n",
                "0.3        0.974     0.960     1.000     0.980\n",
                "0.4        0.974     0.973     0.986     0.979\n",
                "0.5        0.956     0.986     0.944     0.965\n",
                "0.6        0.956     0.986     0.944     0.965\n",
                "0.7        0.930     0.985     0.903     0.942\n",
                "```\n",
                "\n",
                "This shows:\n",
                "- Lower thresholds (0.3-0.4): Perfect/near-perfect recall but lower precision\n",
                "- Default threshold (0.5): Best balance of metrics\n",
                "- Higher thresholds (0.6-0.7): Slightly higher precision but lower recall\n",
                "\n",
                "<a name=\"key-insights\"></a>\n",
                "### Key insights\n",
                "1. The model shows excellent overall performance with balanced metrics\n",
                "2. It's more conservative with positive predictions (high precision)\n",
                "3. The default 0.5 threshold appears optimal for this problem\n",
                "4. Confidence distributions show strong class separation\n",
                "5. ROC-AUC near 1.0 indicates robust probabilistic predictions\n",
                "\n",
                "<a name=\"evaluation-best-practices\"></a>\n",
                "### Evaluation best practices\n",
                "1. Always check multiple metrics, not just accuracy\n",
                "2. Visualise performance through ROC curves and confusion matrices\n",
                "3. Examine prediction confidence distributions\n",
                "4. Test different decision thresholds\n",
                "5. Consider your problem's specific requirements when interpreting results\n",
                "\n",
                "This evaluation toolkit serves as a foundation for assessing more complex models. The same principles and methods will apply when we move to neural networks, though we'll add specific metrics for multi-class problems and additional visualisations for understanding hidden layers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a name=\"persisting-and-loading-our-model\"></a>\n",
                "## Persisting and loading our model\n",
                "\n",
                "After optimising and evaluating our model, we should save it for future use. PyTorch provides a straightforward way to save and load models, preserving both the architecture and learned parameters. We'll also save the standardisation parameters to ensure consistent preprocessing of new data. Below is an example of how to save and load our model to predict on new data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create models directory and save model\n",
                "save_dir = Path('../models')\n",
                "save_dir.mkdir(exist_ok=True)\n",
                "\n",
                "# Save model and scaler\n",
                "model_path = save_dir / 'cancer_classifier.pt'\n",
                "checkpoint = {\n",
                "    'model_state': model.state_dict(),\n",
                "    'scaler_mean': scaler.mean_.tolist(),  # Convert numpy arrays to lists for safer serialisation\n",
                "    'scaler_scale': scaler.scale_.tolist()\n",
                "}\n",
                "torch.save(checkpoint, model_path)  # Remove weights_only parameter\n",
                "\n",
                "# Load model and make prediction\n",
                "def load_and_predict(features):\n",
                "    # Load saved model with weights_only=True for security\n",
                "    checkpoint = torch.load(model_path, weights_only=True)\n",
                "    model.load_state_dict(checkpoint['model_state'])\n",
                "    model.eval()\n",
                "    \n",
                "    # Scale features (convert saved parameters back to numpy arrays)\n",
                "    scaler_mean = np.array(checkpoint['scaler_mean'])\n",
                "    scaler_scale = np.array(checkpoint['scaler_scale'])\n",
                "    features_scaled = (features - scaler_mean) / scaler_scale\n",
                "    \n",
                "    # Make prediction\n",
                "    with torch.no_grad():\n",
                "        features_tensor = torch.FloatTensor(features_scaled.reshape(1, -1))\n",
                "        probability = model(features_tensor).item()\n",
                "        prediction = int(probability > 0.5)\n",
                "    \n",
                "    return prediction, probability\n",
                "\n",
                "# Test with sample data\n",
                "sample_data = np.array([\n",
                "    17.99, 10.38, 122.8, 1001.0, 0.1184, 0.2776, 0.3001, 0.1471, 0.2419,\n",
                "    0.07871, 1.095, 0.9053, 8.589, 153.4, 0.006399, 0.04904, 0.05373,\n",
                "    0.01587, 0.03003, 0.006193, 25.38, 17.33, 184.6, 2019.0, 0.1622,\n",
                "    0.6656, 0.7119, 0.2654, 0.4601, 0.1189\n",
                "])\n",
                "\n",
                "prediction, probability = load_and_predict(sample_data)\n",
                "print(f\"Prediction: {'Malignant' if prediction == 1 else 'Benign'}\")\n",
                "print(f\"Probability of malignancy: {probability:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a name=\"looking-forward-from-logistic-regression-to-neural-networks\"></a>\n",
                "## Looking Forward: From Logistic Regression to Neural Networks\n",
                "\n",
                "Our PyTorch logistic regression implementation provides the perfect foundation for understanding neural networks. Let's examine how our current implementation evolves:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 157,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Current: Logistic Regression (Single Layer)\n",
                "class CancerClassifier(nn.Module):\n",
                "    def __init__(self, input_features):\n",
                "        super().__init__()\n",
                "        self.linear = nn.Linear(input_features, 1)  # Single layer\n",
                "        self.sigmoid = nn.Sigmoid()                 # Single activation\n",
                "        \n",
                "    def forward(self, x):\n",
                "        return self.sigmoid(self.linear(x))        # Direct mapping\n",
                "\n",
                "# Future: Neural Network (Multiple Layers)\n",
                "class CancerNN(nn.Module):\n",
                "    def __init__(self, input_features):\n",
                "        super().__init__()\n",
                "        # Multiple layers with increasing abstraction\n",
                "        self.layer1 = nn.Linear(input_features, 64)\n",
                "        self.layer2 = nn.Linear(64, 32)\n",
                "        self.layer3 = nn.Linear(32, 1)\n",
                "        \n",
                "        # Multiple activation functions\n",
                "        self.relu = nn.ReLU()\n",
                "        self.sigmoid = nn.Sigmoid()\n",
                "        \n",
                "        # Regularisation\n",
                "        self.dropout = nn.Dropout(0.2)\n",
                "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
                "        self.batch_norm2 = nn.BatchNorm1d(32)\n",
                "        \n",
                "    def forward(self, x):\n",
                "        # Complex transformation chain\n",
                "        x = self.dropout(self.relu(self.batch_norm1(self.layer1(x))))\n",
                "        x = self.dropout(self.relu(self.batch_norm2(self.layer2(x))))\n",
                "        return self.sigmoid(self.layer3(x))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The same PyTorch patterns we've established – nn.Module inheritance, forward methods, activation functions – form the basis for neural networks. \n",
                "\n",
                "In Lesson 3, we'll explore how stacking multiple layers of logistic regressions with different activation functions creates a neural network capable of learning more complex patterns. Each layer processes the output of the previous layer, similar to how biological neurons process signals from other neurons."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a name=\"conclusion\"></a>\n",
                "## Conclusion\n",
                "\n",
                "In this lesson, we've transformed our theoretical understanding of logistic regression into a robust, industry-standard implementation. Our journey from mathematical principles to working code has yielded several key insights.\n",
                "\n",
                "Our PyTorch implementation achieved remarkable results, with 96.5% accuracy on the test set. More importantly, we've seen how modern machine learning frameworks enable efficient development through automatic differentiation, batch processing, and hardware acceleration. The DataLoader and GPU capabilities in PyTorch showed us how to process data efficiently at scale - a crucial skill for real-world applications.\n",
                "\n",
                "The systematic approach to model evaluation proved particularly valuable. Rather than simply reporting accuracy, we developed a thorough understanding of our model's behaviour through precision, recall, and careful hyperparameter optimisation. These evaluation techniques helped us understand not just how well our model performed, but why it performed that way.\n",
                "\n",
                "Our implementation followed clear software engineering principles:\n",
                "\n",
                "```python\n",
                "# Industry-standard organisation\n",
                "class CancerClassifier(nn.Module)  # Core PyTorch model\n",
                "class ModelOptimiser               # Hyperparameter optimisation\n",
                "class ModelEvaluator               # Performance evaluation\n",
                "\n",
                "# Model evaluation and optimisation\n",
                "metrics = evaluator.evaluate_metrics() \n",
                "training_curves = evaluator.plot_training_curves()\n",
                "results = optimiser.run_experiments()  # Grid search over hyperparameters\n",
                "```\n",
                "\n",
                "Perhaps most importantly, we've established coding patterns that will serve us well throughout our machine learning journey. The PyTorch model architecture, evaluation frameworks, and optimisation approaches we've developed provide a foundation for exploring more complex models.\n",
                "\n",
                "<a name=\"looking-ahead-to-lesson-2-decision-trees\"></a>\n",
                "### Looking ahead to lesson 2: Decision Trees\n",
                "\n",
                "After exploring logistic regression with PyTorch, we'll next study decision trees - a different approach to machine learning that offers unique advantages in interpretability and handling diverse data types.\n",
                "\n",
                "In Lesson 2A, we'll cover the theory behind decision trees for both classification and regression tasks. We'll explore how trees make splitting decisions, learn strategies for encoding categorical data, and understand the bias-variance tradeoff. This foundation will prepare us for implementing a decision tree from scratch, much like we did with logistic regression in Lesson 1A. \n",
                "\n",
                "Then in Lesson 2B, we'll explore industry-standard implementations using modern frameworks, including more advanced tree-based methods like Random Forests and XGBoost. Along the way, we'll continue building on our understanding of validation, evaluation, and ethical considerations in model development.\n",
                "\n",
                "Next: [2A_decision_trees_theory.ipynb](./2a_decision_trees_theory.ipynb)\n",
                "\n",
                "Yes, several of those links are not hyperlinked. Here's the corrected version:\n",
                "\n",
                "<a name=\"further-reading\"></a>\n",
                "### Further Reading\n",
                "\n",
                "For those interested in deepening their understanding, several excellent resources are available:\n",
                "\n",
                "**PyTorch and Deep Learning**\n",
                "\n",
                "The official [PyTorch documentation](https://pytorch.org) provides comprehensive coverage of the framework's capabilities. \"[Deep Learning with PyTorch](https://pytorch.org/deep-learning-with-pytorch)\" by Stevens, Antiga, and Viehmann offers an excellent practical perspective, while \"[Programming PyTorch for Deep Learning](https://learning.oreilly.com/library/view/programming-pytorch-for/9781492045342/)\" by Pointer provides valuable insights into production implementation.\n",
                "\n",
                "**Machine Learning Engineering**\n",
                "\n",
                "[Chip Huyen's \"Designing Machine Learning Systems\"](https://learning.oreilly.com/library/view/designing-machine-learning/9781098107956/) and [Andriy Burkov's \"Machine Learning Engineering\"](http://www.mlebook.com/) offer broader perspectives on building production systems. [Google's Machine Learning Engineering Best Practices](https://developers.google.com/machine-learning/guides/rules-of-ml) provide practical guidelines drawn from industry experience.\n",
                "\n",
                "**Model Evaluation**\n",
                "\n",
                "[Alice Zheng's \"Evaluating Machine Learning Models\"](https://learning.oreilly.com/library/view/evaluating-machine-learning/9781492048756/) provides an in-depth look at assessment techniques. The [scikit-learn documentation](https://scikit-learn.org/stable/modules/model_evaluation.html) offers practical examples of evaluation metrics, while [Jason Brownlee's \"The Evaluation of Machine Learning Models\"](https://machinelearningmastery.com/evaluate-machine-learning-algorithms/) bridges theory and practice effectively.\n",
                "\n",
                "These resources complement our practical implementation work and provide valuable perspectives on production machine learning development.\n",
                "\n",
                "\n",
                "### Thanks for Learning!\n",
                "\n",
                "This notebook is part of the Supervised Machine Learning from First Principles series.\n",
                "\n",
                "© 2025 Powell-Clark Limited. Licensed under Apache License 2.0.\n",
                "\n",
                "If you found this helpful, please cite as:\n",
                "```\n",
                "Powell-Clark (2025). Supervised Machine Learning from First Principles.\n",
                "GitHub: https://github.com/powell-clark/supervised-machine-learning\n",
                "```\n",
                "\n",
                "Questions or feedback? Contact emmanuel@powell-clark.com"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
