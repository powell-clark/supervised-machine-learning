{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6B: Naive Bayes Practical",
    "",
    "Production Naive Bayes for text classification with scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB",
    "from sklearn.datasets import load_breast_cancer, fetch_20newsgroups",
    "from sklearn.model_selection import train_test_split",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix",
    "import matplotlib.pyplot as plt",
    "import seaborn as sns",
    "np.random.seed(42)",
    "print('\u2705 Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes (continuous features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()",
    "X, y = data.data, data.target",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
    "",
    "gnb = GaussianNB()",
    "gnb.fit(X_train, y_train)",
    "y_pred = gnb.predict(X_test)",
    "",
    "print(f'Gaussian NB Accuracy: {accuracy_score(y_test, y_pred):.3f}')",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification with Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subset of 20 newsgroups",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']",
    "train_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)",
    "test_data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)",
    "",
    "print(f'Training samples: {len(train_data.data)}')",
    "print(f'Categories: {train_data.target_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize text",
    "vectorizer = CountVectorizer(max_features=5000, stop_words='english')",
    "X_train = vectorizer.fit_transform(train_data.data)",
    "X_test = vectorizer.transform(test_data.data)",
    "",
    "print(f'Vocabulary size: {len(vectorizer.vocabulary_)}')",
    "print(f'Training matrix shape: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Multinomial NB",
    "mnb = MultinomialNB(alpha=1.0)  # alpha = Laplace smoothing",
    "mnb.fit(X_train, train_data.target)",
    "y_pred = mnb.predict(X_test)",
    "",
    "print(f'Test Accuracy: {accuracy_score(test_data.target, y_pred):.3f}')",
    "print('\\n' + classification_report(test_data.target, y_pred, target_names=train_data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF often works better than raw counts",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')",
    "X_train_tfidf = tfidf.fit_transform(train_data.data)",
    "X_test_tfidf = tfidf.transform(test_data.data)",
    "",
    "mnb_tfidf = MultinomialNB()",
    "mnb_tfidf.fit(X_train_tfidf, train_data.target)",
    "y_pred_tfidf = mnb_tfidf.predict(X_test_tfidf)",
    "",
    "print(f'TF-IDF Accuracy: {accuracy_score(test_data.target, y_pred_tfidf):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare All Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Naive Bayes Variants Comparison:\\n')",
    "print(f'Gaussian NB (continuous):  Best for numerical features')",
    "print(f'Multinomial NB (counts):   Best for text (word counts)')",
    "print(f'Bernoulli NB (binary):     Best for binary features\\n')",
    "print('For text: Multinomial > Bernoulli > Gaussian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion",
    "",
    "**Key Takeaways:**",
    "- **GaussianNB:** Continuous features (medical, sensor data)",
    "- **MultinomialNB:** Text classification (counts, TF-IDF)",
    "- **BernoulliNB:** Binary features (word present/absent)",
    "",
    "**Text Classification Tips:**",
    "- Use CountVectorizer or TfidfVectorizer",
    "- Remove stop words ('the', 'and', ...)",
    "- Tune alpha (smoothing parameter)",
    "- Multinomial usually beats Bernoulli",
    "",
    "**When to use Naive Bayes:**",
    "- \u2705 Text classification / NLP",
    "- \u2705 Real-time predictions needed",
    "- \u2705 Small training data",
    "- \u2705 Baseline model",
    "- \u274c Complex feature interactions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}