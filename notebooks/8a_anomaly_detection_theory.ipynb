{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 8A: Anomaly Detection Theory",
    "",
    "Detecting outliers, fraud, and rare events using supervised and unsupervised approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction",
    "",
    "Imagine monitoring credit card transactions. Most are normal - groceries, gas, restaurants. Then suddenly: $5000 purchase in a foreign country.",
    "",
    "Anomaly detection identifies these unusual patterns. It's crucial for:",
    "- Fraud detection (credit cards, insurance)",
    "- Network security (intrusion detection)",
    "- Manufacturing (defect detection)",
    "- Healthcare (disease outbreaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents",
    "1. What is Anomaly Detection?",
    "2. Statistical Methods",
    "3. Isolation Forest",
    "4. One-Class SVM",
    "5. Autoencoders for Anomaly Detection",
    "6. Supervised Approaches",
    "7. Evaluation Metrics",
    "8. Real-World Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np",
    "import matplotlib.pyplot as plt",
    "from sklearn.ensemble import IsolationForest",
    "from sklearn.svm import OneClassSVM",
    "from sklearn.datasets import make_classification",
    "from sklearn.metrics import classification_report, roc_auc_score",
    "np.random.seed(42)",
    "print('\u2705 Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Approach: Gaussian Distribution",
    "",
    "**Method:** Model normal data as Gaussian, flag points with low probability.",
    "",
    "**Algorithm:**",
    "1. Compute mean \u03bc and variance \u03c3\u00b2 from training data",
    "2. For new point x, compute p(x)",
    "3. If p(x) < \u03b5 (threshold), flag as anomaly",
    "",
    "$p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$",
    "",
    "For multivariate: Use Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate normal data with a few anomalies",
    "normal = np.random.normal(0, 1, (1000, 2))",
    "anomalies = np.random.uniform(-4, 4, (50, 2))",
    "X = np.vstack([normal, anomalies])",
    "y = np.array([0]*1000 + [1]*50)  # 0=normal, 1=anomaly",
    "",
    "plt.figure(figsize=(10, 6))",
    "plt.scatter(X[y==0, 0], X[y==0, 1], alpha=0.5, label='Normal', s=20)",
    "plt.scatter(X[y==1, 0], X[y==1, 1], c='red', alpha=0.7, label='Anomaly', s=50, marker='x')",
    "plt.xlabel('Feature 1')",
    "plt.ylabel('Feature 2')",
    "plt.title('Anomaly Detection Problem', fontweight='bold')",
    "plt.legend()",
    "plt.grid(alpha=0.3)",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest",
    "",
    "**Key Insight:** Anomalies are 'few and different', so they're isolated quickly in random trees.",
    "",
    "**Algorithm:**",
    "1. Randomly select feature and split value",
    "2. Build tree by recursively splitting",
    "3. Anomalies require fewer splits to isolate",
    "4. Anomaly score = average path length across trees",
    "",
    "**Advantages:**",
    "- Fast (linear time complexity)",
    "- No need to define distance metric",
    "- Handles high dimensions well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forest",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)",
    "y_pred = iso_forest.fit_predict(X)",
    "y_pred = np.where(y_pred == -1, 1, 0)  # Convert to 0/1",
    "",
    "print('Isolation Forest Results:')",
    "print(classification_report(y, y_pred, target_names=['Normal', 'Anomaly']))",
    "print(f'ROC-AUC: {roc_auc_score(y, iso_forest.score_samples(X)):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Class SVM",
    "",
    "**Idea:** Find boundary that encloses normal data in feature space.",
    "",
    "**Algorithm:**",
    "1. Map data to high-dimensional space (kernel trick)",
    "2. Find hyperplane separating data from origin",
    "3. Maximize margin (distance to boundary)",
    "4. Points outside boundary = anomalies",
    "",
    "**Best for:** Small, clean datasets with clear normal region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Class SVM",
    "svm = OneClassSVM(kernel='rbf', gamma='auto', nu=0.05)",
    "y_pred_svm = svm.fit_predict(X)",
    "y_pred_svm = np.where(y_pred_svm == -1, 1, 0)",
    "",
    "print('One-Class SVM Results:')",
    "print(classification_report(y, y_pred_svm, target_names=['Normal', 'Anomaly']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion",
    "",
    "**Method Selection Guide:**",
    "",
    "**Isolation Forest:**",
    "- \u2705 Large datasets",
    "- \u2705 High dimensions",
    "- \u2705 Fast detection needed",
    "- \u2705 General-purpose",
    "",
    "**One-Class SVM:**",
    "- \u2705 Small, clean dataset",
    "- \u2705 Clear normal region",
    "- \u2705 Need decision boundary",
    "",
    "**Statistical (Gaussian):**",
    "- \u2705 Data truly Gaussian",
    "- \u2705 Low dimensions",
    "- \u2705 Interpretability important",
    "",
    "**Autoencoders (Deep Learning):**",
    "- \u2705 Images, sequences",
    "- \u2705 Complex patterns",
    "- \u2705 GPU available",
    "",
    "**Next:** Lesson 8B - Production anomaly detection systems!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}